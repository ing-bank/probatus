{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4037e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probatus.feature_elimination import ShapRFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b55e4",
   "metadata": {},
   "source": [
    "# Shap variance penalty\n",
    "\n",
    "When ShapRFECV is computing feature importance and subsequently eliminating features, it computes the average of shap values to get an estimate of that feature's overall importance. In some situations, the variance of these shap values might be high - which might indicate a lack of agreement regarding that feature's importance. Catering to this situation, probatus allows you to penalize features that have a higher variance of shap values.\n",
    "\n",
    "By setting `shap_variance_penalty_factor` param within `fit_compute()` method, the averaging of shap values is computed by:\n",
    "<<add>>\n",
    "\n",
    "See example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50b0d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 991/1000 [00:27<00:00]        The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      " 98%|===================| 975/1000 [00:27<00:00]        The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=5000, n_informative=20, n_features=100)\n",
    "clf = CatBoostClassifier(n_estimators=1000, verbose=0)\n",
    "shap_elimination = ShapRFECV(clf=clf, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1)\n",
    "report_with_penalty = shap_elimination.fit_compute(X, y, shap_variance_penalty_factor=1.0)\n",
    "report_without_penalty = shap_elimination.fit_compute(X, y, shap_variance_penalty_factor=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bf725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_features</th>\n",
       "      <th>features_set</th>\n",
       "      <th>eliminated_features</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>train_metric_std</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>val_metric_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[94, 57, 78, 41, 30, 47, 10, 88, 22, 95, 36, 8...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>[0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15...</td>\n",
       "      <td>[45, 40, 83, 6, 14, 86, 26, 80, 42, 23, 99, 89...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>[0, 1, 2, 3, 4, 8, 9, 11, 12, 13, 15, 16, 17, ...</td>\n",
       "      <td>[53, 69, 44, 60, 33, 34, 65, 93, 8, 73, 72, 32]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>[0, 1, 2, 3, 4, 9, 11, 12, 13, 15, 16, 17, 18,...</td>\n",
       "      <td>[15, 85, 98, 64, 52, 9, 49, 63, 74, 58]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>[0, 1, 2, 3, 4, 11, 12, 13, 16, 17, 18, 21, 24...</td>\n",
       "      <td>[27, 31, 48, 54, 3, 50, 81, 21]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>[0, 1, 2, 4, 11, 12, 13, 16, 17, 18, 24, 25, 2...</td>\n",
       "      <td>[39, 11, 84, 37, 68, 2]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>[0, 1, 4, 12, 13, 16, 17, 18, 24, 25, 28, 29, ...</td>\n",
       "      <td>[91, 18, 97, 24, 90]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>[0, 1, 4, 12, 13, 16, 17, 25, 28, 29, 35, 38, ...</td>\n",
       "      <td>[77, 82, 28, 4]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>[0, 1, 12, 13, 16, 17, 25, 29, 35, 38, 43, 46,...</td>\n",
       "      <td>[16, 25, 38]</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>[0, 1, 12, 13, 17, 29, 35, 43, 46, 66, 67, 71,...</td>\n",
       "      <td>[0, 1, 76]</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 46, 66, 67, 71, 75, 7...</td>\n",
       "      <td>[67, 46]</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 66, 71, 75, 79, 92]</td>\n",
       "      <td>[71, 66]</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 75, 79, 92]</td>\n",
       "      <td>[75]</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 79, 92]</td>\n",
       "      <td>[43]</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>[12, 13, 17, 29, 35, 79, 92]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>[13, 17, 29, 35, 79, 92]</td>\n",
       "      <td>[92]</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>[13, 17, 29, 35, 79]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_features                                       features_set  \\\n",
       "1            100  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2             80  [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15...   \n",
       "3             64  [0, 1, 2, 3, 4, 8, 9, 11, 12, 13, 15, 16, 17, ...   \n",
       "4             52  [0, 1, 2, 3, 4, 9, 11, 12, 13, 15, 16, 17, 18,...   \n",
       "5             42  [0, 1, 2, 3, 4, 11, 12, 13, 16, 17, 18, 21, 24...   \n",
       "6             34  [0, 1, 2, 4, 11, 12, 13, 16, 17, 18, 24, 25, 2...   \n",
       "7             28  [0, 1, 4, 12, 13, 16, 17, 18, 24, 25, 28, 29, ...   \n",
       "8             23  [0, 1, 4, 12, 13, 16, 17, 25, 28, 29, 35, 38, ...   \n",
       "9             19  [0, 1, 12, 13, 16, 17, 25, 29, 35, 38, 43, 46,...   \n",
       "10            16  [0, 1, 12, 13, 17, 29, 35, 43, 46, 66, 67, 71,...   \n",
       "11            13  [12, 13, 17, 29, 35, 43, 46, 66, 67, 71, 75, 7...   \n",
       "12            11       [12, 13, 17, 29, 35, 43, 66, 71, 75, 79, 92]   \n",
       "13             9               [12, 13, 17, 29, 35, 43, 75, 79, 92]   \n",
       "14             8                   [12, 13, 17, 29, 35, 43, 79, 92]   \n",
       "15             7                       [12, 13, 17, 29, 35, 79, 92]   \n",
       "16             6                           [13, 17, 29, 35, 79, 92]   \n",
       "17             5                               [13, 17, 29, 35, 79]   \n",
       "\n",
       "                                  eliminated_features  train_metric_mean  \\\n",
       "1   [94, 57, 78, 41, 30, 47, 10, 88, 22, 95, 36, 8...              0.999   \n",
       "2   [45, 40, 83, 6, 14, 86, 26, 80, 42, 23, 99, 89...              0.999   \n",
       "3     [53, 69, 44, 60, 33, 34, 65, 93, 8, 73, 72, 32]              0.999   \n",
       "4             [15, 85, 98, 64, 52, 9, 49, 63, 74, 58]              0.999   \n",
       "5                     [27, 31, 48, 54, 3, 50, 81, 21]              0.999   \n",
       "6                             [39, 11, 84, 37, 68, 2]              0.998   \n",
       "7                                [91, 18, 97, 24, 90]              0.998   \n",
       "8                                     [77, 82, 28, 4]              0.998   \n",
       "9                                        [16, 25, 38]              0.997   \n",
       "10                                         [0, 1, 76]              0.994   \n",
       "11                                           [67, 46]              0.989   \n",
       "12                                           [71, 66]              0.978   \n",
       "13                                               [75]              0.960   \n",
       "14                                               [43]              0.944   \n",
       "15                                               [12]              0.929   \n",
       "16                                               [92]              0.904   \n",
       "17                                                 []              0.875   \n",
       "\n",
       "    train_metric_std  val_metric_mean  val_metric_std  \n",
       "1              0.000            0.943           0.006  \n",
       "2              0.000            0.947           0.006  \n",
       "3              0.000            0.947           0.006  \n",
       "4              0.000            0.947           0.006  \n",
       "5              0.000            0.949           0.006  \n",
       "6              0.000            0.950           0.007  \n",
       "7              0.000            0.954           0.010  \n",
       "8              0.000            0.952           0.008  \n",
       "9              0.000            0.946           0.008  \n",
       "10             0.001            0.930           0.007  \n",
       "11             0.001            0.917           0.008  \n",
       "12             0.002            0.903           0.003  \n",
       "13             0.002            0.880           0.006  \n",
       "14             0.003            0.861           0.006  \n",
       "15             0.002            0.841           0.007  \n",
       "16             0.003            0.822           0.010  \n",
       "17             0.002            0.784           0.010  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_with_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc62391",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_features</th>\n",
       "      <th>features_set</th>\n",
       "      <th>eliminated_features</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>train_metric_std</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>val_metric_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[94, 57, 78, 41, 30, 47, 10, 88, 22, 95, 36, 8...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>[0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15...</td>\n",
       "      <td>[45, 40, 83, 6, 14, 86, 26, 80, 42, 23, 99, 89...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>[0, 1, 2, 3, 4, 8, 9, 11, 12, 13, 15, 16, 17, ...</td>\n",
       "      <td>[53, 69, 44, 60, 33, 34, 65, 93, 8, 73, 72, 32]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>[0, 1, 2, 3, 4, 9, 11, 12, 13, 15, 16, 17, 18,...</td>\n",
       "      <td>[15, 85, 98, 64, 52, 9, 49, 63, 74, 58]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>[0, 1, 2, 3, 4, 11, 12, 13, 16, 17, 18, 21, 24...</td>\n",
       "      <td>[27, 31, 48, 54, 3, 50, 81, 21]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>[0, 1, 2, 4, 11, 12, 13, 16, 17, 18, 24, 25, 2...</td>\n",
       "      <td>[39, 11, 84, 37, 68, 2]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>[0, 1, 4, 12, 13, 16, 17, 18, 24, 25, 28, 29, ...</td>\n",
       "      <td>[91, 18, 97, 24, 90]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>[0, 1, 4, 12, 13, 16, 17, 25, 28, 29, 35, 38, ...</td>\n",
       "      <td>[77, 82, 28, 4]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>[0, 1, 12, 13, 16, 17, 25, 29, 35, 38, 43, 46,...</td>\n",
       "      <td>[16, 25, 38]</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>[0, 1, 12, 13, 17, 29, 35, 43, 46, 66, 67, 71,...</td>\n",
       "      <td>[0, 1, 76]</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 46, 66, 67, 71, 75, 7...</td>\n",
       "      <td>[67, 46]</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 66, 71, 75, 79, 92]</td>\n",
       "      <td>[71, 66]</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 75, 79, 92]</td>\n",
       "      <td>[75]</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 79, 92]</td>\n",
       "      <td>[43]</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>[12, 13, 17, 29, 35, 79, 92]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>[13, 17, 29, 35, 79, 92]</td>\n",
       "      <td>[92]</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>[13, 17, 29, 35, 79]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[33, 49, 69, 53, 45, 78, 85, 57, 80, 34, 74, 6...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[15, 70, 5, 98, 63, 64, 9, 59, 88, 65, 22, 32,...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>[0, 1, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 16, ...</td>\n",
       "      <td>[52, 10, 37, 36, 51, 87, 96, 72, 3, 26, 93, 44]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>[0, 1, 2, 4, 6, 7, 11, 12, 13, 14, 16, 17, 18,...</td>\n",
       "      <td>[23, 14, 48, 39, 6, 21, 50, 2, 89, 62]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>[0, 1, 4, 7, 11, 12, 13, 16, 17, 18, 24, 25, 2...</td>\n",
       "      <td>[54, 31, 84, 73, 55, 58, 7, 30]</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>[0, 1, 4, 11, 12, 13, 16, 17, 18, 24, 25, 27, ...</td>\n",
       "      <td>[68, 61, 47, 11, 81, 27]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>[0, 1, 4, 12, 13, 16, 17, 18, 24, 25, 28, 29, ...</td>\n",
       "      <td>[91, 90, 18, 97, 24]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>[0, 1, 4, 12, 13, 16, 17, 25, 28, 29, 35, 38, ...</td>\n",
       "      <td>[0, 77, 82, 4]</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>[1, 12, 13, 16, 17, 25, 28, 29, 35, 38, 43, 46...</td>\n",
       "      <td>[38, 28, 76]</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>[1, 12, 13, 16, 17, 25, 29, 35, 43, 46, 66, 67...</td>\n",
       "      <td>[16, 25, 1]</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 46, 66, 67, 71, 75, 7...</td>\n",
       "      <td>[67, 46]</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 66, 71, 75, 79, 92]</td>\n",
       "      <td>[71, 66]</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>[12, 13, 17, 29, 35, 43, 75, 79, 92]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>[12, 13, 29, 35, 43, 75, 79, 92]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>[13, 29, 35, 43, 75, 79, 92]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>[29, 35, 43, 75, 79, 92]</td>\n",
       "      <td>[92]</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>[29, 35, 43, 75, 79]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_features                                       features_set  \\\n",
       "1            100  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2             80  [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15...   \n",
       "3             64  [0, 1, 2, 3, 4, 8, 9, 11, 12, 13, 15, 16, 17, ...   \n",
       "4             52  [0, 1, 2, 3, 4, 9, 11, 12, 13, 15, 16, 17, 18,...   \n",
       "5             42  [0, 1, 2, 3, 4, 11, 12, 13, 16, 17, 18, 21, 24...   \n",
       "6             34  [0, 1, 2, 4, 11, 12, 13, 16, 17, 18, 24, 25, 2...   \n",
       "7             28  [0, 1, 4, 12, 13, 16, 17, 18, 24, 25, 28, 29, ...   \n",
       "8             23  [0, 1, 4, 12, 13, 16, 17, 25, 28, 29, 35, 38, ...   \n",
       "9             19  [0, 1, 12, 13, 16, 17, 25, 29, 35, 38, 43, 46,...   \n",
       "10            16  [0, 1, 12, 13, 17, 29, 35, 43, 46, 66, 67, 71,...   \n",
       "11            13  [12, 13, 17, 29, 35, 43, 46, 66, 67, 71, 75, 7...   \n",
       "12            11       [12, 13, 17, 29, 35, 43, 66, 71, 75, 79, 92]   \n",
       "13             9               [12, 13, 17, 29, 35, 43, 75, 79, 92]   \n",
       "14             8                   [12, 13, 17, 29, 35, 43, 79, 92]   \n",
       "15             7                       [12, 13, 17, 29, 35, 79, 92]   \n",
       "16             6                           [13, 17, 29, 35, 79, 92]   \n",
       "17             5                               [13, 17, 29, 35, 79]   \n",
       "1            100  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2             80  [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14...   \n",
       "3             64  [0, 1, 2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 16, ...   \n",
       "4             52  [0, 1, 2, 4, 6, 7, 11, 12, 13, 14, 16, 17, 18,...   \n",
       "5             42  [0, 1, 4, 7, 11, 12, 13, 16, 17, 18, 24, 25, 2...   \n",
       "6             34  [0, 1, 4, 11, 12, 13, 16, 17, 18, 24, 25, 27, ...   \n",
       "7             28  [0, 1, 4, 12, 13, 16, 17, 18, 24, 25, 28, 29, ...   \n",
       "8             23  [0, 1, 4, 12, 13, 16, 17, 25, 28, 29, 35, 38, ...   \n",
       "9             19  [1, 12, 13, 16, 17, 25, 28, 29, 35, 38, 43, 46...   \n",
       "10            16  [1, 12, 13, 16, 17, 25, 29, 35, 43, 46, 66, 67...   \n",
       "11            13  [12, 13, 17, 29, 35, 43, 46, 66, 67, 71, 75, 7...   \n",
       "12            11       [12, 13, 17, 29, 35, 43, 66, 71, 75, 79, 92]   \n",
       "13             9               [12, 13, 17, 29, 35, 43, 75, 79, 92]   \n",
       "14             8                   [12, 13, 29, 35, 43, 75, 79, 92]   \n",
       "15             7                       [13, 29, 35, 43, 75, 79, 92]   \n",
       "16             6                           [29, 35, 43, 75, 79, 92]   \n",
       "17             5                               [29, 35, 43, 75, 79]   \n",
       "\n",
       "                                  eliminated_features  train_metric_mean  \\\n",
       "1   [94, 57, 78, 41, 30, 47, 10, 88, 22, 95, 36, 8...              0.999   \n",
       "2   [45, 40, 83, 6, 14, 86, 26, 80, 42, 23, 99, 89...              0.999   \n",
       "3     [53, 69, 44, 60, 33, 34, 65, 93, 8, 73, 72, 32]              0.999   \n",
       "4             [15, 85, 98, 64, 52, 9, 49, 63, 74, 58]              0.999   \n",
       "5                     [27, 31, 48, 54, 3, 50, 81, 21]              0.999   \n",
       "6                             [39, 11, 84, 37, 68, 2]              0.998   \n",
       "7                                [91, 18, 97, 24, 90]              0.998   \n",
       "8                                     [77, 82, 28, 4]              0.998   \n",
       "9                                        [16, 25, 38]              0.997   \n",
       "10                                         [0, 1, 76]              0.994   \n",
       "11                                           [67, 46]              0.989   \n",
       "12                                           [71, 66]              0.978   \n",
       "13                                               [75]              0.960   \n",
       "14                                               [43]              0.944   \n",
       "15                                               [12]              0.929   \n",
       "16                                               [92]              0.904   \n",
       "17                                                 []              0.875   \n",
       "1   [33, 49, 69, 53, 45, 78, 85, 57, 80, 34, 74, 6...              0.999   \n",
       "2   [15, 70, 5, 98, 63, 64, 9, 59, 88, 65, 22, 32,...              0.999   \n",
       "3     [52, 10, 37, 36, 51, 87, 96, 72, 3, 26, 93, 44]              0.999   \n",
       "4              [23, 14, 48, 39, 6, 21, 50, 2, 89, 62]              0.999   \n",
       "5                     [54, 31, 84, 73, 55, 58, 7, 30]              0.999   \n",
       "6                            [68, 61, 47, 11, 81, 27]              0.998   \n",
       "7                                [91, 90, 18, 97, 24]              0.998   \n",
       "8                                      [0, 77, 82, 4]              0.998   \n",
       "9                                        [38, 28, 76]              0.997   \n",
       "10                                        [16, 25, 1]              0.994   \n",
       "11                                           [67, 46]              0.989   \n",
       "12                                           [71, 66]              0.978   \n",
       "13                                               [17]              0.960   \n",
       "14                                               [12]              0.953   \n",
       "15                                               [13]              0.932   \n",
       "16                                               [92]              0.903   \n",
       "17                                                 []              0.870   \n",
       "\n",
       "    train_metric_std  val_metric_mean  val_metric_std  \n",
       "1              0.000            0.943           0.006  \n",
       "2              0.000            0.947           0.006  \n",
       "3              0.000            0.947           0.006  \n",
       "4              0.000            0.947           0.006  \n",
       "5              0.000            0.949           0.006  \n",
       "6              0.000            0.950           0.007  \n",
       "7              0.000            0.954           0.010  \n",
       "8              0.000            0.952           0.008  \n",
       "9              0.000            0.946           0.008  \n",
       "10             0.001            0.930           0.007  \n",
       "11             0.001            0.917           0.008  \n",
       "12             0.002            0.903           0.003  \n",
       "13             0.002            0.880           0.006  \n",
       "14             0.003            0.861           0.006  \n",
       "15             0.002            0.841           0.007  \n",
       "16             0.003            0.822           0.010  \n",
       "17             0.002            0.784           0.010  \n",
       "1              0.000            0.943           0.006  \n",
       "2              0.000            0.944           0.005  \n",
       "3              0.000            0.945           0.006  \n",
       "4              0.000            0.950           0.005  \n",
       "5              0.000            0.950           0.008  \n",
       "6              0.000            0.948           0.006  \n",
       "7              0.000            0.954           0.010  \n",
       "8              0.000            0.952           0.008  \n",
       "9              0.000            0.945           0.005  \n",
       "10             0.001            0.936           0.004  \n",
       "11             0.001            0.917           0.008  \n",
       "12             0.002            0.903           0.003  \n",
       "13             0.002            0.880           0.006  \n",
       "14             0.003            0.875           0.005  \n",
       "15             0.003            0.850           0.012  \n",
       "16             0.003            0.816           0.005  \n",
       "17             0.003            0.778           0.004  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_without_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3bdfca",
   "metadata": {},
   "source": [
    "# Which approach is better?\n",
    "\n",
    "Let's compare a few different configurations of RFECV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e41b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score_a</th>\n",
       "      <th>std_a</th>\n",
       "      <th>num_features_a</th>\n",
       "      <th>best_score_b</th>\n",
       "      <th>std_b</th>\n",
       "      <th>num_features_b</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_informative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.015</td>\n",
       "      <td>67</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.022</td>\n",
       "      <td>103</td>\n",
       "      <td>930</td>\n",
       "      <td>200</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.025</td>\n",
       "      <td>44</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.026</td>\n",
       "      <td>67</td>\n",
       "      <td>1224</td>\n",
       "      <td>200</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.030</td>\n",
       "      <td>44</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.042</td>\n",
       "      <td>29</td>\n",
       "      <td>1154</td>\n",
       "      <td>200</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.003</td>\n",
       "      <td>200</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.003</td>\n",
       "      <td>200</td>\n",
       "      <td>3608</td>\n",
       "      <td>200</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.026</td>\n",
       "      <td>67</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.013</td>\n",
       "      <td>44</td>\n",
       "      <td>744</td>\n",
       "      <td>200</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.011</td>\n",
       "      <td>103</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.017</td>\n",
       "      <td>83</td>\n",
       "      <td>3272</td>\n",
       "      <td>200</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.020</td>\n",
       "      <td>128</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.017</td>\n",
       "      <td>54</td>\n",
       "      <td>1388</td>\n",
       "      <td>200</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.029</td>\n",
       "      <td>67</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.028</td>\n",
       "      <td>160</td>\n",
       "      <td>2391</td>\n",
       "      <td>200</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.014</td>\n",
       "      <td>67</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.019</td>\n",
       "      <td>83</td>\n",
       "      <td>1141</td>\n",
       "      <td>200</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.013</td>\n",
       "      <td>200</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.020</td>\n",
       "      <td>54</td>\n",
       "      <td>2704</td>\n",
       "      <td>200</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_score_a  std_a  num_features_a  best_score_b  std_b  num_features_b  \\\n",
       "0         0.783  0.015              67         0.787  0.022             103   \n",
       "1         0.844  0.025              44         0.843  0.026              67   \n",
       "2         0.776  0.030              44         0.775  0.042              29   \n",
       "3         0.923  0.003             200         0.923  0.003             200   \n",
       "4         0.786  0.026              67         0.786  0.013              44   \n",
       "5         0.916  0.011             103         0.914  0.017              83   \n",
       "6         0.820  0.020             128         0.825  0.017              54   \n",
       "7         0.844  0.029              67         0.851  0.028             160   \n",
       "8         0.843  0.014              67         0.841  0.019              83   \n",
       "9         0.892  0.013             200         0.896  0.020              54   \n",
       "\n",
       "   n_samples  n_features  n_informative  \n",
       "0        930         200            138  \n",
       "1       1224         200            105  \n",
       "2       1154         200            180  \n",
       "3       3608         200             27  \n",
       "4        744         200            105  \n",
       "5       3272         200             52  \n",
       "6       1388         200            159  \n",
       "7       2391         200            104  \n",
       "8       1141         200             94  \n",
       "9       2704         200             39  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare A: shap_variance_penalty_factor=0.5 & approximate=True\n",
    "# vs B: shap_variance_penalty_factor=0 (disabled) & approximate=True\n",
    "num_simulations = 10\n",
    "results = []\n",
    "\n",
    "\n",
    "def get_best_idx(shap_report):\n",
    "    shap_report[\"eval_metric\"] = shap_report[\"val_metric_mean\"]\n",
    "    best_iteration_idx = shap_report[\"eval_metric\"].argmax()\n",
    "\n",
    "    return best_iteration_idx\n",
    "\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    # Params\n",
    "    n_samples = np.random.randint(500, 5000)\n",
    "    n_features = 200\n",
    "    n_informative = np.random.randint(10, 200)\n",
    "    test_size = np.random.uniform(0.05, 0.5)\n",
    "\n",
    "    # Create data\n",
    "    X, y = make_classification(n_samples=n_samples, n_informative=n_informative, n_features=n_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    # Model\n",
    "    clf = CatBoostClassifier(n_estimators=1000, verbose=0)\n",
    "\n",
    "    # Best score from ShapRFECV WITHOUT penalization\n",
    "    shap_elimination = ShapRFECV(clf=clf, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1)\n",
    "    report_a = shap_elimination.fit_compute(\n",
    "        X_train, y_train, shap_variance_penalty_factor=0, approximate=True, check_additivity=False\n",
    "    )\n",
    "    best_idx_a = get_best_idx(report_a)\n",
    "    best_score_a = report_a[\"val_metric_mean\"].iloc[best_idx_a]\n",
    "    std_a = report_a[\"val_metric_std\"].iloc[best_idx_a]\n",
    "    num_features_a = report_a[\"num_features\"].iloc[best_idx_a]\n",
    "\n",
    "    # Best score from ShapRFECV WITH penalization\n",
    "    shap_elimination = ShapRFECV(clf=clf, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1)\n",
    "    report_b = shap_elimination.fit_compute(\n",
    "        X_train, y_train, shap_variance_penalty_factor=0.5, approximate=True, check_additivity=False\n",
    "    )\n",
    "    best_idx_b = get_best_idx(report_b)\n",
    "    best_score_b = report_b[\"val_metric_mean\"].iloc[best_idx_b]\n",
    "    std_b = report_b[\"val_metric_std\"].iloc[best_idx_b]\n",
    "    num_features_b = report_b[\"num_features\"].iloc[best_idx_b]\n",
    "\n",
    "    results.append(\n",
    "        [best_score_a, std_a, num_features_a, best_score_b, std_b, num_features_b, n_samples, n_features, n_informative]\n",
    "    )\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\n",
    "            \"best_score_a\",\n",
    "            \"std_a\",\n",
    "            \"num_features_a\",\n",
    "            \"best_score_b\",\n",
    "            \"std_b\",\n",
    "            \"num_features_b\",\n",
    "            \"n_samples\",\n",
    "            \"n_features\",\n",
    "            \"n_informative\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9fb4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      " 97%|=================== | 450/466 [00:13<00:00]       The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      " 99%|===================| 461/466 [00:14<00:00]        The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      " 99%|===================| 336/338 [00:11<00:00]        The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "100%|===================| 337/338 [00:11<00:00]        The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "100%|===================| 518/520 [00:15<00:00]       The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "100%|===================| 517/519 [00:15<00:00]        The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      " 98%|===================| 790/806 [00:22<00:00]        The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      " 97%|=================== | 779/806 [00:22<00:00]       The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "100%|===================| 514/515 [00:15<00:00]        The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      " 96%|=================== | 495/514 [00:14<00:00]       The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score_a</th>\n",
       "      <th>std_a</th>\n",
       "      <th>num_features_a</th>\n",
       "      <th>best_score_b</th>\n",
       "      <th>std_b</th>\n",
       "      <th>num_features_b</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_informative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.019</td>\n",
       "      <td>24</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.019</td>\n",
       "      <td>24</td>\n",
       "      <td>1059</td>\n",
       "      <td>200</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.025</td>\n",
       "      <td>128</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.019</td>\n",
       "      <td>83</td>\n",
       "      <td>1357</td>\n",
       "      <td>200</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.032</td>\n",
       "      <td>160</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.020</td>\n",
       "      <td>128</td>\n",
       "      <td>2898</td>\n",
       "      <td>200</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.011</td>\n",
       "      <td>16</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.011</td>\n",
       "      <td>16</td>\n",
       "      <td>2656</td>\n",
       "      <td>200</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.034</td>\n",
       "      <td>128</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.029</td>\n",
       "      <td>67</td>\n",
       "      <td>1574</td>\n",
       "      <td>200</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.011</td>\n",
       "      <td>83</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.010</td>\n",
       "      <td>103</td>\n",
       "      <td>4039</td>\n",
       "      <td>200</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.011</td>\n",
       "      <td>83</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.014</td>\n",
       "      <td>103</td>\n",
       "      <td>1769</td>\n",
       "      <td>200</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.013</td>\n",
       "      <td>128</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.019</td>\n",
       "      <td>103</td>\n",
       "      <td>2080</td>\n",
       "      <td>200</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.957</td>\n",
       "      <td>0.003</td>\n",
       "      <td>36</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.007</td>\n",
       "      <td>67</td>\n",
       "      <td>4916</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.016</td>\n",
       "      <td>160</td>\n",
       "      <td>4139</td>\n",
       "      <td>200</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_score_a  std_a  num_features_a  best_score_b  std_b  num_features_b  \\\n",
       "0         0.891  0.019              24         0.891  0.019              24   \n",
       "1         0.819  0.025             128         0.821  0.019              83   \n",
       "2         0.840  0.032             160         0.843  0.020             128   \n",
       "3         0.927  0.011              16         0.927  0.011              16   \n",
       "4         0.811  0.034             128         0.812  0.029              67   \n",
       "5         0.904  0.011              83         0.899  0.010             103   \n",
       "6         0.854  0.011              83         0.862  0.014             103   \n",
       "7         0.839  0.013             128         0.828  0.019             103   \n",
       "8         0.957  0.003              36         0.957  0.007              67   \n",
       "9         0.854  0.010             128         0.855  0.016             160   \n",
       "\n",
       "   n_samples  n_features  n_informative  \n",
       "0       1059         200             34  \n",
       "1       1357         200            129  \n",
       "2       2898         200            175  \n",
       "3       2656         200             18  \n",
       "4       1574         200            129  \n",
       "5       4039         200             89  \n",
       "6       1769         200            107  \n",
       "7       2080         200            162  \n",
       "8       4916         200             31  \n",
       "9       4139         200            164  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare A: shap_variance_penalty_factor=0.5 & approximate=False\n",
    "# vs B: shap_variance_penalty_factor=0 (disabled) & approximate=False\n",
    "num_simulations = 10\n",
    "results = []\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    # Params\n",
    "    n_samples = np.random.randint(500, 5000)\n",
    "    n_features = 200\n",
    "    n_informative = np.random.randint(10, 200)\n",
    "    test_size = np.random.uniform(0.05, 0.5)\n",
    "\n",
    "    # Create data\n",
    "    X, y = make_classification(n_samples=n_samples, n_informative=n_informative, n_features=n_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    # Model\n",
    "    clf = CatBoostClassifier(n_estimators=1000, verbose=0)\n",
    "\n",
    "    # Best score from ShapRFECV WITHOUT penalization\n",
    "    shap_elimination = ShapRFECV(clf=clf, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1)\n",
    "    report_a = shap_elimination.fit_compute(X_train, y_train, shap_variance_penalty_factor=0, approximate=False)\n",
    "    best_idx_a = get_best_idx(report_a)\n",
    "    best_score_a = report_a[\"val_metric_mean\"].iloc[best_idx_a]\n",
    "    std_a = report_a[\"val_metric_std\"].iloc[best_idx_a]\n",
    "    num_features_a = report_a[\"num_features\"].iloc[best_idx_a]\n",
    "\n",
    "    # Best score from ShapRFECV WITH penalization\n",
    "    shap_elimination = ShapRFECV(clf=clf, step=0.2, min_features_to_select=5, cv=5, scoring=\"f1\", n_jobs=5, verbose=1)\n",
    "    report_b = shap_elimination.fit_compute(X_train, y_train, shap_variance_penalty_factor=0.5, approximate=False)\n",
    "    best_idx_b = get_best_idx(report_b)\n",
    "    best_score_b = report_b[\"val_metric_mean\"].iloc[best_idx_b]\n",
    "    std_b = report_b[\"val_metric_std\"].iloc[best_idx_b]\n",
    "    num_features_b = report_b[\"num_features\"].iloc[best_idx_b]\n",
    "\n",
    "    results.append(\n",
    "        [best_score_a, std_a, num_features_a, best_score_b, std_b, num_features_b, n_samples, n_features, n_informative]\n",
    "    )\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\n",
    "            \"best_score_a\",\n",
    "            \"std_a\",\n",
    "            \"num_features_a\",\n",
    "            \"best_score_b\",\n",
    "            \"std_b\",\n",
    "            \"num_features_b\",\n",
    "            \"n_samples\",\n",
    "            \"n_features\",\n",
    "            \"n_informative\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Show results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353500a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
