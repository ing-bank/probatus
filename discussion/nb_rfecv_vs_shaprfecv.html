
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Validation of regressors and classifiers and data used to develop them">
      
      
        <meta name="author" content="ING Bank N. V.">
      
      
        <link rel="canonical" href="https://ing-bank.github.io/probatus/discussion/nb_rfecv_vs_shaprfecv.html">
      
      
        <link rel="prev" href="../api/utils.html">
      
      
        <link rel="next" href="../howto/grouped_data.html">
      
      
      <link rel="icon" href="../img/Probatus_P_white.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.29">
    
    
      
        <title>ShapRFECV vs sklearn RFECV - Probatus</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.76a95c52.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#shaprfecv-vs-sklearn-rfecv" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="Probatus" class="md-header__button md-logo" aria-label="Probatus" data-md-component="logo">
      
  <img src="../img/Probatus_P_white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Probatus
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ShapRFECV vs sklearn RFECV
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ing-bank/probatus/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../index.html" class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../api/feature_elimination.html" class="md-tabs__link">
          
  
  Api

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="nb_rfecv_vs_shaprfecv.html" class="md-tabs__link">
          
  
  Discussion

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../howto/grouped_data.html" class="md-tabs__link">
          
  
  Howto

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/nb_automatic_best_num_features.html" class="md-tabs__link">
          
  
  Tutorials

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Probatus" class="md-nav__button md-logo" aria-label="Probatus" data-md-component="logo">
      
  <img src="../img/Probatus_P_white.png" alt="logo">

    </a>
    Probatus
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ing-bank/probatus/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Api
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Api
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/feature_elimination.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Features Elimination
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/model_interpret.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Interpretation using SHAP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/sample_similarity.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sample Similarity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/utils.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utility Functions
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Discussion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Discussion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="nb_rfecv_vs_shaprfecv.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    ShapRFECV vs sklearn RFECV
  </span>
  

      </a>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Howto
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Howto
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../howto/grouped_data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to work with grouped data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../howto/reproducibility.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to ensure reproducibility of the results
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_automatic_best_num_features.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Feature selection techniques
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_custom_scoring.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom Scoring Metrics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_sample_similarity.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sample Similarity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_dependence.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap dependence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_feature_elimination.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ShapRFECV - Recursive Feature Elimination using SHAP importance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_model_interpreter.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tree Model Interpretation using SHAP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_variance_penalty_and_results_comparison.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap variance penalty
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<script>
(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :
    typeof define === 'function' && define.amd ? define(factory) :
    (global = global || self, global.ClipboardCopyElement = factory());
  }(this, function () { 'use strict';

    function createNode(text) {
      const node = document.createElement('pre');
      node.style.width = '1px';
      node.style.height = '1px';
      node.style.position = 'fixed';
      node.style.top = '5px';
      node.textContent = text;
      return node;
    }

    function copyNode(node) {
      if ('clipboard' in navigator) {
        // eslint-disable-next-line flowtype/no-flow-fix-me-comments
        // $FlowFixMe Clipboard is not defined in Flow yet.
        return navigator.clipboard.writeText(node.textContent);
      }

      const selection = getSelection();

      if (selection == null) {
        return Promise.reject(new Error());
      }

      selection.removeAllRanges();
      const range = document.createRange();
      range.selectNodeContents(node);
      selection.addRange(range);
      document.execCommand('copy');
      selection.removeAllRanges();
      return Promise.resolve();
    }
    function copyText(text) {
      if ('clipboard' in navigator) {
        // eslint-disable-next-line flowtype/no-flow-fix-me-comments
        // $FlowFixMe Clipboard is not defined in Flow yet.
        return navigator.clipboard.writeText(text);
      }

      const body = document.body;

      if (!body) {
        return Promise.reject(new Error());
      }

      const node = createNode(text);
      body.appendChild(node);
      copyNode(node);
      body.removeChild(node);
      return Promise.resolve();
    }

    function copy(button) {
      const id = button.getAttribute('for');
      const text = button.getAttribute('value');

      function trigger() {
        button.dispatchEvent(new CustomEvent('clipboard-copy', {
          bubbles: true
        }));
      }

      if (text) {
        copyText(text).then(trigger);
      } else if (id) {
        const root = 'getRootNode' in Element.prototype ? button.getRootNode() : button.ownerDocument;
        if (!(root instanceof Document || 'ShadowRoot' in window && root instanceof ShadowRoot)) return;
        const node = root.getElementById(id);
        if (node) copyTarget(node).then(trigger);
      }
    }

    function copyTarget(content) {
      if (content instanceof HTMLInputElement || content instanceof HTMLTextAreaElement) {
        return copyText(content.value);
      } else if (content instanceof HTMLAnchorElement && content.hasAttribute('href')) {
        return copyText(content.href);
      } else {
        return copyNode(content);
      }
    }

    function clicked(event) {
      const button = event.currentTarget;

      if (button instanceof HTMLElement) {
        copy(button);
      }
    }

    function keydown(event) {
      if (event.key === ' ' || event.key === 'Enter') {
        const button = event.currentTarget;

        if (button instanceof HTMLElement) {
          event.preventDefault();
          copy(button);
        }
      }
    }

    function focused(event) {
      event.currentTarget.addEventListener('keydown', keydown);
    }

    function blurred(event) {
      event.currentTarget.removeEventListener('keydown', keydown);
    }

    class ClipboardCopyElement extends HTMLElement {
      constructor() {
        super();
        this.addEventListener('click', clicked);
        this.addEventListener('focus', focused);
        this.addEventListener('blur', blurred);
      }

      connectedCallback() {
        if (!this.hasAttribute('tabindex')) {
          this.setAttribute('tabindex', '0');
        }

        if (!this.hasAttribute('role')) {
          this.setAttribute('role', 'button');
        }
      }

      get value() {
        return this.getAttribute('value') || '';
      }

      set value(text) {
        this.setAttribute('value', text);
      }

    }

    if (!window.customElements.get('clipboard-copy')) {
      window.ClipboardCopyElement = ClipboardCopyElement;
      window.customElements.define('clipboard-copy', ClipboardCopyElement);
    }

    return ClipboardCopyElement;

  }));
</script>
<script>
      document.addEventListener('clipboard-copy', function(event) {
        const notice = event.target.querySelector('.notice')
        notice.hidden = false
        setTimeout(function() {
          notice.hidden = true
        }, 1000)
      })
</script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight-ipynb .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight-ipynb { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight-ipynb .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight-ipynb .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight-ipynb .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight-ipynb .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight-ipynb .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight-ipynb .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight-ipynb .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight-ipynb .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight-ipynb .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight-ipynb .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight-ipynb .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight-ipynb .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight-ipynb .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight-ipynb .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight-ipynb .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight-ipynb .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight-ipynb .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight-ipynb .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight-ipynb .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight-ipynb .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight-ipynb .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight-ipynb .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight-ipynb .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight-ipynb .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight-ipynb .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight-ipynb .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight-ipynb .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight-ipynb .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight-ipynb .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight-ipynb .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight-ipynb .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight-ipynb .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight-ipynb .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight-ipynb .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight-ipynb .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight-ipynb .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight-ipynb .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight-ipynb .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight-ipynb .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight-ipynb .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight-ipynb .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
@charset "UTF-8";.jupyter-wrapper{--md-red-50: #ffebee;--md-red-100: #ffcdd2;--md-red-200: #ef9a9a;--md-red-300: #e57373;--md-red-400: #ef5350;--md-red-500: #f44336;--md-red-600: #e53935;--md-red-700: #d32f2f;--md-red-800: #c62828;--md-red-900: #b71c1c;--md-red-A100: #ff8a80;--md-red-A200: #ff5252;--md-red-A400: #ff1744;--md-red-A700: #d50000;--md-pink-50: #fce4ec;--md-pink-100: #f8bbd0;--md-pink-200: #f48fb1;--md-pink-300: #f06292;--md-pink-400: #ec407a;--md-pink-500: #e91e63;--md-pink-600: #d81b60;--md-pink-700: #c2185b;--md-pink-800: #ad1457;--md-pink-900: #880e4f;--md-pink-A100: #ff80ab;--md-pink-A200: #ff4081;--md-pink-A400: #f50057;--md-pink-A700: #c51162;--md-purple-50: #f3e5f5;--md-purple-100: #e1bee7;--md-purple-200: #ce93d8;--md-purple-300: #ba68c8;--md-purple-400: #ab47bc;--md-purple-500: #9c27b0;--md-purple-600: #8e24aa;--md-purple-700: #7b1fa2;--md-purple-800: #6a1b9a;--md-purple-900: #4a148c;--md-purple-A100: #ea80fc;--md-purple-A200: #e040fb;--md-purple-A400: #d500f9;--md-purple-A700: #aa00ff;--md-deep-purple-50: #ede7f6;--md-deep-purple-100: #d1c4e9;--md-deep-purple-200: #b39ddb;--md-deep-purple-300: #9575cd;--md-deep-purple-400: #7e57c2;--md-deep-purple-500: #673ab7;--md-deep-purple-600: #5e35b1;--md-deep-purple-700: #512da8;--md-deep-purple-800: #4527a0;--md-deep-purple-900: #311b92;--md-deep-purple-A100: #b388ff;--md-deep-purple-A200: #7c4dff;--md-deep-purple-A400: #651fff;--md-deep-purple-A700: #6200ea;--md-indigo-50: #e8eaf6;--md-indigo-100: #c5cae9;--md-indigo-200: #9fa8da;--md-indigo-300: #7986cb;--md-indigo-400: #5c6bc0;--md-indigo-500: #3f51b5;--md-indigo-600: #3949ab;--md-indigo-700: #303f9f;--md-indigo-800: #283593;--md-indigo-900: #1a237e;--md-indigo-A100: #8c9eff;--md-indigo-A200: #536dfe;--md-indigo-A400: #3d5afe;--md-indigo-A700: #304ffe;--md-blue-50: #e3f2fd;--md-blue-100: #bbdefb;--md-blue-200: #90caf9;--md-blue-300: #64b5f6;--md-blue-400: #42a5f5;--md-blue-500: #2196f3;--md-blue-600: #1e88e5;--md-blue-700: #1976d2;--md-blue-800: #1565c0;--md-blue-900: #0d47a1;--md-blue-A100: #82b1ff;--md-blue-A200: #448aff;--md-blue-A400: #2979ff;--md-blue-A700: #2962ff;--md-light-blue-50: #e1f5fe;--md-light-blue-100: #b3e5fc;--md-light-blue-200: #81d4fa;--md-light-blue-300: #4fc3f7;--md-light-blue-400: #29b6f6;--md-light-blue-500: #03a9f4;--md-light-blue-600: #039be5;--md-light-blue-700: #0288d1;--md-light-blue-800: #0277bd;--md-light-blue-900: #01579b;--md-light-blue-A100: #80d8ff;--md-light-blue-A200: #40c4ff;--md-light-blue-A400: #00b0ff;--md-light-blue-A700: #0091ea;--md-cyan-50: #e0f7fa;--md-cyan-100: #b2ebf2;--md-cyan-200: #80deea;--md-cyan-300: #4dd0e1;--md-cyan-400: #26c6da;--md-cyan-500: #00bcd4;--md-cyan-600: #00acc1;--md-cyan-700: #0097a7;--md-cyan-800: #00838f;--md-cyan-900: #006064;--md-cyan-A100: #84ffff;--md-cyan-A200: #18ffff;--md-cyan-A400: #00e5ff;--md-cyan-A700: #00b8d4;--md-teal-50: #e0f2f1;--md-teal-100: #b2dfdb;--md-teal-200: #80cbc4;--md-teal-300: #4db6ac;--md-teal-400: #26a69a;--md-teal-500: #009688;--md-teal-600: #00897b;--md-teal-700: #00796b;--md-teal-800: #00695c;--md-teal-900: #004d40;--md-teal-A100: #a7ffeb;--md-teal-A200: #64ffda;--md-teal-A400: #1de9b6;--md-teal-A700: #00bfa5;--md-green-50: #e8f5e9;--md-green-100: #c8e6c9;--md-green-200: #a5d6a7;--md-green-300: #81c784;--md-green-400: #66bb6a;--md-green-500: #4caf50;--md-green-600: #43a047;--md-green-700: #388e3c;--md-green-800: #2e7d32;--md-green-900: #1b5e20;--md-green-A100: #b9f6ca;--md-green-A200: #69f0ae;--md-green-A400: #00e676;--md-green-A700: #00c853;--md-light-green-50: #f1f8e9;--md-light-green-100: #dcedc8;--md-light-green-200: #c5e1a5;--md-light-green-300: #aed581;--md-light-green-400: #9ccc65;--md-light-green-500: #8bc34a;--md-light-green-600: #7cb342;--md-light-green-700: #689f38;--md-light-green-800: #558b2f;--md-light-green-900: #33691e;--md-light-green-A100: #ccff90;--md-light-green-A200: #b2ff59;--md-light-green-A400: #76ff03;--md-light-green-A700: #64dd17;--md-lime-50: #f9fbe7;--md-lime-100: #f0f4c3;--md-lime-200: #e6ee9c;--md-lime-300: #dce775;--md-lime-400: #d4e157;--md-lime-500: #cddc39;--md-lime-600: #c0ca33;--md-lime-700: #afb42b;--md-lime-800: #9e9d24;--md-lime-900: #827717;--md-lime-A100: #f4ff81;--md-lime-A200: #eeff41;--md-lime-A400: #c6ff00;--md-lime-A700: #aeea00;--md-yellow-50: #fffde7;--md-yellow-100: #fff9c4;--md-yellow-200: #fff59d;--md-yellow-300: #fff176;--md-yellow-400: #ffee58;--md-yellow-500: #ffeb3b;--md-yellow-600: #fdd835;--md-yellow-700: #fbc02d;--md-yellow-800: #f9a825;--md-yellow-900: #f57f17;--md-yellow-A100: #ffff8d;--md-yellow-A200: #ffff00;--md-yellow-A400: #ffea00;--md-yellow-A700: #ffd600;--md-amber-50: #fff8e1;--md-amber-100: #ffecb3;--md-amber-200: #ffe082;--md-amber-300: #ffd54f;--md-amber-400: #ffca28;--md-amber-500: #ffc107;--md-amber-600: #ffb300;--md-amber-700: #ffa000;--md-amber-800: #ff8f00;--md-amber-900: #ff6f00;--md-amber-A100: #ffe57f;--md-amber-A200: #ffd740;--md-amber-A400: #ffc400;--md-amber-A700: #ffab00;--md-orange-50: #fff3e0;--md-orange-100: #ffe0b2;--md-orange-200: #ffcc80;--md-orange-300: #ffb74d;--md-orange-400: #ffa726;--md-orange-500: #ff9800;--md-orange-600: #fb8c00;--md-orange-700: #f57c00;--md-orange-800: #ef6c00;--md-orange-900: #e65100;--md-orange-A100: #ffd180;--md-orange-A200: #ffab40;--md-orange-A400: #ff9100;--md-orange-A700: #ff6d00;--md-deep-orange-50: #fbe9e7;--md-deep-orange-100: #ffccbc;--md-deep-orange-200: #ffab91;--md-deep-orange-300: #ff8a65;--md-deep-orange-400: #ff7043;--md-deep-orange-500: #ff5722;--md-deep-orange-600: #f4511e;--md-deep-orange-700: #e64a19;--md-deep-orange-800: #d84315;--md-deep-orange-900: #bf360c;--md-deep-orange-A100: #ff9e80;--md-deep-orange-A200: #ff6e40;--md-deep-orange-A400: #ff3d00;--md-deep-orange-A700: #dd2c00;--md-brown-50: #efebe9;--md-brown-100: #d7ccc8;--md-brown-200: #bcaaa4;--md-brown-300: #a1887f;--md-brown-400: #8d6e63;--md-brown-500: #795548;--md-brown-600: #6d4c41;--md-brown-700: #5d4037;--md-brown-800: #4e342e;--md-brown-900: #3e2723;--md-grey-50: #fafafa;--md-grey-100: #f5f5f5;--md-grey-200: #eeeeee;--md-grey-300: #e0e0e0;--md-grey-400: #bdbdbd;--md-grey-500: #9e9e9e;--md-grey-600: #757575;--md-grey-700: #616161;--md-grey-800: #424242;--md-grey-900: #212121;--md-blue-grey-50: #eceff1;--md-blue-grey-100: #cfd8dc;--md-blue-grey-200: #b0bec5;--md-blue-grey-300: #90a4ae;--md-blue-grey-400: #78909c;--md-blue-grey-500: #607d8b;--md-blue-grey-600: #546e7a;--md-blue-grey-700: #455a64;--md-blue-grey-800: #37474f;--md-blue-grey-900: #263238}.jupyter-wrapper{--jp-shadow-base-lightness: 0;--jp-shadow-umbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .2 );--jp-shadow-penumbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .14 );--jp-shadow-ambient-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .12 );--jp-elevation-z0: none;--jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color), 0px 1px 1px 0px var(--jp-shadow-penumbra-color), 0px 1px 3px 0px var(--jp-shadow-ambient-color);--jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color), 0px 2px 2px 0px var(--jp-shadow-penumbra-color), 0px 1px 5px 0px var(--jp-shadow-ambient-color);--jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color), 0px 4px 5px 0px var(--jp-shadow-penumbra-color), 0px 1px 10px 0px var(--jp-shadow-ambient-color);--jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color), 0px 6px 10px 0px var(--jp-shadow-penumbra-color), 0px 1px 18px 0px var(--jp-shadow-ambient-color);--jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color), 0px 8px 10px 1px var(--jp-shadow-penumbra-color), 0px 3px 14px 2px var(--jp-shadow-ambient-color);--jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color), 0px 12px 17px 2px var(--jp-shadow-penumbra-color), 0px 5px 22px 4px var(--jp-shadow-ambient-color);--jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color), 0px 16px 24px 2px var(--jp-shadow-penumbra-color), 0px 6px 30px 5px var(--jp-shadow-ambient-color);--jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color), 0px 20px 31px 3px var(--jp-shadow-penumbra-color), 0px 8px 38px 7px var(--jp-shadow-ambient-color);--jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color), 0px 24px 38px 3px var(--jp-shadow-penumbra-color), 0px 9px 46px 8px var(--jp-shadow-ambient-color);--jp-border-width: 1px;--jp-border-color0: var(--md-grey-400);--jp-border-color1: var(--md-grey-400);--jp-border-color2: var(--md-grey-300);--jp-border-color3: var(--md-grey-200);--jp-inverse-border-color: var(--md-grey-600);--jp-border-radius: 2px;--jp-ui-font-scale-factor: 1.2;--jp-ui-font-size0: .83333em;--jp-ui-font-size1: 13px;--jp-ui-font-size2: 1.2em;--jp-ui-font-size3: 1.44em;--jp-ui-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-ui-font-color0: rgba(0, 0, 0, 1);--jp-ui-font-color1: rgba(0, 0, 0, .87);--jp-ui-font-color2: rgba(0, 0, 0, .54);--jp-ui-font-color3: rgba(0, 0, 0, .38);--jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);--jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);--jp-ui-inverse-font-color2: rgba(255, 255, 255, .7);--jp-ui-inverse-font-color3: rgba(255, 255, 255, .5);--jp-content-line-height: 1.6;--jp-content-font-scale-factor: 1.2;--jp-content-font-size0: .83333em;--jp-content-font-size1: 14px;--jp-content-font-size2: 1.2em;--jp-content-font-size3: 1.44em;--jp-content-font-size4: 1.728em;--jp-content-font-size5: 2.0736em;--jp-content-presentation-font-size1: 17px;--jp-content-heading-line-height: 1;--jp-content-heading-margin-top: 1.2em;--jp-content-heading-margin-bottom: .8em;--jp-content-heading-font-weight: 500;--jp-content-font-color0: rgba(0, 0, 0, 1);--jp-content-font-color1: rgba(0, 0, 0, .87);--jp-content-font-color2: rgba(0, 0, 0, .54);--jp-content-font-color3: rgba(0, 0, 0, .38);--jp-content-link-color: var(--md-blue-700);--jp-content-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-code-font-size: 13px;--jp-code-line-height: 1.3077;--jp-code-padding: 5px;--jp-code-font-family-default: Menlo, Consolas, "DejaVu Sans Mono", monospace;--jp-code-font-family: var(--jp-code-font-family-default);--jp-code-presentation-font-size: 16px;--jp-code-cursor-width0: 1.4px;--jp-code-cursor-width1: 2px;--jp-code-cursor-width2: 4px;--jp-layout-color0: white;--jp-layout-color1: white;--jp-layout-color2: var(--md-grey-200);--jp-layout-color3: var(--md-grey-400);--jp-layout-color4: var(--md-grey-600);--jp-inverse-layout-color0: #111111;--jp-inverse-layout-color1: var(--md-grey-900);--jp-inverse-layout-color2: var(--md-grey-800);--jp-inverse-layout-color3: var(--md-grey-700);--jp-inverse-layout-color4: var(--md-grey-600);--jp-brand-color0: var(--md-blue-900);--jp-brand-color1: var(--md-blue-700);--jp-brand-color2: var(--md-blue-300);--jp-brand-color3: var(--md-blue-100);--jp-brand-color4: var(--md-blue-50);--jp-accent-color0: var(--md-green-900);--jp-accent-color1: var(--md-green-700);--jp-accent-color2: var(--md-green-300);--jp-accent-color3: var(--md-green-100);--jp-warn-color0: var(--md-orange-900);--jp-warn-color1: var(--md-orange-700);--jp-warn-color2: var(--md-orange-300);--jp-warn-color3: var(--md-orange-100);--jp-error-color0: var(--md-red-900);--jp-error-color1: var(--md-red-700);--jp-error-color2: var(--md-red-300);--jp-error-color3: var(--md-red-100);--jp-success-color0: var(--md-green-900);--jp-success-color1: var(--md-green-700);--jp-success-color2: var(--md-green-300);--jp-success-color3: var(--md-green-100);--jp-info-color0: var(--md-cyan-900);--jp-info-color1: var(--md-cyan-700);--jp-info-color2: var(--md-cyan-300);--jp-info-color3: var(--md-cyan-100);--jp-cell-padding: 5px;--jp-cell-collapser-width: 8px;--jp-cell-collapser-min-height: 20px;--jp-cell-collapser-not-active-hover-opacity: .6;--jp-cell-editor-background: var(--md-grey-100);--jp-cell-editor-border-color: var(--md-grey-300);--jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-cell-editor-active-background: var(--jp-layout-color0);--jp-cell-editor-active-border-color: var(--jp-brand-color1);--jp-cell-prompt-width: 64px;--jp-cell-prompt-font-family: var(--jp-code-font-family-default);--jp-cell-prompt-letter-spacing: 0px;--jp-cell-prompt-opacity: 1;--jp-cell-prompt-not-active-opacity: .5;--jp-cell-prompt-not-active-font-color: var(--md-grey-700);--jp-cell-inprompt-font-color: #307fc1;--jp-cell-outprompt-font-color: #bf5b3d;--jp-notebook-padding: 10px;--jp-notebook-select-background: var(--jp-layout-color1);--jp-notebook-multiselected-color: var(--md-blue-50);--jp-notebook-scroll-padding: calc( 100% - var(--jp-code-font-size) * var(--jp-code-line-height) - var(--jp-code-padding) - var(--jp-cell-padding) - 1px );--jp-rendermime-error-background: #fdd;--jp-rendermime-table-row-background: var(--md-grey-100);--jp-rendermime-table-row-hover-background: var(--md-light-blue-50);--jp-dialog-background: rgba(0, 0, 0, .25);--jp-console-padding: 10px;--jp-toolbar-border-color: var(--jp-border-color1);--jp-toolbar-micro-height: 8px;--jp-toolbar-background: var(--jp-layout-color1);--jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, .24);--jp-toolbar-header-margin: 4px 4px 0px 4px;--jp-toolbar-active-background: var(--md-grey-300);--jp-statusbar-height: 24px;--jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-input-active-background: var(--jp-layout-color1);--jp-input-hover-background: var(--jp-layout-color1);--jp-input-background: var(--md-grey-100);--jp-input-border-color: var(--jp-inverse-border-color);--jp-input-active-border-color: var(--jp-brand-color1);--jp-input-active-box-shadow-color: rgba(19, 124, 189, .3);--jp-editor-selected-background: #d9d9d9;--jp-editor-selected-focused-background: #d7d4f0;--jp-editor-cursor-color: var(--jp-ui-font-color0);--jp-mirror-editor-keyword-color: #008000;--jp-mirror-editor-atom-color: #88f;--jp-mirror-editor-number-color: #080;--jp-mirror-editor-def-color: #00f;--jp-mirror-editor-variable-color: var(--md-grey-900);--jp-mirror-editor-variable-2-color: #05a;--jp-mirror-editor-variable-3-color: #085;--jp-mirror-editor-punctuation-color: #05a;--jp-mirror-editor-property-color: #05a;--jp-mirror-editor-operator-color: #aa22ff;--jp-mirror-editor-comment-color: #408080;--jp-mirror-editor-string-color: #ba2121;--jp-mirror-editor-string-2-color: #708;--jp-mirror-editor-meta-color: #aa22ff;--jp-mirror-editor-qualifier-color: #555;--jp-mirror-editor-builtin-color: #008000;--jp-mirror-editor-bracket-color: #997;--jp-mirror-editor-tag-color: #170;--jp-mirror-editor-attribute-color: #00c;--jp-mirror-editor-header-color: blue;--jp-mirror-editor-quote-color: #090;--jp-mirror-editor-link-color: #00c;--jp-mirror-editor-error-color: #f00;--jp-mirror-editor-hr-color: #999;--jp-collaborator-color1: #ffad8e;--jp-collaborator-color2: #dac83d;--jp-collaborator-color3: #72dd76;--jp-collaborator-color4: #00e4d0;--jp-collaborator-color5: #45d4ff;--jp-collaborator-color6: #e2b1ff;--jp-collaborator-color7: #ff9de6;--jp-vega-background: white;--jp-sidebar-min-width: 250px;--jp-search-toggle-off-opacity: .5;--jp-search-toggle-hover-opacity: .8;--jp-search-toggle-on-opacity: 1;--jp-search-selected-match-background-color: rgb(245, 200, 0);--jp-search-selected-match-color: black;--jp-search-unselected-match-background-color: var( --jp-inverse-layout-color0 );--jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);--jp-icon-contrast-color0: var(--md-purple-600);--jp-icon-contrast-color1: var(--md-green-600);--jp-icon-contrast-color2: var(--md-pink-600);--jp-icon-contrast-color3: var(--md-blue-600);--jp-jupyter-icon-color: #f37626;--jp-notebook-icon-color: #f37626;--jp-json-icon-color: var(--md-orange-700);--jp-console-icon-background-color: var(--md-blue-700);--jp-console-icon-color: white;--jp-terminal-icon-background-color: var(--md-grey-800);--jp-terminal-icon-color: var(--md-grey-200);--jp-text-editor-icon-color: var(--md-grey-700);--jp-inspector-icon-color: var(--md-grey-700);--jp-switch-color: var(--md-grey-400);--jp-switch-true-position-color: var(--md-orange-900)}[data-md-color-scheme=slate] .jupyter-wrapper{--jp-shadow-base-lightness: 32;--jp-shadow-umbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .2 );--jp-shadow-penumbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .14 );--jp-shadow-ambient-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .12 );--jp-elevation-z0: none;--jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color), 0px 1px 1px 0px var(--jp-shadow-penumbra-color), 0px 1px 3px 0px var(--jp-shadow-ambient-color);--jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color), 0px 2px 2px 0px var(--jp-shadow-penumbra-color), 0px 1px 5px 0px var(--jp-shadow-ambient-color);--jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color), 0px 4px 5px 0px var(--jp-shadow-penumbra-color), 0px 1px 10px 0px var(--jp-shadow-ambient-color);--jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color), 0px 6px 10px 0px var(--jp-shadow-penumbra-color), 0px 1px 18px 0px var(--jp-shadow-ambient-color);--jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color), 0px 8px 10px 1px var(--jp-shadow-penumbra-color), 0px 3px 14px 2px var(--jp-shadow-ambient-color);--jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color), 0px 12px 17px 2px var(--jp-shadow-penumbra-color), 0px 5px 22px 4px var(--jp-shadow-ambient-color);--jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color), 0px 16px 24px 2px var(--jp-shadow-penumbra-color), 0px 6px 30px 5px var(--jp-shadow-ambient-color);--jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color), 0px 20px 31px 3px var(--jp-shadow-penumbra-color), 0px 8px 38px 7px var(--jp-shadow-ambient-color);--jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color), 0px 24px 38px 3px var(--jp-shadow-penumbra-color), 0px 9px 46px 8px var(--jp-shadow-ambient-color);--jp-border-width: 1px;--jp-border-color0: var(--md-grey-700);--jp-border-color1: var(--md-grey-700);--jp-border-color2: var(--md-grey-800);--jp-border-color3: var(--md-grey-900);--jp-inverse-border-color: var(--md-grey-600);--jp-border-radius: 2px;--jp-ui-font-scale-factor: 1.2;--jp-ui-font-size0: .83333em;--jp-ui-font-size1: 13px;--jp-ui-font-size2: 1.2em;--jp-ui-font-size3: 1.44em;--jp-ui-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-ui-font-color0: rgba(255, 255, 255, 1);--jp-ui-font-color1: rgba(255, 255, 255, .87);--jp-ui-font-color2: rgba(255, 255, 255, .54);--jp-ui-font-color3: rgba(255, 255, 255, .38);--jp-ui-inverse-font-color0: rgba(0, 0, 0, 1);--jp-ui-inverse-font-color1: rgba(0, 0, 0, .8);--jp-ui-inverse-font-color2: rgba(0, 0, 0, .5);--jp-ui-inverse-font-color3: rgba(0, 0, 0, .3);--jp-content-line-height: 1.6;--jp-content-font-scale-factor: 1.2;--jp-content-font-size0: .83333em;--jp-content-font-size1: 14px;--jp-content-font-size2: 1.2em;--jp-content-font-size3: 1.44em;--jp-content-font-size4: 1.728em;--jp-content-font-size5: 2.0736em;--jp-content-presentation-font-size1: 17px;--jp-content-heading-line-height: 1;--jp-content-heading-margin-top: 1.2em;--jp-content-heading-margin-bottom: .8em;--jp-content-heading-font-weight: 500;--jp-content-font-color0: rgba(255, 255, 255, 1);--jp-content-font-color1: rgba(255, 255, 255, 1);--jp-content-font-color2: rgba(255, 255, 255, .7);--jp-content-font-color3: rgba(255, 255, 255, .5);--jp-content-link-color: var(--md-blue-300);--jp-content-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-code-font-size: 13px;--jp-code-line-height: 1.3077;--jp-code-padding: 5px;--jp-code-font-family-default: Menlo, Consolas, "DejaVu Sans Mono", monospace;--jp-code-font-family: var(--jp-code-font-family-default);--jp-code-presentation-font-size: 16px;--jp-code-cursor-width0: 1.4px;--jp-code-cursor-width1: 2px;--jp-code-cursor-width2: 4px;--jp-layout-color0: #111111;--jp-layout-color1: var(--md-grey-900);--jp-layout-color2: var(--md-grey-800);--jp-layout-color3: var(--md-grey-700);--jp-layout-color4: var(--md-grey-600);--jp-inverse-layout-color0: white;--jp-inverse-layout-color1: white;--jp-inverse-layout-color2: var(--md-grey-200);--jp-inverse-layout-color3: var(--md-grey-400);--jp-inverse-layout-color4: var(--md-grey-600);--jp-brand-color0: var(--md-blue-700);--jp-brand-color1: var(--md-blue-500);--jp-brand-color2: var(--md-blue-300);--jp-brand-color3: var(--md-blue-100);--jp-brand-color4: var(--md-blue-50);--jp-accent-color0: var(--md-green-700);--jp-accent-color1: var(--md-green-500);--jp-accent-color2: var(--md-green-300);--jp-accent-color3: var(--md-green-100);--jp-warn-color0: var(--md-orange-700);--jp-warn-color1: var(--md-orange-500);--jp-warn-color2: var(--md-orange-300);--jp-warn-color3: var(--md-orange-100);--jp-error-color0: var(--md-red-700);--jp-error-color1: var(--md-red-500);--jp-error-color2: var(--md-red-300);--jp-error-color3: var(--md-red-100);--jp-success-color0: var(--md-green-700);--jp-success-color1: var(--md-green-500);--jp-success-color2: var(--md-green-300);--jp-success-color3: var(--md-green-100);--jp-info-color0: var(--md-cyan-700);--jp-info-color1: var(--md-cyan-500);--jp-info-color2: var(--md-cyan-300);--jp-info-color3: var(--md-cyan-100);--jp-cell-padding: 5px;--jp-cell-collapser-width: 8px;--jp-cell-collapser-min-height: 20px;--jp-cell-collapser-not-active-hover-opacity: .6;--jp-cell-editor-background: var(--jp-layout-color1);--jp-cell-editor-border-color: var(--md-grey-700);--jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-cell-editor-active-background: var(--jp-layout-color0);--jp-cell-editor-active-border-color: var(--jp-brand-color1);--jp-cell-prompt-width: 64px;--jp-cell-prompt-font-family: var(--jp-code-font-family-default);--jp-cell-prompt-letter-spacing: 0px;--jp-cell-prompt-opacity: 1;--jp-cell-prompt-not-active-opacity: 1;--jp-cell-prompt-not-active-font-color: var(--md-grey-300);--jp-cell-inprompt-font-color: #307fc1;--jp-cell-outprompt-font-color: #bf5b3d;--jp-notebook-padding: 10px;--jp-notebook-select-background: var(--jp-layout-color1);--jp-notebook-multiselected-color: rgba(33, 150, 243, .24);--jp-notebook-scroll-padding: calc( 100% - var(--jp-code-font-size) * var(--jp-code-line-height) - var(--jp-code-padding) - var(--jp-cell-padding) - 1px );--jp-rendermime-error-background: rgba(244, 67, 54, .28);--jp-rendermime-table-row-background: var(--md-grey-900);--jp-rendermime-table-row-hover-background: rgba(3, 169, 244, .2);--jp-dialog-background: rgba(0, 0, 0, .6);--jp-console-padding: 10px;--jp-toolbar-border-color: var(--jp-border-color2);--jp-toolbar-micro-height: 8px;--jp-toolbar-background: var(--jp-layout-color1);--jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, .8);--jp-toolbar-header-margin: 4px 4px 0px 4px;--jp-toolbar-active-background: var(--jp-layout-color0);--jp-statusbar-height: 24px;--jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-input-active-background: var(--jp-layout-color0);--jp-input-hover-background: var(--jp-layout-color2);--jp-input-background: var(--md-grey-800);--jp-input-border-color: var(--jp-inverse-border-color);--jp-input-active-border-color: var(--jp-brand-color1);--jp-input-active-box-shadow-color: rgba(19, 124, 189, .3);--jp-editor-selected-background: var(--jp-layout-color2);--jp-editor-selected-focused-background: rgba(33, 150, 243, .24);--jp-editor-cursor-color: var(--jp-ui-font-color0);--jp-mirror-editor-keyword-color: var(--md-green-500);--jp-mirror-editor-atom-color: var(--md-blue-300);--jp-mirror-editor-number-color: var(--md-green-400);--jp-mirror-editor-def-color: var(--md-blue-600);--jp-mirror-editor-variable-color: var(--md-grey-300);--jp-mirror-editor-variable-2-color: var(--md-blue-400);--jp-mirror-editor-variable-3-color: var(--md-green-600);--jp-mirror-editor-punctuation-color: var(--md-blue-400);--jp-mirror-editor-property-color: var(--md-blue-400);--jp-mirror-editor-operator-color: #aa22ff;--jp-mirror-editor-comment-color: #408080;--jp-mirror-editor-string-color: #ff7070;--jp-mirror-editor-string-2-color: var(--md-purple-300);--jp-mirror-editor-meta-color: #aa22ff;--jp-mirror-editor-qualifier-color: #555;--jp-mirror-editor-builtin-color: var(--md-green-600);--jp-mirror-editor-bracket-color: #997;--jp-mirror-editor-tag-color: var(--md-green-700);--jp-mirror-editor-attribute-color: var(--md-blue-700);--jp-mirror-editor-header-color: var(--md-blue-500);--jp-mirror-editor-quote-color: var(--md-green-300);--jp-mirror-editor-link-color: var(--md-blue-700);--jp-mirror-editor-error-color: #f00;--jp-mirror-editor-hr-color: #999;--jp-collaborator-color1: #ad4a00;--jp-collaborator-color2: #7b6a00;--jp-collaborator-color3: #007e00;--jp-collaborator-color4: #008772;--jp-collaborator-color5: #0079b9;--jp-collaborator-color6: #8b45c6;--jp-collaborator-color7: #be208b;--jp-vega-background: var(--md-grey-400);--jp-sidebar-min-width: 250px;--jp-search-toggle-off-opacity: .6;--jp-search-toggle-hover-opacity: .8;--jp-search-toggle-on-opacity: 1;--jp-search-selected-match-background-color: rgb(255, 225, 0);--jp-search-selected-match-color: black;--jp-search-unselected-match-background-color: var( --jp-inverse-layout-color0 );--jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);--jp-scrollbar-background-color: #3f4244;--jp-scrollbar-thumb-color: 88, 96, 97;--jp-scrollbar-endpad: 3px;--jp-scrollbar-thumb-margin: 3.5px;--jp-scrollbar-thumb-radius: 9px;--jp-icon-contrast-color0: var(--md-purple-600);--jp-icon-contrast-color1: var(--md-green-600);--jp-icon-contrast-color2: var(--md-pink-600);--jp-icon-contrast-color3: var(--md-blue-600);--jp-jupyter-icon-color: #f37626;--jp-notebook-icon-color: #f37626;--jp-json-icon-color: var(--md-orange-500);--jp-console-icon-background-color: var(--md-blue-500);--jp-console-icon-color: white;--jp-terminal-icon-background-color: var(--md-grey-200);--jp-terminal-icon-color: var(--md-grey-800);--jp-text-editor-icon-color: var(--md-grey-200);--jp-inspector-icon-color: var(--md-grey-200);--jp-switch-color: var(--md-grey-400);--jp-switch-true-position-color: var(--md-orange-700)}.jupyter-wrapper [data-jp-theme-scrollbars=true]{scrollbar-color:rgb(var(--jp-scrollbar-thumb-color)) var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar{scrollbar-color:rgba(var(--jp-scrollbar-thumb-color),.5) transparent}.jupyter-wrapper .jp-scrollbar-tiny{scrollbar-color:rgba(var(--jp-scrollbar-thumb-color),.5) transparent;scrollbar-width:thin}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-corner{background:var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-thumb{background:rgb(var(--jp-scrollbar-thumb-color));border:var(--jp-scrollbar-thumb-margin) solid transparent;background-clip:content-box;border-radius:var(--jp-scrollbar-thumb-radius)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-track:horizontal{border-left:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color);border-right:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-track:vertical{border-top:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color);border-bottom:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-corner,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-corner{background-color:transparent}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-thumb{background:rgba(var(--jp-scrollbar-thumb-color),.5);border:var(--jp-scrollbar-thumb-margin) solid transparent;background-clip:content-box;border-radius:var(--jp-scrollbar-thumb-radius)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal{border-left:var(--jp-scrollbar-endpad) solid transparent;border-right:var(--jp-scrollbar-endpad) solid transparent}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical{border-top:var(--jp-scrollbar-endpad) solid transparent;border-bottom:var(--jp-scrollbar-endpad) solid transparent}.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar,.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar-corner{background-color:transparent;height:4px;width:4px}.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar-thumb{background:rgba(var(--jp-scrollbar-thumb-color),.5)}.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal{border-left:0px solid transparent;border-right:0px solid transparent}.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar-track:vertical{border-top:0px solid transparent;border-bottom:0px solid transparent}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal]{min-height:16px;max-height:16px;min-width:45px;border-top:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical]{min-width:16px;max-width:16px;min-height:45px;border-left:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar-button{background-color:#f0f0f0;background-position:center center;min-height:15px;max-height:15px;min-width:15px;max-width:15px}.jupyter-wrapper .lm-ScrollBar-button:hover{background-color:#dadada}.jupyter-wrapper .lm-ScrollBar-button.lm-mod-active{background-color:#cdcdcd}.jupyter-wrapper .lm-ScrollBar-track{background:#f0f0f0}.jupyter-wrapper .lm-ScrollBar-thumb{background:#cdcdcd}.jupyter-wrapper .lm-ScrollBar-thumb:hover{background:#bababa}.jupyter-wrapper .lm-ScrollBar-thumb.lm-mod-active{background:#a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-thumb{height:100%;min-width:15px;border-left:1px solid #a0a0a0;border-right:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-thumb{width:100%;min-height:15px;border-top:1px solid #a0a0a0;border-bottom:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-button[data-action=decrement]{background-image:var(--jp-icon-caret-left);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-button[data-action=increment]{background-image:var(--jp-icon-caret-right);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-button[data-action=decrement]{background-image:var(--jp-icon-caret-up);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-button[data-action=increment]{background-image:var(--jp-icon-caret-down);background-size:17px}.jupyter-wrapper .p-Widget,.jupyter-wrapper .lm-Widget{box-sizing:border-box;position:relative;overflow:hidden;cursor:default}.jupyter-wrapper .p-Widget.p-mod-hidden,.jupyter-wrapper .lm-Widget.lm-mod-hidden{display:none!important}.jupyter-wrapper .lm-AccordionPanel[data-orientation=horizontal]>.lm-AccordionPanel-title{display:block;transform-origin:top left;transform:rotate(-90deg) translate(-100%)}.jupyter-wrapper .p-CommandPalette,.jupyter-wrapper .lm-CommandPalette{display:flex;flex-direction:column;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-CommandPalette-search,.jupyter-wrapper .lm-CommandPalette-search{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-content,.jupyter-wrapper .lm-CommandPalette-content{flex:1 1 auto;margin:0;padding:0;min-height:0;overflow:auto;list-style-type:none}.jupyter-wrapper .p-CommandPalette-header,.jupyter-wrapper .lm-CommandPalette-header{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .p-CommandPalette-item,.jupyter-wrapper .lm-CommandPalette-item{display:flex;flex-direction:row}.jupyter-wrapper .p-CommandPalette-itemIcon,.jupyter-wrapper .lm-CommandPalette-itemIcon{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-itemContent,.jupyter-wrapper .lm-CommandPalette-itemContent{flex:1 1 auto;overflow:hidden}.jupyter-wrapper .p-CommandPalette-itemShortcut,.jupyter-wrapper .lm-CommandPalette-itemShortcut{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-itemLabel,.jupyter-wrapper .lm-CommandPalette-itemLabel{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .lm-close-icon{border:1px solid transparent;background-color:transparent;position:absolute;z-index:1;right:3%;top:0;bottom:0;margin:auto;padding:7px 0;display:none;vertical-align:middle;outline:0;cursor:pointer}.jupyter-wrapper .lm-close-icon:after{content:"X";display:block;width:15px;height:15px;text-align:center;color:#000;font-weight:400;font-size:12px;cursor:pointer}.jupyter-wrapper .p-DockPanel,.jupyter-wrapper .lm-DockPanel,.jupyter-wrapper .p-DockPanel-widget,.jupyter-wrapper .lm-DockPanel-widget{z-index:0}.jupyter-wrapper .p-DockPanel-tabBar,.jupyter-wrapper .lm-DockPanel-tabBar{z-index:1}.jupyter-wrapper .p-DockPanel-handle,.jupyter-wrapper .lm-DockPanel-handle{z-index:2}.jupyter-wrapper .p-DockPanel-handle.p-mod-hidden,.jupyter-wrapper .lm-DockPanel-handle.lm-mod-hidden{display:none!important}.jupyter-wrapper .p-DockPanel-handle:after,.jupyter-wrapper .lm-DockPanel-handle:after{position:absolute;top:0;left:0;width:100%;height:100%;content:""}.jupyter-wrapper .p-DockPanel-handle[data-orientation=horizontal],.jupyter-wrapper .lm-DockPanel-handle[data-orientation=horizontal]{cursor:ew-resize}.jupyter-wrapper .p-DockPanel-handle[data-orientation=vertical],.jupyter-wrapper .lm-DockPanel-handle[data-orientation=vertical]{cursor:ns-resize}.jupyter-wrapper .p-DockPanel-handle[data-orientation=horizontal]:after,.jupyter-wrapper .lm-DockPanel-handle[data-orientation=horizontal]:after{left:50%;min-width:8px;transform:translate(-50%)}.jupyter-wrapper .p-DockPanel-handle[data-orientation=vertical]:after,.jupyter-wrapper .lm-DockPanel-handle[data-orientation=vertical]:after{top:50%;min-height:8px;transform:translateY(-50%)}.jupyter-wrapper .p-DockPanel-overlay,.jupyter-wrapper .lm-DockPanel-overlay{z-index:3;box-sizing:border-box;pointer-events:none}.jupyter-wrapper .p-DockPanel-overlay.p-mod-hidden,.jupyter-wrapper .lm-DockPanel-overlay.lm-mod-hidden{display:none!important}.jupyter-wrapper .p-Menu,.jupyter-wrapper .lm-Menu{z-index:10000;position:absolute;white-space:nowrap;overflow-x:hidden;overflow-y:auto;outline:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-Menu-content,.jupyter-wrapper .lm-Menu-content{margin:0;padding:0;display:table;list-style-type:none}.jupyter-wrapper .p-Menu-item,.jupyter-wrapper .lm-Menu-item{display:table-row}.jupyter-wrapper .p-Menu-item.p-mod-hidden,.jupyter-wrapper .p-Menu-item.p-mod-collapsed,.jupyter-wrapper .lm-Menu-item.lm-mod-hidden,.jupyter-wrapper .lm-Menu-item.lm-mod-collapsed{display:none!important}.jupyter-wrapper .p-Menu-itemIcon,.jupyter-wrapper .p-Menu-itemSubmenuIcon,.jupyter-wrapper .lm-Menu-itemIcon,.jupyter-wrapper .lm-Menu-itemSubmenuIcon{display:table-cell;text-align:center}.jupyter-wrapper .p-Menu-itemLabel,.jupyter-wrapper .lm-Menu-itemLabel{display:table-cell;text-align:left}.jupyter-wrapper .p-Menu-itemShortcut,.jupyter-wrapper .lm-Menu-itemShortcut{display:table-cell;text-align:right}.jupyter-wrapper .p-MenuBar,.jupyter-wrapper .lm-MenuBar{outline:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-MenuBar-content,.jupyter-wrapper .lm-MenuBar-content{margin:0;padding:0;display:flex;flex-direction:row;list-style-type:none}.jupyter-wrapper .p--MenuBar-item,.jupyter-wrapper .lm-MenuBar-item{box-sizing:border-box}.jupyter-wrapper .p-MenuBar-itemIcon,.jupyter-wrapper .p-MenuBar-itemLabel,.jupyter-wrapper .lm-MenuBar-itemIcon,.jupyter-wrapper .lm-MenuBar-itemLabel{display:inline-block}.jupyter-wrapper .p-ScrollBar,.jupyter-wrapper .lm-ScrollBar{display:flex;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-ScrollBar[data-orientation=horizontal],.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal]{flex-direction:row}.jupyter-wrapper .p-ScrollBar[data-orientation=vertical],.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical]{flex-direction:column}.jupyter-wrapper .p-ScrollBar-button,.jupyter-wrapper .lm-ScrollBar-button{box-sizing:border-box;flex:0 0 auto}.jupyter-wrapper .p-ScrollBar-track,.jupyter-wrapper .lm-ScrollBar-track{box-sizing:border-box;position:relative;overflow:hidden;flex:1 1 auto}.jupyter-wrapper .p-ScrollBar-thumb,.jupyter-wrapper .lm-ScrollBar-thumb{box-sizing:border-box;position:absolute}.jupyter-wrapper .p-SplitPanel-child,.jupyter-wrapper .lm-SplitPanel-child{z-index:0}.jupyter-wrapper .p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel-handle{z-index:1}.jupyter-wrapper .p-SplitPanel-handle.p-mod-hidden,.jupyter-wrapper .lm-SplitPanel-handle.lm-mod-hidden{display:none!important}.jupyter-wrapper .p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel-handle:after{position:absolute;top:0;left:0;width:100%;height:100%;content:""}.jupyter-wrapper .p-SplitPanel[data-orientation=horizontal]>.p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel[data-orientation=horizontal]>.lm-SplitPanel-handle{cursor:ew-resize}.jupyter-wrapper .p-SplitPanel[data-orientation=vertical]>.p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel[data-orientation=vertical]>.lm-SplitPanel-handle{cursor:ns-resize}.jupyter-wrapper .p-SplitPanel[data-orientation=horizontal]>.p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel[data-orientation=horizontal]>.lm-SplitPanel-handle:after{left:50%;min-width:8px;transform:translate(-50%)}.jupyter-wrapper .p-SplitPanel[data-orientation=vertical]>.p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel[data-orientation=vertical]>.lm-SplitPanel-handle:after{top:50%;min-height:8px;transform:translateY(-50%)}.jupyter-wrapper .p-TabBar,.jupyter-wrapper .lm-TabBar{display:flex;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-TabBar[data-orientation=horizontal],.jupyter-wrapper .lm-TabBar[data-orientation=horizontal]{flex-direction:row;align-items:flex-end}.jupyter-wrapper .p-TabBar[data-orientation=vertical],.jupyter-wrapper .lm-TabBar[data-orientation=vertical]{flex-direction:column;align-items:flex-end}.jupyter-wrapper .p-TabBar-content,.jupyter-wrapper .lm-TabBar-content{margin:0;padding:0;display:flex;flex:1 1 auto;list-style-type:none}.jupyter-wrapper .p-TabBar[data-orientation=horizontal]>.p-TabBar-content,.jupyter-wrapper .lm-TabBar[data-orientation=horizontal]>.lm-TabBar-content{flex-direction:row}.jupyter-wrapper .p-TabBar[data-orientation=vertical]>.p-TabBar-content,.jupyter-wrapper .lm-TabBar[data-orientation=vertical]>.lm-TabBar-content{flex-direction:column}.jupyter-wrapper .p-TabBar-tab,.jupyter-wrapper .lm-TabBar-tab{display:flex;flex-direction:row;box-sizing:border-box;overflow:hidden;touch-action:none}.jupyter-wrapper .p-TabBar-tabIcon,.jupyter-wrapper .p-TabBar-tabCloseIcon,.jupyter-wrapper .lm-TabBar-tabIcon,.jupyter-wrapper .lm-TabBar-tabCloseIcon{flex:0 0 auto}.jupyter-wrapper .p-TabBar-tabLabel,.jupyter-wrapper .lm-TabBar-tabLabel{flex:1 1 auto;overflow:hidden;white-space:nowrap}.jupyter-wrapper .lm-TabBar-tabInput{-webkit-user-select:all;user-select:all;width:100%;box-sizing:border-box}.jupyter-wrapper .p-TabBar-tab.p-mod-hidden,.jupyter-wrapper .lm-TabBar-tab.lm-mod-hidden,.jupyter-wrapper .lm-TabBar-addButton.lm-mod-hidden{display:none!important}.jupyter-wrapper .p-TabBar.p-mod-dragging .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging .lm-TabBar-tab{position:relative}.jupyter-wrapper .p-TabBar.p-mod-dragging[data-orientation=horizontal] .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging[data-orientation=horizontal] .lm-TabBar-tab{left:0;transition:left .15s ease}.jupyter-wrapper .p-TabBar.p-mod-dragging[data-orientation=vertical] .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging[data-orientation=vertical] .lm-TabBar-tab{top:0;transition:top .15s ease}.jupyter-wrapper .p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging,.jupyter-wrapper .lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging{transition:none}.jupyter-wrapper .lm-TabBar-tabLabel .lm-TabBar-tabInput{-webkit-user-select:all;user-select:all;width:100%;box-sizing:border-box;background:inherit}.jupyter-wrapper .p-TabPanel-tabBar,.jupyter-wrapper .lm-TabPanel-tabBar{z-index:1}.jupyter-wrapper .p-TabPanel-stackedPanel,.jupyter-wrapper .lm-TabPanel-stackedPanel{z-index:0}.jupyter-wrapper html{-webkit-box-sizing:border-box;box-sizing:border-box}.jupyter-wrapper *,.jupyter-wrapper *:before,.jupyter-wrapper *:after{-webkit-box-sizing:inherit;box-sizing:inherit}.jupyter-wrapper body{font-size:14px;font-weight:400;letter-spacing:0;line-height:1.28581;text-transform:none;color:#182026;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,Icons16,sans-serif}.jupyter-wrapper p{margin-bottom:10px;margin-top:0}.jupyter-wrapper small{font-size:12px}.jupyter-wrapper strong{font-weight:600}.jupyter-wrapper ::-moz-selection{background:rgba(125,188,255,.6)}.jupyter-wrapper ::selection{background:rgba(125,188,255,.6)}.jupyter-wrapper .bp3-heading{color:#182026;font-weight:600;margin:0 0 10px;padding:0}.jupyter-wrapper .bp3-dark .bp3-heading{color:#f5f8fa}.jupyter-wrapper h1.bp3-heading,.jupyter-wrapper .bp3-running-text h1{font-size:36px;line-height:40px}.jupyter-wrapper h2.bp3-heading,.jupyter-wrapper .bp3-running-text h2{font-size:28px;line-height:32px}.jupyter-wrapper h3.bp3-heading,.jupyter-wrapper .bp3-running-text h3{font-size:22px;line-height:25px}.jupyter-wrapper h4.bp3-heading,.jupyter-wrapper .bp3-running-text h4{font-size:18px;line-height:21px}.jupyter-wrapper h5.bp3-heading,.jupyter-wrapper .bp3-running-text h5{font-size:16px;line-height:19px}.jupyter-wrapper h6.bp3-heading,.jupyter-wrapper .bp3-running-text h6{font-size:14px;line-height:16px}.jupyter-wrapper .bp3-ui-text{font-size:14px;font-weight:400;letter-spacing:0;line-height:1.28581;text-transform:none}.jupyter-wrapper .bp3-monospace-text{font-family:monospace;text-transform:none}.jupyter-wrapper .bp3-text-muted{color:#5c7080}.jupyter-wrapper .bp3-dark .bp3-text-muted{color:#a7b6c2}.jupyter-wrapper .bp3-text-disabled{color:#5c708099}.jupyter-wrapper .bp3-dark .bp3-text-disabled{color:#a7b6c299}.jupyter-wrapper .bp3-text-overflow-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal}.jupyter-wrapper .bp3-running-text{font-size:14px;line-height:1.5}.jupyter-wrapper .bp3-running-text h1{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h1{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h2{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h2{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h3{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h3{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h4{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h4{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h5{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h5{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h6{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h6{color:#f5f8fa}.jupyter-wrapper .bp3-running-text hr{border:none;border-bottom:1px solid rgba(16,22,26,.15);margin:20px 0}.jupyter-wrapper .bp3-dark .bp3-running-text hr{border-color:#ffffff26}.jupyter-wrapper .bp3-running-text p{margin:0 0 10px;padding:0}.jupyter-wrapper .bp3-text-large{font-size:16px}.jupyter-wrapper .bp3-text-small{font-size:12px}.jupyter-wrapper a .bp3-icon,.jupyter-wrapper a .bp3-icon-standard,.jupyter-wrapper a .bp3-icon-large,.jupyter-wrapper a code,.jupyter-wrapper .bp3-dark a code{color:inherit}.jupyter-wrapper .bp3-dark a,.jupyter-wrapper .bp3-dark a:hover{color:#48aff0}.jupyter-wrapper .bp3-dark a .bp3-icon,.jupyter-wrapper .bp3-dark a .bp3-icon-standard,.jupyter-wrapper .bp3-dark a .bp3-icon-large,.jupyter-wrapper .bp3-dark a:hover .bp3-icon,.jupyter-wrapper .bp3-dark a:hover .bp3-icon-standard,.jupyter-wrapper .bp3-dark a:hover .bp3-icon-large{color:inherit}.jupyter-wrapper .bp3-running-text code,.jupyter-wrapper .bp3-code{font-family:monospace;text-transform:none;background:rgba(255,255,255,.7);border-radius:3px;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33;color:#5c7080;font-size:smaller;padding:2px 5px}.jupyter-wrapper .bp3-dark .bp3-running-text code,.jupyter-wrapper .bp3-running-text .bp3-dark code,.jupyter-wrapper .bp3-dark .bp3-code{background:rgba(16,22,26,.3);-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66;color:#a7b6c2}.jupyter-wrapper .bp3-running-text a>code,.jupyter-wrapper a>.bp3-code{color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-running-text a>code,.jupyter-wrapper .bp3-running-text .bp3-dark a>code,.jupyter-wrapper .bp3-dark a>.bp3-code{color:inherit}.jupyter-wrapper .bp3-running-text pre,.jupyter-wrapper .bp3-code-block{font-family:monospace;text-transform:none;background:rgba(255,255,255,.7);border-radius:3px;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px #10161a26;color:#182026;display:block;font-size:13px;line-height:1.4;margin:10px 0;padding:13px 15px 12px;word-break:break-all;word-wrap:break-word}.jupyter-wrapper .bp3-dark .bp3-running-text pre,.jupyter-wrapper .bp3-running-text .bp3-dark pre,.jupyter-wrapper .bp3-dark .bp3-code-block{background:rgba(16,22,26,.3);-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-running-text pre>code,.jupyter-wrapper .bp3-code-block>code{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit;font-size:inherit;padding:0}.jupyter-wrapper .bp3-running-text kbd,.jupyter-wrapper .bp3-key{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background:#ffffff;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 0 #10161a00,0 1px 1px #10161a33;color:#5c7080;display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;font-family:inherit;font-size:12px;height:24px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;line-height:24px;min-width:24px;padding:3px 6px;vertical-align:middle}.jupyter-wrapper .bp3-running-text kbd .bp3-icon,.jupyter-wrapper .bp3-key .bp3-icon,.jupyter-wrapper .bp3-running-text kbd .bp3-icon-standard,.jupyter-wrapper .bp3-key .bp3-icon-standard,.jupyter-wrapper .bp3-running-text kbd .bp3-icon-large,.jupyter-wrapper .bp3-key .bp3-icon-large{margin-right:5px}.jupyter-wrapper .bp3-dark .bp3-running-text kbd,.jupyter-wrapper .bp3-running-text .bp3-dark kbd,.jupyter-wrapper .bp3-dark .bp3-key{background:#394b59;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66;color:#a7b6c2}.jupyter-wrapper .bp3-running-text blockquote,.jupyter-wrapper .bp3-blockquote{border-left:solid 4px rgba(167,182,194,.5);margin:0 0 10px;padding:0 20px}.jupyter-wrapper .bp3-dark .bp3-running-text blockquote,.jupyter-wrapper .bp3-running-text .bp3-dark blockquote,.jupyter-wrapper .bp3-dark .bp3-blockquote{border-color:#73869480}.jupyter-wrapper .bp3-running-text ul,.jupyter-wrapper .bp3-running-text ol,.jupyter-wrapper .bp3-list{margin:10px 0;padding-left:30px}.jupyter-wrapper .bp3-running-text ul li:not(:last-child),.jupyter-wrapper .bp3-running-text ol li:not(:last-child),.jupyter-wrapper .bp3-list li:not(:last-child){margin-bottom:5px}.jupyter-wrapper .bp3-running-text ul ol,.jupyter-wrapper .bp3-running-text ol ol,.jupyter-wrapper .bp3-list ol,.jupyter-wrapper .bp3-running-text ul ul,.jupyter-wrapper .bp3-running-text ol ul,.jupyter-wrapper .bp3-list ul{margin-top:5px}.jupyter-wrapper .bp3-list-unstyled{list-style:none;margin:0;padding:0}.jupyter-wrapper .bp3-list-unstyled li{padding:0}.jupyter-wrapper .bp3-rtl{text-align:right}.jupyter-wrapper .bp3-dark{color:#f5f8fa}.jupyter-wrapper :focus{outline:rgba(19,124,189,.6) auto 2px;outline-offset:2px;-moz-outline-radius:6px}.jupyter-wrapper .bp3-focus-disabled :focus{outline:none!important}.jupyter-wrapper .bp3-focus-disabled :focus~.bp3-control-indicator{outline:none!important}.jupyter-wrapper .bp3-alert{max-width:400px;padding:20px}.jupyter-wrapper .bp3-alert-body{display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-alert-body .bp3-icon{font-size:40px;margin-right:20px;margin-top:0}.jupyter-wrapper .bp3-alert-contents{word-break:break-word}.jupyter-wrapper .bp3-alert-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;margin-top:10px}.jupyter-wrapper .bp3-alert-footer .bp3-button{margin-left:10px}.jupyter-wrapper .bp3-breadcrumbs{-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:default;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;height:30px;list-style:none;margin:0;padding:0}.jupyter-wrapper .bp3-breadcrumbs>li{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-breadcrumbs>li:after{background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 00-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 001.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");content:"";display:block;height:16px;margin:0 5px;width:16px}.jupyter-wrapper .bp3-breadcrumbs>li:last-of-type:after{display:none}.jupyter-wrapper .bp3-breadcrumb,.jupyter-wrapper .bp3-breadcrumb-current,.jupyter-wrapper .bp3-breadcrumbs-collapsed{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;font-size:16px}.jupyter-wrapper .bp3-breadcrumb,.jupyter-wrapper .bp3-breadcrumbs-collapsed{color:#5c7080}.jupyter-wrapper .bp3-breadcrumb:hover{text-decoration:none}.jupyter-wrapper .bp3-breadcrumb.bp3-disabled{color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-breadcrumb .bp3-icon{margin-right:5px}.jupyter-wrapper .bp3-breadcrumb-current{color:inherit;font-weight:600}.jupyter-wrapper .bp3-breadcrumb-current .bp3-input{font-size:inherit;font-weight:inherit;vertical-align:baseline}.jupyter-wrapper .bp3-breadcrumbs-collapsed{background:#ced9e0;border:none;border-radius:3px;cursor:pointer;margin-right:2px;padding:1px 5px;vertical-align:text-bottom}.jupyter-wrapper .bp3-breadcrumbs-collapsed:before{background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;content:"";display:block;height:16px;width:16px}.jupyter-wrapper .bp3-breadcrumbs-collapsed:hover{background:#bfccd6;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-dark .bp3-breadcrumb,.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs>li:after{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-breadcrumb.bp3-disabled{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-breadcrumb-current{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed:hover{background:rgba(16,22,26,.6);color:#f5f8fa}.jupyter-wrapper .bp3-button{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:none;border-radius:3px;cursor:pointer;font-size:14px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding:5px 10px;text-align:left;vertical-align:middle;min-height:30px;min-width:30px}.jupyter-wrapper .bp3-button>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-button>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-button:before,.jupyter-wrapper .bp3-button>*{margin-right:7px}.jupyter-wrapper .bp3-button:empty:before,.jupyter-wrapper .bp3-button>:last-child{margin-right:0}.jupyter-wrapper .bp3-button:empty{padding:0!important}.jupyter-wrapper .bp3-button:disabled,.jupyter-wrapper .bp3-button.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-button.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-button.bp3-align-right,.jupyter-wrapper .bp3-align-right .bp3-button{text-align:right}.jupyter-wrapper .bp3-button.bp3-align-left,.jupyter-wrapper .bp3-align-left .bp3-button{text-align:left}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]){background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;color:#182026}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active:hover,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-button.bp3-intent-primary{background-color:#137cbd;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-primary:hover{background-color:#106ba3;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-active{background-color:#0e5a8a;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-disabled{background-color:#137cbd80;background-image:none;border-color:transparent;-webkit-box-shadow:none;box-shadow:none;color:#fff9}.jupyter-wrapper .bp3-button.bp3-intent-success{background-color:#0f9960;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-success:hover,.jupyter-wrapper .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-success:hover{background-color:#0d8050;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-active{background-color:#0a6640;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-disabled{background-color:#0f996080;background-image:none;border-color:transparent;-webkit-box-shadow:none;box-shadow:none;color:#fff9}.jupyter-wrapper .bp3-button.bp3-intent-warning{background-color:#d9822b;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-warning:hover{background-color:#bf7326;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-active{background-color:#a66321;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-disabled{background-color:#d9822b80;background-image:none;border-color:transparent;-webkit-box-shadow:none;box-shadow:none;color:#fff9}.jupyter-wrapper .bp3-button.bp3-intent-danger{background-color:#db3737;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-danger:hover{background-color:#c23030;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-active{background-color:#a82a2a;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-disabled{background-color:#db373780;background-image:none;border-color:transparent;-webkit-box-shadow:none;box-shadow:none;color:#fff9}.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-button-spinner .bp3-spinner-head{stroke:#fff}.jupyter-wrapper .bp3-button.bp3-large,.jupyter-wrapper .bp3-large .bp3-button{min-height:40px;min-width:40px;font-size:16px;padding:5px 15px}.jupyter-wrapper .bp3-button.bp3-large:before,.jupyter-wrapper .bp3-button.bp3-large>*,.jupyter-wrapper .bp3-large .bp3-button:before,.jupyter-wrapper .bp3-large .bp3-button>*{margin-right:10px}.jupyter-wrapper .bp3-button.bp3-large:empty:before,.jupyter-wrapper .bp3-button.bp3-large>:last-child,.jupyter-wrapper .bp3-large .bp3-button:empty:before,.jupyter-wrapper .bp3-large .bp3-button>:last-child{margin-right:0}.jupyter-wrapper .bp3-button.bp3-small,.jupyter-wrapper .bp3-small .bp3-button{min-height:24px;min-width:24px;padding:0 7px}.jupyter-wrapper .bp3-button.bp3-loading{position:relative}.jupyter-wrapper .bp3-button.bp3-loading[class*=bp3-icon-]:before{visibility:hidden}.jupyter-wrapper .bp3-button.bp3-loading .bp3-button-spinner{margin:0;position:absolute}.jupyter-wrapper .bp3-button.bp3-loading>:not(.bp3-button-spinner){visibility:hidden}.jupyter-wrapper .bp3-button[class*=bp3-icon-]:before{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;color:#5c7080}.jupyter-wrapper .bp3-button .bp3-icon,.jupyter-wrapper .bp3-button .bp3-icon-standard,.jupyter-wrapper .bp3-button .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-button .bp3-icon.bp3-align-right,.jupyter-wrapper .bp3-button .bp3-icon-standard.bp3-align-right,.jupyter-wrapper .bp3-button .bp3-icon-large.bp3-align-right{margin-left:7px}.jupyter-wrapper .bp3-button .bp3-icon:first-child:last-child,.jupyter-wrapper .bp3-button .bp3-spinner+.bp3-icon:last-child{margin:0 -7px}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]){background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):hover,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):hover{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-active{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):disabled,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-disabled{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-])[class*=bp3-icon-]:before{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon-large{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-],.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:active,.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-].bp3-active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:disabled,.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-].bp3-disabled{background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#ffffff4d}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-] .bp3-button-spinner .bp3-spinner-head{stroke:#8a9ba8}.jupyter-wrapper .bp3-button:disabled:before,.jupyter-wrapper .bp3-button:disabled .bp3-icon,.jupyter-wrapper .bp3-button:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-button:disabled .bp3-icon-large,.jupyter-wrapper .bp3-button.bp3-disabled:before,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon-standard,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon-large,.jupyter-wrapper .bp3-button[class*=bp3-intent-]:before,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon-standard,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon-large{color:inherit!important}.jupyter-wrapper .bp3-button.bp3-minimal{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-button.bp3-minimal:hover{background:rgba(167,182,194,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-active{background:rgba(115,134,148,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026}.jupyter-wrapper .bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-button.bp3-minimal:disabled:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled:hover{background:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-button.bp3-minimal:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal:disabled:hover.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{background:none;color:#a7b6c299;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{background:none;color:#106ba380}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{background:none;color:#48aff080}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{background:none;color:#0d805080}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{background:none;color:#3dcc9180}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{background:none;color:#bf732680}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{background:none;color:#ffb36680}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{background:none;color:#c2303080}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{background:none;color:#ff737380}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-outlined{background:none;-webkit-box-shadow:none;box-shadow:none;border:1px solid rgba(24,32,38,.2);-webkit-box-sizing:border-box;box-sizing:border-box}.jupyter-wrapper .bp3-button.bp3-outlined:hover{background:rgba(167,182,194,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-button.bp3-outlined:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-active{background:rgba(115,134,148,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026}.jupyter-wrapper .bp3-button.bp3-outlined:disabled,.jupyter-wrapper .bp3-button.bp3-outlined:disabled:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled:hover{background:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-button.bp3-outlined:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined:disabled:hover.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{background:none;color:#a7b6c299;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#106ba3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{background:none;color:#106ba380}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{background:none;color:#48aff080}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#0d8050}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{background:none;color:#0d805080}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{background:none;color:#3dcc9180}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#bf7326}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{background:none;color:#bf732680}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{background:none;color:#ffb36680}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#c23030}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{background:none;color:#c2303080}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{background:none;color:#ff737380}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-outlined:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled,.jupyter-wrapper .bp3-button.bp3-outlined:disabled:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled:hover{border-color:#5c70801a}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined{border-color:#fff6}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{border-color:#fff3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary{border-color:#106ba399}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{border-color:#106ba333}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{border-color:#48aff099}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{border-color:#48aff033}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success{border-color:#0d805099}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{border-color:#0d805033}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{border-color:#3dcc9199}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{border-color:#3dcc9133}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning{border-color:#bf732699}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{border-color:#bf732633}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{border-color:#ffb36699}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{border-color:#ffb36633}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger{border-color:#c2303099}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{border-color:#c2303033}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{border-color:#ff737399}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{border-color:#ff737333}.jupyter-wrapper a.bp3-button{text-align:center;text-decoration:none;-webkit-transition:none;transition:none}.jupyter-wrapper a.bp3-button,.jupyter-wrapper a.bp3-button:hover,.jupyter-wrapper a.bp3-button:active{color:#182026}.jupyter-wrapper a.bp3-button.bp3-disabled{color:#5c708099}.jupyter-wrapper .bp3-button-text{-webkit-box-flex:0;-ms-flex:0 1 auto;flex:0 1 auto}.jupyter-wrapper .bp3-button.bp3-align-left .bp3-button-text,.jupyter-wrapper .bp3-button.bp3-align-right .bp3-button-text,.jupyter-wrapper .bp3-button-group.bp3-align-left .bp3-button-text,.jupyter-wrapper .bp3-button-group.bp3-align-right .bp3-button-text{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.jupyter-wrapper .bp3-button-group .bp3-button{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;position:relative;z-index:4}.jupyter-wrapper .bp3-button-group .bp3-button:focus{z-index:5}.jupyter-wrapper .bp3-button-group .bp3-button:hover{z-index:6}.jupyter-wrapper .bp3-button-group .bp3-button:active,.jupyter-wrapper .bp3-button-group .bp3-button.bp3-active{z-index:7}.jupyter-wrapper .bp3-button-group .bp3-button:disabled,.jupyter-wrapper .bp3-button-group .bp3-button.bp3-disabled{z-index:3}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]{z-index:9}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:focus{z-index:10}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:hover{z-index:11}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:active,.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-].bp3-active{z-index:12}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:disabled,.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-].bp3-disabled{z-index:8}.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:first-child) .bp3-button,.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:first-child){border-bottom-left-radius:0;border-top-left-radius:0}.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:last-child){border-bottom-right-radius:0;border-top-right-radius:0;margin-right:-1px}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:hover{background:rgba(167,182,194,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-active{background:rgba(115,134,148,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{background:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{background:none;color:#a7b6c299;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{background:none;color:#106ba380}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{background:none;color:#48aff080}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{background:none;color:#0d805080}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{background:none;color:#3dcc9180}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{background:none;color:#bf732680}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{background:none;color:#ffb36680}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{background:none;color:#c2303080}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{background:none;color:#ff737380}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button-group .bp3-popover-wrapper,.jupyter-wrapper .bp3-button-group .bp3-popover-target{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-button-group .bp3-button.bp3-fill,.jupyter-wrapper .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group.bp3-vertical{-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;vertical-align:top}.jupyter-wrapper .bp3-button-group.bp3-vertical.bp3-fill{height:100%;width:unset}.jupyter-wrapper .bp3-button-group.bp3-vertical .bp3-button{margin-right:0!important;width:100%}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:first-child .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:first-child{border-radius:3px 3px 0 0}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:last-child .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:last-child{border-radius:0 0 3px 3px}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:not(:last-child){margin-bottom:-1px}.jupyter-wrapper .bp3-button-group.bp3-align-left .bp3-button{text-align:left}.jupyter-wrapper .bp3-dark .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-dark .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:last-child){margin-right:1px}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-vertical>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-vertical>.bp3-button:not(:last-child){margin-bottom:1px}.jupyter-wrapper .bp3-callout{font-size:14px;line-height:1.5;background-color:#8a9ba826;border-radius:3px;padding:10px 12px 9px;position:relative;width:100%}.jupyter-wrapper .bp3-callout[class*=bp3-icon-]{padding-left:40px}.jupyter-wrapper .bp3-callout[class*=bp3-icon-]:before{font-family:Icons20,sans-serif;font-size:20px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;color:#5c7080;left:10px;position:absolute;top:10px}.jupyter-wrapper .bp3-callout.bp3-callout-icon{padding-left:40px}.jupyter-wrapper .bp3-callout.bp3-callout-icon>.bp3-icon:first-child{color:#5c7080;left:10px;position:absolute;top:10px}.jupyter-wrapper .bp3-callout .bp3-heading{line-height:20px;margin-bottom:5px;margin-top:0}.jupyter-wrapper .bp3-callout .bp3-heading:last-child{margin-bottom:0}.jupyter-wrapper .bp3-dark .bp3-callout{background-color:#8a9ba833}.jupyter-wrapper .bp3-dark .bp3-callout[class*=bp3-icon-]:before{color:#a7b6c2}.jupyter-wrapper .bp3-callout.bp3-intent-primary{background-color:#137cbd26}.jupyter-wrapper .bp3-callout.bp3-intent-primary[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-callout.bp3-intent-primary>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-primary .bp3-heading{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary{background-color:#137cbd40}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{color:#48aff0}.jupyter-wrapper .bp3-callout.bp3-intent-success{background-color:#0f996026}.jupyter-wrapper .bp3-callout.bp3-intent-success[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-callout.bp3-intent-success>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-success .bp3-heading{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success{background-color:#0f996040}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{color:#3dcc91}.jupyter-wrapper .bp3-callout.bp3-intent-warning{background-color:#d9822b26}.jupyter-wrapper .bp3-callout.bp3-intent-warning[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-callout.bp3-intent-warning>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-warning .bp3-heading{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning{background-color:#d9822b40}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{color:#ffb366}.jupyter-wrapper .bp3-callout.bp3-intent-danger{background-color:#db373726}.jupyter-wrapper .bp3-callout.bp3-intent-danger[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-callout.bp3-intent-danger>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-danger .bp3-heading{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger{background-color:#db373740}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{color:#ff7373}.jupyter-wrapper .bp3-running-text .bp3-callout{margin:20px 0}.jupyter-wrapper .bp3-card{background-color:#fff;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.15),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px #10161a26,0 0 #10161a00,0 0 #10161a00;padding:20px;-webkit-transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .2s cubic-bezier(.4,1,.75,.9);transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9),box-shadow .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9),box-shadow .2s cubic-bezier(.4,1,.75,.9),-webkit-transform .2s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-card.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px #10161a66,0 0 #10161a00,0 0 #10161a00}.jupyter-wrapper .bp3-elevation-0{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.15),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px #10161a26,0 0 #10161a00,0 0 #10161a00}.jupyter-wrapper .bp3-elevation-0.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-0{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px #10161a66,0 0 #10161a00,0 0 #10161a00}.jupyter-wrapper .bp3-elevation-1{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 0 #10161a00,0 1px 1px #10161a33}.jupyter-wrapper .bp3-elevation-1.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-1{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66}.jupyter-wrapper .bp3-elevation-2{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 1px 1px rgba(16,22,26,.2),0 2px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 1px 1px #10161a33,0 2px 6px #10161a33}.jupyter-wrapper .bp3-elevation-2.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-2{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.4),0 2px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 1px 1px #10161a66,0 2px 6px #10161a66}.jupyter-wrapper .bp3-elevation-3{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33}.jupyter-wrapper .bp3-elevation-3.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-3{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-elevation-4{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 4px 8px #10161a33,0 18px 46px 6px #10161a33}.jupyter-wrapper .bp3-elevation-4.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-4{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 4px 8px #10161a66,0 18px 46px 6px #10161a66}.jupyter-wrapper .bp3-card.bp3-interactive:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;cursor:pointer}.jupyter-wrapper .bp3-card.bp3-interactive:hover.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card.bp3-interactive:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-card.bp3-interactive:active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 0 #10161a00,0 1px 1px #10161a33;opacity:.9;-webkit-transition-duration:0;transition-duration:0}.jupyter-wrapper .bp3-card.bp3-interactive:active.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card.bp3-interactive:active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66}.jupyter-wrapper .bp3-collapse{height:0;overflow-y:hidden;-webkit-transition:height .2s cubic-bezier(.4,1,.75,.9);transition:height .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-collapse .bp3-collapse-body{-webkit-transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9);transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9),-webkit-transform .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-collapse .bp3-collapse-body[aria-hidden=true]{display:none}.jupyter-wrapper .bp3-context-menu .bp3-popover-target{display:block}.jupyter-wrapper .bp3-context-menu-popover-target{position:fixed}.jupyter-wrapper .bp3-dialog-container{opacity:1;-webkit-transform:scale(1);transform:scale(1);-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;min-height:100%;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:100%}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-enter>.bp3-dialog,.jupyter-wrapper .bp3-dialog-container.bp3-overlay-appear>.bp3-dialog{opacity:0;-webkit-transform:scale(.5);transform:scale(.5)}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-enter-active>.bp3-dialog,.jupyter-wrapper .bp3-dialog-container.bp3-overlay-appear-active>.bp3-dialog{opacity:1;-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:opacity,transform;transition-property:opacity,transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-exit>.bp3-dialog{opacity:1;-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-exit-active>.bp3-dialog{opacity:0;-webkit-transform:scale(.5);transform:scale(.5);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:opacity,transform;transition-property:opacity,transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-dialog{background:#ebf1f5;border-radius:6px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 4px 8px #10161a33,0 18px 46px 6px #10161a33;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:30px 0;padding-bottom:20px;pointer-events:all;-webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text;width:500px}.jupyter-wrapper .bp3-dialog:focus{outline:0}.jupyter-wrapper .bp3-dialog.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-dialog{background:#293742;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 4px 8px #10161a66,0 18px 46px 6px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dialog-header{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background:#ffffff;border-radius:6px 6px 0 0;-webkit-box-shadow:0 1px 0 rgba(16,22,26,.15);box-shadow:0 1px #10161a26;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;min-height:40px;padding-left:20px;padding-right:5px;z-index:30}.jupyter-wrapper .bp3-dialog-header .bp3-icon-large,.jupyter-wrapper .bp3-dialog-header .bp3-icon{color:#5c7080;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-right:10px}.jupyter-wrapper .bp3-dialog-header .bp3-heading{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:inherit;margin:0}.jupyter-wrapper .bp3-dialog-header .bp3-heading:last-child{margin-right:20px}.jupyter-wrapper .bp3-dark .bp3-dialog-header{background:#30404d;-webkit-box-shadow:0 1px 0 rgba(16,22,26,.4);box-shadow:0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-dialog-header .bp3-icon-large,.jupyter-wrapper .bp3-dark .bp3-dialog-header .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dialog-body{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:18px;margin:20px}.jupyter-wrapper .bp3-dialog-footer{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin:0 20px}.jupyter-wrapper .bp3-dialog-footer-actions{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end}.jupyter-wrapper .bp3-dialog-footer-actions .bp3-button{margin-left:10px}.jupyter-wrapper .bp3-multistep-dialog-panels{display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-multistep-dialog-left-panel{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1;flex:1;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.jupyter-wrapper .bp3-dark .bp3-multistep-dialog-left-panel{background:#202b33}.jupyter-wrapper .bp3-multistep-dialog-right-panel{background-color:#f5f8fa;border-left:1px solid rgba(16,22,26,.15);border-radius:0 0 6px;-webkit-box-flex:3;-ms-flex:3;flex:3;min-width:0}.jupyter-wrapper .bp3-dark .bp3-multistep-dialog-right-panel{background-color:#293742;border-left:1px solid rgba(16,22,26,.4)}.jupyter-wrapper .bp3-multistep-dialog-footer{background-color:#fff;border-radius:0 0 6px;border-top:1px solid rgba(16,22,26,.15);padding:10px}.jupyter-wrapper .bp3-dark .bp3-multistep-dialog-footer{background:#30404d;border-top:1px solid rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dialog-step-container{background-color:#f5f8fa;border-bottom:1px solid rgba(16,22,26,.15)}.jupyter-wrapper .bp3-dark .bp3-dialog-step-container{background:#293742;border-bottom:1px solid rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dialog-step-container.bp3-dialog-step-viewed{background-color:#fff}.jupyter-wrapper .bp3-dark .bp3-dialog-step-container.bp3-dialog-step-viewed{background:#30404d}.jupyter-wrapper .bp3-dialog-step{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#f5f8fa;border-radius:6px;cursor:not-allowed;display:-webkit-box;display:-ms-flexbox;display:flex;margin:4px;padding:6px 14px}.jupyter-wrapper .bp3-dark .bp3-dialog-step{background:#293742}.jupyter-wrapper .bp3-dialog-step-viewed .bp3-dialog-step{background-color:#fff;cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-dialog-step-viewed .bp3-dialog-step{background:#30404d}.jupyter-wrapper .bp3-dialog-step:hover{background-color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-dialog-step:hover{background:#293742}.jupyter-wrapper .bp3-dialog-step-icon{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#5c708099;border-radius:50%;color:#fff;display:-webkit-box;display:-ms-flexbox;display:flex;height:25px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:25px}.jupyter-wrapper .bp3-dark .bp3-dialog-step-icon{background-color:#a7b6c299}.jupyter-wrapper .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-icon{background-color:#2b95d6}.jupyter-wrapper .bp3-dialog-step-viewed .bp3-dialog-step-icon{background-color:#8a9ba8}.jupyter-wrapper .bp3-dialog-step-title{color:#5c708099;-webkit-box-flex:1;-ms-flex:1;flex:1;padding-left:10px}.jupyter-wrapper .bp3-dark .bp3-dialog-step-title{color:#a7b6c299}.jupyter-wrapper .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-title{color:#2b95d6}.jupyter-wrapper .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{color:#182026}.jupyter-wrapper .bp3-dark .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{color:#f5f8fa}.jupyter-wrapper .bp3-drawer{background:#ffffff;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 4px 8px #10161a33,0 18px 46px 6px #10161a33;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:0;padding:0}.jupyter-wrapper .bp3-drawer:focus{outline:0}.jupyter-wrapper .bp3-drawer.bp3-position-top{height:50%;left:0;right:0;top:0}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-appear{-webkit-transform:translateY(-100%);transform:translateY(-100%)}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{-webkit-transform:translateY(-100%);transform:translateY(-100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom{bottom:0;height:50%;left:0;right:0}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{-webkit-transform:translateY(100%);transform:translateY(100%)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{-webkit-transform:translateY(100%);transform:translateY(100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-left{bottom:0;left:0;top:0;width:50%}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-appear{-webkit-transform:translateX(-100%);transform:translate(-100%)}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translate(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-exit{-webkit-transform:translateX(0);transform:translate(0)}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{-webkit-transform:translateX(-100%);transform:translate(-100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-right{bottom:0;right:0;top:0;width:50%}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-appear{-webkit-transform:translateX(100%);transform:translate(100%)}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translate(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-exit{-webkit-transform:translateX(0);transform:translate(0)}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{-webkit-transform:translateX(100%);transform:translate(100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical){bottom:0;right:0;top:0;width:50%}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-enter,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{-webkit-transform:translateX(100%);transform:translate(100%)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translate(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{-webkit-transform:translateX(0);transform:translate(0)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{-webkit-transform:translateX(100%);transform:translate(100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical{bottom:0;height:50%;left:0;right:0}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-appear{-webkit-transform:translateY(100%);transform:translateY(100%)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-exit-active{-webkit-transform:translateY(100%);transform:translateY(100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-drawer{background:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 4px 8px #10161a66,0 18px 46px 6px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-drawer-header{-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:0;-webkit-box-shadow:0 1px 0 rgba(16,22,26,.15);box-shadow:0 1px #10161a26;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;min-height:40px;padding:5px 5px 5px 20px;position:relative}.jupyter-wrapper .bp3-drawer-header .bp3-icon-large,.jupyter-wrapper .bp3-drawer-header .bp3-icon{color:#5c7080;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-right:10px}.jupyter-wrapper .bp3-drawer-header .bp3-heading{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:inherit;margin:0}.jupyter-wrapper .bp3-drawer-header .bp3-heading:last-child{margin-right:20px}.jupyter-wrapper .bp3-dark .bp3-drawer-header{-webkit-box-shadow:0 1px 0 rgba(16,22,26,.4);box-shadow:0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-drawer-header .bp3-icon-large,.jupyter-wrapper .bp3-dark .bp3-drawer-header .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-drawer-body{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:18px;overflow:auto}.jupyter-wrapper .bp3-drawer-footer{-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.15);box-shadow:inset 0 1px #10161a26;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding:10px 20px;position:relative}.jupyter-wrapper .bp3-dark .bp3-drawer-footer{-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.4);box-shadow:inset 0 1px #10161a66}.jupyter-wrapper .bp3-editable-text{cursor:text;display:inline-block;max-width:100%;position:relative;vertical-align:top;white-space:nowrap}.jupyter-wrapper .bp3-editable-text:before{bottom:-3px;left:-3px;position:absolute;right:-3px;top:-3px;border-radius:3px;content:"";-webkit-transition:background-color .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:background-color .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:background-color .1s cubic-bezier(.4,1,.75,.9),box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:background-color .1s cubic-bezier(.4,1,.75,.9),box-shadow .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-editable-text:hover:before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a26}.jupyter-wrapper .bp3-editable-text.bp3-editable-text-editing:before{background-color:#fff;-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-editable-text.bp3-disabled:before{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{color:#137cbd}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary:hover:before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(19,124,189,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #137cbd66}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{color:#0f9960}.jupyter-wrapper .bp3-editable-text.bp3-intent-success:hover:before{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px rgba(15,153,96,.4);box-shadow:0 0 #0f996000,0 0 #0f996000,inset 0 0 0 1px #0f996066}.jupyter-wrapper .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px #0f99604d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{color:#d9822b}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning:hover:before{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px rgba(217,130,43,.4);box-shadow:0 0 #d9822b00,0 0 #d9822b00,inset 0 0 0 1px #d9822b66}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px #d9822b4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{color:#db3737}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger:hover:before{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px rgba(219,55,55,.4);box-shadow:0 0 #db373700,0 0 #db373700,inset 0 0 0 1px #db373766}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px #db37374d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-dark .bp3-editable-text:hover:before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(255,255,255,.15);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #ffffff26}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-editable-text-editing:before{background-color:#10161a4d;-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-disabled:before{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary:hover:before{-webkit-box-shadow:0 0 0 0 rgba(72,175,240,0),0 0 0 0 rgba(72,175,240,0),inset 0 0 0 1px rgba(72,175,240,.4);box-shadow:0 0 #48aff000,0 0 #48aff000,inset 0 0 0 1px #48aff066}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #48aff0,0 0 0 3px rgba(72,175,240,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #48aff0,0 0 0 3px #48aff04d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success:hover:before{-webkit-box-shadow:0 0 0 0 rgba(61,204,145,0),0 0 0 0 rgba(61,204,145,0),inset 0 0 0 1px rgba(61,204,145,.4);box-shadow:0 0 #3dcc9100,0 0 #3dcc9100,inset 0 0 0 1px #3dcc9166}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #3dcc91,0 0 0 3px rgba(61,204,145,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #3dcc91,0 0 0 3px #3dcc914d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning:hover:before{-webkit-box-shadow:0 0 0 0 rgba(255,179,102,0),0 0 0 0 rgba(255,179,102,0),inset 0 0 0 1px rgba(255,179,102,.4);box-shadow:0 0 #ffb36600,0 0 #ffb36600,inset 0 0 0 1px #ffb36666}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #ffb366,0 0 0 3px rgba(255,179,102,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #ffb366,0 0 0 3px #ffb3664d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger:hover:before{-webkit-box-shadow:0 0 0 0 rgba(255,115,115,0),0 0 0 0 rgba(255,115,115,0),inset 0 0 0 1px rgba(255,115,115,.4);box-shadow:0 0 #ff737300,0 0 #ff737300,inset 0 0 0 1px #ff737366}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #ff7373,0 0 0 3px rgba(255,115,115,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #ff7373,0 0 0 3px #ff73734d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text-content{color:inherit;display:inherit;font:inherit;letter-spacing:inherit;max-width:inherit;min-width:inherit;position:relative;resize:none;text-transform:inherit;vertical-align:top}.jupyter-wrapper .bp3-editable-text-input{background:none;border:none;-webkit-box-shadow:none;box-shadow:none;padding:0;white-space:pre-wrap;width:100%}.jupyter-wrapper .bp3-editable-text-input::-webkit-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input::-moz-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input:-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input::-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input::placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input:focus{outline:none}.jupyter-wrapper .bp3-editable-text-input::-ms-clear{display:none}.jupyter-wrapper .bp3-editable-text-content{overflow:hidden;padding-right:2px;text-overflow:ellipsis;white-space:pre}.jupyter-wrapper .bp3-editable-text-editing>.bp3-editable-text-content{left:0;position:absolute;visibility:hidden}.jupyter-wrapper .bp3-editable-text-placeholder>.bp3-editable-text-content{color:#5c708099}.jupyter-wrapper .bp3-dark .bp3-editable-text-placeholder>.bp3-editable-text-content{color:#a7b6c299}.jupyter-wrapper .bp3-editable-text.bp3-multiline{display:block}.jupyter-wrapper .bp3-editable-text.bp3-multiline .bp3-editable-text-content{overflow:auto;white-space:pre-wrap;word-wrap:break-word}.jupyter-wrapper .bp3-divider{border-bottom:1px solid rgba(16,22,26,.15);border-right:1px solid rgba(16,22,26,.15);margin:5px}.jupyter-wrapper .bp3-dark .bp3-divider{border-color:#10161a66}.jupyter-wrapper .bp3-control-group{-webkit-transform:translateZ(0);transform:translateZ(0);display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch}.jupyter-wrapper .bp3-control-group>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-control-group>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-control-group .bp3-button,.jupyter-wrapper .bp3-control-group .bp3-html-select,.jupyter-wrapper .bp3-control-group .bp3-input,.jupyter-wrapper .bp3-control-group .bp3-select{position:relative}.jupyter-wrapper .bp3-control-group .bp3-input{border-radius:inherit;z-index:2}.jupyter-wrapper .bp3-control-group .bp3-input:focus{border-radius:3px;z-index:14}.jupyter-wrapper .bp3-control-group .bp3-input[class*=bp3-intent]{z-index:13}.jupyter-wrapper .bp3-control-group .bp3-input[class*=bp3-intent]:focus{z-index:15}.jupyter-wrapper .bp3-control-group .bp3-input[readonly],.jupyter-wrapper .bp3-control-group .bp3-input:disabled,.jupyter-wrapper .bp3-control-group .bp3-input.bp3-disabled{z-index:1}.jupyter-wrapper .bp3-control-group .bp3-input-group[class*=bp3-intent] .bp3-input{z-index:13}.jupyter-wrapper .bp3-control-group .bp3-input-group[class*=bp3-intent] .bp3-input:focus{z-index:15}.jupyter-wrapper .bp3-control-group .bp3-button,.jupyter-wrapper .bp3-control-group .bp3-html-select select,.jupyter-wrapper .bp3-control-group .bp3-select select{-webkit-transform:translateZ(0);transform:translateZ(0);border-radius:inherit;z-index:4}.jupyter-wrapper .bp3-control-group .bp3-button:focus,.jupyter-wrapper .bp3-control-group .bp3-html-select select:focus,.jupyter-wrapper .bp3-control-group .bp3-select select:focus{z-index:5}.jupyter-wrapper .bp3-control-group .bp3-button:hover,.jupyter-wrapper .bp3-control-group .bp3-html-select select:hover,.jupyter-wrapper .bp3-control-group .bp3-select select:hover{z-index:6}.jupyter-wrapper .bp3-control-group .bp3-button:active,.jupyter-wrapper .bp3-control-group .bp3-html-select select:active,.jupyter-wrapper .bp3-control-group .bp3-select select:active{z-index:7}.jupyter-wrapper .bp3-control-group .bp3-button[readonly],.jupyter-wrapper .bp3-control-group .bp3-button:disabled,.jupyter-wrapper .bp3-control-group .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[readonly],.jupyter-wrapper .bp3-control-group .bp3-html-select select:disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[readonly],.jupyter-wrapper .bp3-control-group .bp3-select select:disabled,.jupyter-wrapper .bp3-control-group .bp3-select select.bp3-disabled{z-index:3}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent],.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent],.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]{z-index:9}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:focus,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:focus,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:focus{z-index:10}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:hover,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:hover,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:hover{z-index:11}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:active,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:active,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:active{z-index:12}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent].bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent].bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent].bp3-disabled{z-index:8}.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-icon,.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-button,.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-input-left-container,.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-input-action{z-index:16}.jupyter-wrapper .bp3-control-group .bp3-select:after,.jupyter-wrapper .bp3-control-group .bp3-html-select:after,.jupyter-wrapper .bp3-control-group .bp3-select>.bp3-icon,.jupyter-wrapper .bp3-control-group .bp3-html-select>.bp3-icon{z-index:17}.jupyter-wrapper .bp3-control-group .bp3-select:focus-within{z-index:5}.jupyter-wrapper .bp3-control-group:not(.bp3-vertical)>*:not(.bp3-divider){margin-right:-1px}.jupyter-wrapper .bp3-control-group:not(.bp3-vertical)>.bp3-divider:not(:first-child){margin-left:6px}.jupyter-wrapper .bp3-dark .bp3-control-group:not(.bp3-vertical)>*:not(.bp3-divider){margin-right:0}.jupyter-wrapper .bp3-dark .bp3-control-group:not(.bp3-vertical)>.bp3-button+.bp3-button{margin-left:1px}.jupyter-wrapper .bp3-control-group .bp3-popover-wrapper,.jupyter-wrapper .bp3-control-group .bp3-popover-target{border-radius:inherit}.jupyter-wrapper .bp3-control-group>:first-child{border-radius:3px 0 0 3px}.jupyter-wrapper .bp3-control-group>:last-child{border-radius:0 3px 3px 0;margin-right:0}.jupyter-wrapper .bp3-control-group>:only-child{border-radius:3px;margin-right:0}.jupyter-wrapper .bp3-control-group .bp3-input-group .bp3-button{border-radius:3px}.jupyter-wrapper .bp3-control-group .bp3-numeric-input:not(:first-child) .bp3-input-group{border-bottom-left-radius:0;border-top-left-radius:0}.jupyter-wrapper .bp3-control-group.bp3-fill{width:100%}.jupyter-wrapper .bp3-control-group>.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-control-group.bp3-fill>*:not(.bp3-fixed){-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-control-group.bp3-vertical{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.jupyter-wrapper .bp3-control-group.bp3-vertical>*{margin-top:-1px}.jupyter-wrapper .bp3-control-group.bp3-vertical>:first-child{border-radius:3px 3px 0 0;margin-top:0}.jupyter-wrapper .bp3-control-group.bp3-vertical>:last-child{border-radius:0 0 3px 3px}.jupyter-wrapper .bp3-control{cursor:pointer;display:block;margin-bottom:10px;position:relative;text-transform:none}.jupyter-wrapper .bp3-control input:checked~.bp3-control-indicator{background-color:#137cbd;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-control:hover input:checked~.bp3-control-indicator{background-color:#106ba3;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-control input:not(:disabled):active:checked~.bp3-control-indicator{background:#0e5a8a;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-control input:disabled:checked~.bp3-control-indicator{background:rgba(19,124,189,.5);-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-control input:checked~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control:hover input:checked~.bp3-control-indicator{background-color:#106ba3;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control input:not(:disabled):active:checked~.bp3-control-indicator{background-color:#0e5a8a;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-control input:disabled:checked~.bp3-control-indicator{background:rgba(14,90,138,.5);-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-control:not(.bp3-align-right){padding-left:26px}.jupyter-wrapper .bp3-control:not(.bp3-align-right) .bp3-control-indicator{margin-left:-26px}.jupyter-wrapper .bp3-control.bp3-align-right{padding-right:26px}.jupyter-wrapper .bp3-control.bp3-align-right .bp3-control-indicator{margin-right:-26px}.jupyter-wrapper .bp3-control.bp3-disabled{color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-control.bp3-inline{display:inline-block;margin-right:20px}.jupyter-wrapper .bp3-control input{left:0;opacity:0;position:absolute;top:0;z-index:-1}.jupyter-wrapper .bp3-control .bp3-control-indicator{background-clip:padding-box;background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));border:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;cursor:pointer;display:inline-block;font-size:16px;height:1em;margin-right:10px;margin-top:-3px;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;width:1em}.jupyter-wrapper .bp3-control .bp3-control-indicator:before{content:"";display:block;height:1em;width:1em}.jupyter-wrapper .bp3-control:hover .bp3-control-indicator{background-color:#ebf1f5}.jupyter-wrapper .bp3-control input:not(:disabled):active~.bp3-control-indicator{background:#d8e1e8;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-control input:disabled~.bp3-control-indicator{background:rgba(206,217,224,.5);-webkit-box-shadow:none;box-shadow:none;cursor:not-allowed}.jupyter-wrapper .bp3-control input:focus~.bp3-control-indicator{outline:rgba(19,124,189,.6) auto 2px;outline-offset:2px;-moz-outline-radius:6px}.jupyter-wrapper .bp3-control.bp3-align-right .bp3-control-indicator{float:right;margin-left:10px;margin-top:1px}.jupyter-wrapper .bp3-control.bp3-large{font-size:16px}.jupyter-wrapper .bp3-control.bp3-large:not(.bp3-align-right){padding-left:30px}.jupyter-wrapper .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{margin-left:-30px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right{padding-right:30px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{margin-right:-30px}.jupyter-wrapper .bp3-control.bp3-large .bp3-control-indicator{font-size:20px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{margin-top:0}.jupyter-wrapper .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator{background-color:#137cbd;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-control.bp3-checkbox:hover input:indeterminate~.bp3-control-indicator{background-color:#106ba3;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate~.bp3-control-indicator{background:#0e5a8a;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{background:rgba(19,124,189,.5);-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate~.bp3-control-indicator{background-color:#106ba3;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate~.bp3-control-indicator{background-color:#0e5a8a;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{background:rgba(14,90,138,.5);-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-control.bp3-checkbox .bp3-control-indicator{border-radius:3px}.jupyter-wrapper .bp3-control.bp3-checkbox input:checked~.bp3-control-indicator:before{background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 00-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0012 5z' fill='white'/%3e%3c/svg%3e")}.jupyter-wrapper .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator:before{background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e")}.jupyter-wrapper .bp3-control.bp3-radio .bp3-control-indicator{border-radius:50%}.jupyter-wrapper .bp3-control.bp3-radio input:checked~.bp3-control-indicator:before{background-image:radial-gradient(#ffffff,#ffffff 28%,transparent 32%)}.jupyter-wrapper .bp3-control.bp3-radio input:checked:disabled~.bp3-control-indicator:before{opacity:.5}.jupyter-wrapper .bp3-control.bp3-radio input:focus~.bp3-control-indicator{-moz-outline-radius:16px}.jupyter-wrapper .bp3-control.bp3-switch input~.bp3-control-indicator{background:rgba(167,182,194,.5)}.jupyter-wrapper .bp3-control.bp3-switch:hover input~.bp3-control-indicator{background:rgba(115,134,148,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:not(:disabled):active~.bp3-control-indicator{background:rgba(92,112,128,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:disabled~.bp3-control-indicator{background:rgba(206,217,224,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:disabled~.bp3-control-indicator:before{background:rgba(255,255,255,.8)}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator{background:#137cbd}.jupyter-wrapper .bp3-control.bp3-switch:hover input:checked~.bp3-control-indicator{background:#106ba3}.jupyter-wrapper .bp3-control.bp3-switch input:checked:not(:disabled):active~.bp3-control-indicator{background:#0e5a8a}.jupyter-wrapper .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator{background:rgba(19,124,189,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator:before{background:rgba(255,255,255,.8)}.jupyter-wrapper .bp3-control.bp3-switch:not(.bp3-align-right){padding-left:38px}.jupyter-wrapper .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{margin-left:-38px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-align-right{padding-right:38px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{margin-right:-38px}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator{border:none;border-radius:1.75em;-webkit-box-shadow:none!important;box-shadow:none!important;min-width:1.75em;-webkit-transition:background-color .1s cubic-bezier(.4,1,.75,.9);transition:background-color .1s cubic-bezier(.4,1,.75,.9);width:auto}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator:before{background:#ffffff;border-radius:50%;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a33,0 1px 1px #10161a33;height:calc(1em - 4px);left:0;margin:2px;position:absolute;-webkit-transition:left .1s cubic-bezier(.4,1,.75,.9);transition:left .1s cubic-bezier(.4,1,.75,.9);width:calc(1em - 4px)}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator:before{left:calc(100% - 1em)}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){padding-left:45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{margin-left:-45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large.bp3-align-right{padding-right:45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{margin-right:-45px}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input~.bp3-control-indicator{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch:hover input~.bp3-control-indicator{background:rgba(16,22,26,.7)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active~.bp3-control-indicator{background:rgba(16,22,26,.9)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:disabled~.bp3-control-indicator{background:rgba(57,75,89,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:disabled~.bp3-control-indicator:before{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked~.bp3-control-indicator{background:#137cbd}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch:hover input:checked~.bp3-control-indicator{background:#106ba3}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active~.bp3-control-indicator{background:#0e5a8a}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator{background:rgba(14,90,138,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator:before{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator:before{background:#394b59;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked~.bp3-control-indicator:before{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66}.jupyter-wrapper .bp3-control.bp3-switch .bp3-switch-inner-text{font-size:.7em;text-align:center}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{line-height:0;margin-left:.5em;margin-right:1.2em;visibility:hidden}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{line-height:1em;margin-left:1.2em;margin-right:.5em;visibility:visible}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator .bp3-control-indicator-child:first-child{line-height:1em;visibility:visible}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator .bp3-control-indicator-child:last-child{line-height:0;visibility:hidden}.jupyter-wrapper .bp3-dark .bp3-control{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-control.bp3-disabled{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-control .bp3-control-indicator{background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control:hover .bp3-control-indicator{background-color:#30404d}.jupyter-wrapper .bp3-dark .bp3-control input:not(:disabled):active~.bp3-control-indicator{background:#202b33;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-control input:disabled~.bp3-control-indicator{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked~.bp3-control-indicator,.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{color:#a7b6c299}.jupyter-wrapper .bp3-file-input{cursor:pointer;display:inline-block;height:30px;position:relative}.jupyter-wrapper .bp3-file-input input{margin:0;min-width:200px;opacity:0}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input{background:rgba(206,217,224,.5);-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;resize:none}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input:after,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input:after .bp3-active,.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input:after .bp3-active:hover,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after .bp3-active,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after .bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input:after,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input:after .bp3-active,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after .bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{color:#182026}.jupyter-wrapper .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{color:#f5f8fa}.jupyter-wrapper .bp3-file-input.bp3-fill{width:100%}.jupyter-wrapper .bp3-file-input.bp3-large,.jupyter-wrapper .bp3-large .bp3-file-input{height:40px}.jupyter-wrapper .bp3-file-input .bp3-file-upload-input-custom-text:after{content:attr(bp3-button-text)}.jupyter-wrapper .bp3-file-upload-input{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#ffffff;border:none;border-radius:3px;-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33;color:#182026;font-size:14px;font-weight:400;height:30px;line-height:30px;outline:none;padding:0 80px 0 10px;-webkit-transition:-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:box-shadow .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);vertical-align:middle;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;color:#5c708099;left:0;position:absolute;right:0;top:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-file-upload-input::-webkit-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input::-moz-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input:-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input::-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input::placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input:focus,.jupyter-wrapper .bp3-file-upload-input.bp3-active{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-file-upload-input[type=search],.jupyter-wrapper .bp3-file-upload-input.bp3-round{border-radius:30px;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:10px}.jupyter-wrapper .bp3-file-upload-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px #10161a26}.jupyter-wrapper .bp3-file-upload-input:disabled,.jupyter-wrapper .bp3-file-upload-input.bp3-disabled{background:rgba(206,217,224,.5);-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;resize:none}.jupyter-wrapper .bp3-file-upload-input:after{background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;color:#182026;min-height:24px;min-width:24px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;border-radius:3px;content:"Browse";line-height:24px;margin:3px;position:absolute;right:0;text-align:center;top:0;width:70px}.jupyter-wrapper .bp3-file-upload-input:after:hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-file-upload-input:after:active,.jupyter-wrapper .bp3-file-upload-input:after .bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-file-upload-input:after:disabled,.jupyter-wrapper .bp3-file-upload-input:after .bp3-disabled{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-file-upload-input:after:disabled .bp3-active,.jupyter-wrapper .bp3-file-upload-input:after:disabled .bp3-active:hover,.jupyter-wrapper .bp3-file-upload-input:after .bp3-disabled.bp3-active,.jupyter-wrapper .bp3-file-upload-input:after .bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-file-upload-input:hover:after{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-file-upload-input:active:after{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-large .bp3-file-upload-input{font-size:16px;height:40px;line-height:40px;padding-right:95px}.jupyter-wrapper .bp3-large .bp3-file-upload-input[type=search],.jupyter-wrapper .bp3-large .bp3-file-upload-input.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-large .bp3-file-upload-input:after{min-height:30px;min-width:30px;line-height:30px;margin:5px;width:85px}.jupyter-wrapper .bp3-dark .bp3-file-upload-input{background:rgba(16,22,26,.3);-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66;color:#f5f8fa;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-moz-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-file-upload-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:disabled,.jupyter-wrapper .bp3-dark .bp3-file-upload-input.bp3-disabled{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after{background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:hover,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:hover{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-active{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:disabled,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-disabled{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:disabled .bp3-active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:hover:after{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:active:after{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-file-upload-input:after{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-form-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:0 0 15px}.jupyter-wrapper .bp3-form-group label.bp3-label{margin-bottom:5px}.jupyter-wrapper .bp3-form-group .bp3-control{margin-top:7px}.jupyter-wrapper .bp3-form-group .bp3-form-helper-text{color:#5c7080;font-size:12px;margin-top:5px}.jupyter-wrapper .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{color:#106ba3}.jupyter-wrapper .bp3-form-group.bp3-intent-success .bp3-form-helper-text{color:#0d8050}.jupyter-wrapper .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{color:#bf7326}.jupyter-wrapper .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{color:#c23030}.jupyter-wrapper .bp3-form-group.bp3-inline{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row}.jupyter-wrapper .bp3-form-group.bp3-inline.bp3-large label.bp3-label{line-height:40px;margin:0 10px 0 0}.jupyter-wrapper .bp3-form-group.bp3-inline label.bp3-label{line-height:30px;margin:0 10px 0 0}.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-label,.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-text-muted,.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-form-helper-text{color:#5c708099!important}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-form-group .bp3-form-helper-text{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{color:#a7b6c299!important}.jupyter-wrapper .bp3-input-group{display:block;position:relative}.jupyter-wrapper .bp3-input-group .bp3-input{position:relative;width:100%}.jupyter-wrapper .bp3-input-group .bp3-input:not(:first-child){padding-left:30px}.jupyter-wrapper .bp3-input-group .bp3-input:not(:last-child){padding-right:30px}.jupyter-wrapper .bp3-input-group .bp3-input-action,.jupyter-wrapper .bp3-input-group>.bp3-input-left-container,.jupyter-wrapper .bp3-input-group>.bp3-button,.jupyter-wrapper .bp3-input-group>.bp3-icon{position:absolute;top:0}.jupyter-wrapper .bp3-input-group .bp3-input-action:first-child,.jupyter-wrapper .bp3-input-group>.bp3-input-left-container:first-child,.jupyter-wrapper .bp3-input-group>.bp3-button:first-child,.jupyter-wrapper .bp3-input-group>.bp3-icon:first-child{left:0}.jupyter-wrapper .bp3-input-group .bp3-input-action:last-child,.jupyter-wrapper .bp3-input-group>.bp3-input-left-container:last-child,.jupyter-wrapper .bp3-input-group>.bp3-button:last-child,.jupyter-wrapper .bp3-input-group>.bp3-icon:last-child{right:0}.jupyter-wrapper .bp3-input-group .bp3-button{min-height:24px;min-width:24px;margin:3px;padding:0 7px}.jupyter-wrapper .bp3-input-group .bp3-button:empty{padding:0}.jupyter-wrapper .bp3-input-group>.bp3-input-left-container,.jupyter-wrapper .bp3-input-group>.bp3-icon{z-index:1}.jupyter-wrapper .bp3-input-group>.bp3-input-left-container>.bp3-icon,.jupyter-wrapper .bp3-input-group>.bp3-icon{color:#5c7080}.jupyter-wrapper .bp3-input-group>.bp3-input-left-container>.bp3-icon:empty,.jupyter-wrapper .bp3-input-group>.bp3-icon:empty{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}.jupyter-wrapper .bp3-input-group>.bp3-input-left-container>.bp3-icon,.jupyter-wrapper .bp3-input-group>.bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input-action>.bp3-spinner{margin:7px}.jupyter-wrapper .bp3-input-group .bp3-tag{margin:5px}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus),.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){color:#5c7080}.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus),.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){color:#a7b6c2}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled{color:#5c708099!important}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon-large,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{color:#5c708099!important}.jupyter-wrapper .bp3-input-group.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-input-group.bp3-disabled .bp3-icon{color:#5c708099}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-button{min-height:30px;min-width:30px;margin:5px}.jupyter-wrapper .bp3-input-group.bp3-large>.bp3-input-left-container>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-large>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input-action>.bp3-spinner{margin:12px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input{font-size:16px;height:40px;line-height:40px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input[type=search],.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input:not(:first-child){padding-left:40px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input:not(:last-child){padding-right:40px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-button,.jupyter-wrapper .bp3-input-group.bp3-small .bp3-tag{min-height:20px;min-width:20px;margin:2px}.jupyter-wrapper .bp3-input-group.bp3-small>.bp3-input-left-container>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-small>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input-action>.bp3-spinner{margin:4px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input{font-size:12px;height:24px;line-height:24px;padding-left:8px;padding-right:8px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input[type=search],.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input.bp3-round{padding:0 12px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input:not(:first-child){padding-left:24px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input:not(:last-child){padding-right:24px}.jupyter-wrapper .bp3-input-group.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;width:100%}.jupyter-wrapper .bp3-input-group.bp3-round .bp3-button,.jupyter-wrapper .bp3-input-group.bp3-round .bp3-input,.jupyter-wrapper .bp3-input-group.bp3-round .bp3-tag{border-radius:30px}.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{color:#a7b6c299}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #137cbd,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-primary>.bp3-icon{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-primary>.bp3-icon{color:#48aff0}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #0f996000,0 0 #0f996000,inset 0 0 0 1px #0f9960,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px #0f99604d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-success>.bp3-icon{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-success>.bp3-icon{color:#3dcc91}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #d9822b00,0 0 #d9822b00,inset 0 0 0 1px #d9822b,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px #d9822b4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-warning>.bp3-icon{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-warning>.bp3-icon{color:#ffb366}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #db373700,0 0 #db373700,inset 0 0 0 1px #db3737,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px #db37374d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-danger>.bp3-icon{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-danger>.bp3-icon{color:#ff7373}.jupyter-wrapper .bp3-input{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#ffffff;border:none;border-radius:3px;-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33;color:#182026;font-size:14px;font-weight:400;height:30px;line-height:30px;outline:none;padding:0 10px;-webkit-transition:-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:box-shadow .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);vertical-align:middle}.jupyter-wrapper .bp3-input::-webkit-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input::-moz-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input:-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input::-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input::placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input:focus,.jupyter-wrapper .bp3-input.bp3-active{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input[type=search],.jupyter-wrapper .bp3-input.bp3-round{border-radius:30px;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:10px}.jupyter-wrapper .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px #10161a26}.jupyter-wrapper .bp3-input:disabled,.jupyter-wrapper .bp3-input.bp3-disabled{background:rgba(206,217,224,.5);-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;resize:none}.jupyter-wrapper .bp3-input.bp3-large{font-size:16px;height:40px;line-height:40px}.jupyter-wrapper .bp3-input.bp3-large[type=search],.jupyter-wrapper .bp3-input.bp3-large.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-input.bp3-small{font-size:12px;height:24px;line-height:24px;padding-left:8px;padding-right:8px}.jupyter-wrapper .bp3-input.bp3-small[type=search],.jupyter-wrapper .bp3-input.bp3-small.bp3-round{padding:0 12px}.jupyter-wrapper .bp3-input.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;width:100%}.jupyter-wrapper .bp3-dark .bp3-input{background:rgba(16,22,26,.3);-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-input::-webkit-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input::-moz-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input:-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input::-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input::placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-disabled{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-input.bp3-intent-primary{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #137cbd,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-primary:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-primary[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-input.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-input.bp3-intent-primary.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #137cbd,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-success{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #0f996000,0 0 #0f996000,inset 0 0 0 1px #0f9960,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-success:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px #0f99604d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-success[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-input.bp3-intent-success:disabled,.jupyter-wrapper .bp3-input.bp3-intent-success.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #0f996000,0 0 #0f996000,0 0 #0f996000,inset 0 0 0 1px #0f9960,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #0f9960,0 0 0 1px #0f9960,0 0 0 3px #0f99604d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-warning{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #d9822b00,0 0 #d9822b00,inset 0 0 0 1px #d9822b,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-warning:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px #d9822b4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-warning[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-input.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-input.bp3-intent-warning.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #d9822b00,0 0 #d9822b00,0 0 #d9822b00,inset 0 0 0 1px #d9822b,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #d9822b,0 0 0 1px #d9822b,0 0 0 3px #d9822b4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-danger{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #db373700,0 0 #db373700,inset 0 0 0 1px #db3737,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-danger:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px #db37374d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-danger[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-input.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-input.bp3-intent-danger.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #db373700,0 0 #db373700,0 0 #db373700,inset 0 0 0 1px #db3737,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #db3737,0 0 0 1px #db3737,0 0 0 3px #db37374d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input::-ms-clear{display:none}.jupyter-wrapper textarea.bp3-input{max-width:100%;padding:10px}.jupyter-wrapper textarea.bp3-input,.jupyter-wrapper textarea.bp3-input.bp3-large,.jupyter-wrapper textarea.bp3-input.bp3-small{height:auto;line-height:inherit}.jupyter-wrapper textarea.bp3-input.bp3-small{padding:8px}.jupyter-wrapper .bp3-dark textarea.bp3-input{background:rgba(16,22,26,.3);-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark textarea.bp3-input::-webkit-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input::-moz-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input:-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input::-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input::placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark textarea.bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark textarea.bp3-input:disabled,.jupyter-wrapper .bp3-dark textarea.bp3-input.bp3-disabled{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper label.bp3-label{display:block;margin-bottom:15px;margin-top:0}.jupyter-wrapper label.bp3-label .bp3-html-select,.jupyter-wrapper label.bp3-label .bp3-input,.jupyter-wrapper label.bp3-label .bp3-select,.jupyter-wrapper label.bp3-label .bp3-slider,.jupyter-wrapper label.bp3-label .bp3-popover-wrapper{display:block;margin-top:5px;text-transform:none}.jupyter-wrapper label.bp3-label .bp3-button-group{margin-top:5px}.jupyter-wrapper label.bp3-label .bp3-select select,.jupyter-wrapper label.bp3-label .bp3-html-select select{font-weight:400;vertical-align:top;width:100%}.jupyter-wrapper label.bp3-label.bp3-disabled,.jupyter-wrapper label.bp3-label.bp3-disabled .bp3-text-muted{color:#5c708099}.jupyter-wrapper label.bp3-label.bp3-inline{line-height:30px}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-html-select,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input-group,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-select,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-popover-wrapper{display:inline-block;margin:0 0 0 5px;vertical-align:top}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-button-group{margin:0 0 0 5px}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input-group .bp3-input{margin-left:0}.jupyter-wrapper label.bp3-label.bp3-inline.bp3-large{line-height:40px}.jupyter-wrapper label.bp3-label:not(.bp3-inline) .bp3-popover-target{display:block}.jupyter-wrapper .bp3-dark label.bp3-label{color:#f5f8fa}.jupyter-wrapper .bp3-dark label.bp3-label.bp3-disabled,.jupyter-wrapper .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{color:#a7b6c299}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button{-webkit-box-flex:1;-ms-flex:1 1 14px;flex:1 1 14px;min-height:0;padding:0;width:30px}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button:first-child{border-radius:0 3px 0 0}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button:last-child{border-radius:0 0 3px}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical:first-child>.bp3-button:first-child{border-radius:3px 0 0}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical:first-child>.bp3-button:last-child{border-radius:0 0 0 3px}.jupyter-wrapper .bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical>.bp3-button{width:40px}.jupyter-wrapper form{display:block}.jupyter-wrapper .bp3-html-select select,.jupyter-wrapper .bp3-select select{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:none;cursor:pointer;font-size:14px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:left;vertical-align:middle;background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;color:#182026;-moz-appearance:none;-webkit-appearance:none;border-radius:3px;height:30px;padding:0 25px 0 10px;width:100%}.jupyter-wrapper .bp3-html-select select>*,.jupyter-wrapper .bp3-select select>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-html-select select>.bp3-fill,.jupyter-wrapper .bp3-select select>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-html-select select:before,.jupyter-wrapper .bp3-select select:before,.jupyter-wrapper .bp3-html-select select>*,.jupyter-wrapper .bp3-select select>*{margin-right:7px}.jupyter-wrapper .bp3-html-select select:empty:before,.jupyter-wrapper .bp3-select select:empty:before,.jupyter-wrapper .bp3-html-select select>:last-child,.jupyter-wrapper .bp3-select select>:last-child{margin-right:0}.jupyter-wrapper .bp3-html-select select:hover,.jupyter-wrapper .bp3-select select:hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-html-select select:active,.jupyter-wrapper .bp3-select select:active,.jupyter-wrapper .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-select select.bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-html-select select:disabled,.jupyter-wrapper .bp3-select select:disabled,.jupyter-wrapper .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-select select.bp3-disabled{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-html-select select:disabled.bp3-active,.jupyter-wrapper .bp3-select select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select select:disabled.bp3-active:hover,.jupyter-wrapper .bp3-select select:disabled.bp3-active:hover,.jupyter-wrapper .bp3-html-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select select.bp3-disabled.bp3-active:hover,.jupyter-wrapper .bp3-select select.bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-html-select.bp3-minimal select,.jupyter-wrapper .bp3-select.bp3-minimal select{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal select:hover{background:rgba(167,182,194,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-active{background:rgba(115,134,148,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026}.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled:hover{background:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{background:none;color:#a7b6c299;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{background:none;color:#106ba380}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{background:none;color:#48aff080}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{background:none;color:#0d805080}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{background:none;color:#3dcc9180}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{background:none;color:#bf732680}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{background:none;color:#ffb36680}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{background:none;color:#c2303080}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{background:none;color:#ff737380}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-html-select.bp3-large select,.jupyter-wrapper .bp3-select.bp3-large select{font-size:16px;height:40px;padding-right:35px}.jupyter-wrapper .bp3-dark .bp3-html-select select,.jupyter-wrapper .bp3-dark .bp3-select select{background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select select:hover,.jupyter-wrapper .bp3-dark .bp3-select select:hover,.jupyter-wrapper .bp3-dark .bp3-html-select select:active,.jupyter-wrapper .bp3-dark .bp3-select select:active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select select:hover,.jupyter-wrapper .bp3-dark .bp3-select select:hover{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-html-select select:active,.jupyter-wrapper .bp3-dark .bp3-select select:active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-active{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-html-select select:disabled,.jupyter-wrapper .bp3-dark .bp3-select select:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-disabled{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-html-select select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-html-select select:disabled,.jupyter-wrapper .bp3-select select:disabled{background-color:#ced9e080;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-select .bp3-icon,.jupyter-wrapper .bp3-select:after{color:#5c7080;pointer-events:none;position:absolute;right:7px;top:7px}.jupyter-wrapper .bp3-html-select .bp3-disabled.bp3-icon,.jupyter-wrapper .bp3-select .bp3-disabled.bp3-icon,.jupyter-wrapper .bp3-disabled.bp3-select:after{color:#5c708099}.jupyter-wrapper .bp3-html-select,.jupyter-wrapper .bp3-select{display:inline-block;letter-spacing:normal;position:relative;vertical-align:middle}.jupyter-wrapper .bp3-html-select select::-ms-expand,.jupyter-wrapper .bp3-select select::-ms-expand{display:none}.jupyter-wrapper .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-select .bp3-icon{color:#5c7080}.jupyter-wrapper .bp3-html-select .bp3-icon:hover,.jupyter-wrapper .bp3-select .bp3-icon:hover{color:#182026}.jupyter-wrapper .bp3-dark .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-select .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-html-select .bp3-icon:hover,.jupyter-wrapper .bp3-dark .bp3-select .bp3-icon:hover{color:#f5f8fa}.jupyter-wrapper .bp3-html-select.bp3-large:after,.jupyter-wrapper .bp3-html-select.bp3-large .bp3-icon,.jupyter-wrapper .bp3-select.bp3-large:after,.jupyter-wrapper .bp3-select.bp3-large .bp3-icon{right:12px;top:12px}.jupyter-wrapper .bp3-html-select.bp3-fill,.jupyter-wrapper .bp3-html-select.bp3-fill select,.jupyter-wrapper .bp3-select.bp3-fill,.jupyter-wrapper .bp3-select.bp3-fill select{width:100%}.jupyter-wrapper .bp3-dark .bp3-html-select option,.jupyter-wrapper .bp3-dark .bp3-select option{background-color:#30404d;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select option:disabled,.jupyter-wrapper .bp3-dark .bp3-select option:disabled{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-html-select:after,.jupyter-wrapper .bp3-dark .bp3-select:after{color:#a7b6c2}.jupyter-wrapper .bp3-select:after{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;content:""}.jupyter-wrapper .bp3-running-text table,.jupyter-wrapper table.bp3-html-table{border-spacing:0;font-size:14px}.jupyter-wrapper .bp3-running-text table th,.jupyter-wrapper table.bp3-html-table th,.jupyter-wrapper .bp3-running-text table td,.jupyter-wrapper table.bp3-html-table td{padding:11px;text-align:left;vertical-align:top}.jupyter-wrapper .bp3-running-text table th,.jupyter-wrapper table.bp3-html-table th{color:#182026;font-weight:600}.jupyter-wrapper .bp3-running-text table td,.jupyter-wrapper table.bp3-html-table td{color:#182026}.jupyter-wrapper .bp3-running-text table tbody tr:first-child th,.jupyter-wrapper table.bp3-html-table tbody tr:first-child th,.jupyter-wrapper .bp3-running-text table tbody tr:first-child td,.jupyter-wrapper table.bp3-html-table tbody tr:first-child td,.jupyter-wrapper .bp3-running-text table tfoot tr:first-child th,.jupyter-wrapper table.bp3-html-table tfoot tr:first-child th,.jupyter-wrapper .bp3-running-text table tfoot tr:first-child td,.jupyter-wrapper table.bp3-html-table tfoot tr:first-child td{-webkit-box-shadow:inset 0 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 0 1px #10161a26}.jupyter-wrapper .bp3-dark .bp3-running-text table th,.jupyter-wrapper .bp3-running-text .bp3-dark table th,.jupyter-wrapper .bp3-dark table.bp3-html-table th,.jupyter-wrapper .bp3-dark .bp3-running-text table td,.jupyter-wrapper .bp3-running-text .bp3-dark table td,.jupyter-wrapper .bp3-dark table.bp3-html-table td{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-running-text table tbody tr:first-child th,.jupyter-wrapper .bp3-running-text .bp3-dark table tbody tr:first-child th,.jupyter-wrapper .bp3-dark table.bp3-html-table tbody tr:first-child th,.jupyter-wrapper .bp3-dark .bp3-running-text table tbody tr:first-child td,.jupyter-wrapper .bp3-running-text .bp3-dark table tbody tr:first-child td,.jupyter-wrapper .bp3-dark table.bp3-html-table tbody tr:first-child td,.jupyter-wrapper .bp3-dark .bp3-running-text table tfoot tr:first-child th,.jupyter-wrapper .bp3-running-text .bp3-dark table tfoot tr:first-child th,.jupyter-wrapper .bp3-dark table.bp3-html-table tfoot tr:first-child th,.jupyter-wrapper .bp3-dark .bp3-running-text table tfoot tr:first-child td,.jupyter-wrapper .bp3-running-text .bp3-dark table tfoot tr:first-child td,.jupyter-wrapper .bp3-dark table.bp3-html-table tfoot tr:first-child td{-webkit-box-shadow:inset 0 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 0 1px #ffffff26}.jupyter-wrapper table.bp3-html-table.bp3-html-table-condensed th,.jupyter-wrapper table.bp3-html-table.bp3-html-table-condensed td,.jupyter-wrapper table.bp3-html-table.bp3-small th,.jupyter-wrapper table.bp3-html-table.bp3-small td{padding-bottom:6px;padding-top:6px}.jupyter-wrapper table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{background:rgba(191,204,214,.15)}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 0 #10161a26}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tbody tr td,.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tfoot tr td{-webkit-box-shadow:inset 0 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 0 1px #10161a26}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){-webkit-box-shadow:inset 1px 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 1px #10161a26}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 0 #10161a26}.jupyter-wrapper table.bp3-html-table.bp3-interactive tbody tr:hover td{background-color:#bfccd64d;cursor:pointer}.jupyter-wrapper table.bp3-html-table.bp3-interactive tbody tr:active td{background-color:#bfccd666}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{background:rgba(92,112,128,.15)}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 0 #ffffff26}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td,.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td{-webkit-box-shadow:inset 0 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 0 1px #ffffff26}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){-webkit-box-shadow:inset 1px 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 1px #ffffff26}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{-webkit-box-shadow:inset 1px 0 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 0 #ffffff26}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{background-color:#5c70804d;cursor:pointer}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{background-color:#5c708066}.jupyter-wrapper .bp3-key-combo{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center}.jupyter-wrapper .bp3-key-combo>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-key-combo>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-key-combo:before,.jupyter-wrapper .bp3-key-combo>*{margin-right:5px}.jupyter-wrapper .bp3-key-combo:empty:before,.jupyter-wrapper .bp3-key-combo>:last-child{margin-right:0}.jupyter-wrapper .bp3-hotkey-dialog{padding-bottom:0;top:40px}.jupyter-wrapper .bp3-hotkey-dialog .bp3-dialog-body{margin:0;padding:0}.jupyter-wrapper .bp3-hotkey-dialog .bp3-hotkey-label{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1}.jupyter-wrapper .bp3-hotkey-column{margin:auto;max-height:80vh;overflow-y:auto;padding:30px}.jupyter-wrapper .bp3-hotkey-column .bp3-heading{margin-bottom:20px}.jupyter-wrapper .bp3-hotkey-column .bp3-heading:not(:first-child){margin-top:40px}.jupyter-wrapper .bp3-hotkey{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;margin-left:0;margin-right:0}.jupyter-wrapper .bp3-hotkey:not(:last-child){margin-bottom:10px}.jupyter-wrapper .bp3-icon{display:inline-block;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;vertical-align:text-bottom}.jupyter-wrapper .bp3-icon:not(:empty):before{content:""!important;content:unset!important}.jupyter-wrapper .bp3-icon>svg{display:block}.jupyter-wrapper .bp3-icon>svg:not([fill]){fill:currentColor}.jupyter-wrapper .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-icon-large.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-icon-large.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-icon-large.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-icon-large.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-danger{color:#ff7373}.jupyter-wrapper span.bp3-icon-standard{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;display:inline-block}.jupyter-wrapper span.bp3-icon-large{font-family:Icons20,sans-serif;font-size:20px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;display:inline-block}.jupyter-wrapper span.bp3-icon:empty{font-family:Icons20;font-size:inherit;font-style:normal;font-weight:400;line-height:1}.jupyter-wrapper span.bp3-icon:empty:before{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}.jupyter-wrapper .bp3-icon-add:before{content:""}.jupyter-wrapper .bp3-icon-add-column-left:before{content:""}.jupyter-wrapper .bp3-icon-add-column-right:before{content:""}.jupyter-wrapper .bp3-icon-add-row-bottom:before{content:""}.jupyter-wrapper .bp3-icon-add-row-top:before{content:""}.jupyter-wrapper .bp3-icon-add-to-artifact:before{content:""}.jupyter-wrapper .bp3-icon-add-to-folder:before{content:""}.jupyter-wrapper .bp3-icon-airplane:before{content:""}.jupyter-wrapper .bp3-icon-align-center:before{content:""}.jupyter-wrapper .bp3-icon-align-justify:before{content:""}.jupyter-wrapper .bp3-icon-align-left:before{content:""}.jupyter-wrapper .bp3-icon-align-right:before{content:""}.jupyter-wrapper .bp3-icon-alignment-bottom:before{content:""}.jupyter-wrapper .bp3-icon-alignment-horizontal-center:before{content:""}.jupyter-wrapper .bp3-icon-alignment-left:before{content:""}.jupyter-wrapper .bp3-icon-alignment-right:before{content:""}.jupyter-wrapper .bp3-icon-alignment-top:before{content:""}.jupyter-wrapper .bp3-icon-alignment-vertical-center:before{content:""}.jupyter-wrapper .bp3-icon-annotation:before{content:""}.jupyter-wrapper .bp3-icon-application:before{content:""}.jupyter-wrapper .bp3-icon-applications:before{content:""}.jupyter-wrapper .bp3-icon-archive:before{content:""}.jupyter-wrapper .bp3-icon-arrow-bottom-left:before{content:"↙"}.jupyter-wrapper .bp3-icon-arrow-bottom-right:before{content:"↘"}.jupyter-wrapper .bp3-icon-arrow-down:before{content:"↓"}.jupyter-wrapper .bp3-icon-arrow-left:before{content:"←"}.jupyter-wrapper .bp3-icon-arrow-right:before{content:"→"}.jupyter-wrapper .bp3-icon-arrow-top-left:before{content:"↖"}.jupyter-wrapper .bp3-icon-arrow-top-right:before{content:"↗"}.jupyter-wrapper .bp3-icon-arrow-up:before{content:"↑"}.jupyter-wrapper .bp3-icon-arrows-horizontal:before{content:"↔"}.jupyter-wrapper .bp3-icon-arrows-vertical:before{content:"↕"}.jupyter-wrapper .bp3-icon-asterisk:before{content:"*"}.jupyter-wrapper .bp3-icon-automatic-updates:before{content:""}.jupyter-wrapper .bp3-icon-badge:before{content:""}.jupyter-wrapper .bp3-icon-ban-circle:before{content:""}.jupyter-wrapper .bp3-icon-bank-account:before{content:""}.jupyter-wrapper .bp3-icon-barcode:before{content:""}.jupyter-wrapper .bp3-icon-blank:before{content:""}.jupyter-wrapper .bp3-icon-blocked-person:before{content:""}.jupyter-wrapper .bp3-icon-bold:before{content:""}.jupyter-wrapper .bp3-icon-book:before{content:""}.jupyter-wrapper .bp3-icon-bookmark:before{content:""}.jupyter-wrapper .bp3-icon-box:before{content:""}.jupyter-wrapper .bp3-icon-briefcase:before{content:""}.jupyter-wrapper .bp3-icon-bring-data:before{content:""}.jupyter-wrapper .bp3-icon-build:before{content:""}.jupyter-wrapper .bp3-icon-calculator:before{content:""}.jupyter-wrapper .bp3-icon-calendar:before{content:""}.jupyter-wrapper .bp3-icon-camera:before{content:""}.jupyter-wrapper .bp3-icon-caret-down:before{content:"⌄"}.jupyter-wrapper .bp3-icon-caret-left:before{content:"〈"}.jupyter-wrapper .bp3-icon-caret-right:before{content:"〉"}.jupyter-wrapper .bp3-icon-caret-up:before{content:"⌃"}.jupyter-wrapper .bp3-icon-cell-tower:before{content:""}.jupyter-wrapper .bp3-icon-MKDOCS_changes:before{content:""}.jupyter-wrapper .bp3-icon-chart:before{content:""}.jupyter-wrapper .bp3-icon-chat:before{content:""}.jupyter-wrapper .bp3-icon-chevron-backward:before{content:""}.jupyter-wrapper .bp3-icon-chevron-down:before{content:""}.jupyter-wrapper .bp3-icon-chevron-forward:before{content:""}.jupyter-wrapper .bp3-icon-chevron-left:before{content:""}.jupyter-wrapper .bp3-icon-chevron-right:before{content:""}.jupyter-wrapper .bp3-icon-chevron-up:before{content:""}.jupyter-wrapper .bp3-icon-circle:before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-down:before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-left:before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-right:before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-up:before{content:""}.jupyter-wrapper .bp3-icon-citation:before{content:""}.jupyter-wrapper .bp3-icon-clean:before{content:""}.jupyter-wrapper .bp3-icon-clipboard:before{content:""}.jupyter-wrapper .bp3-icon-cloud:before{content:"☁"}.jupyter-wrapper .bp3-icon-cloud-download:before{content:""}.jupyter-wrapper .bp3-icon-cloud-upload:before{content:""}.jupyter-wrapper .bp3-icon-code:before{content:""}.jupyter-wrapper .bp3-icon-code-block:before{content:""}.jupyter-wrapper .bp3-icon-cog:before{content:""}.jupyter-wrapper .bp3-icon-collapse-all:before{content:""}.jupyter-wrapper .bp3-icon-column-layout:before{content:""}.jupyter-wrapper .bp3-icon-comment:before{content:""}.jupyter-wrapper .bp3-icon-comparison:before{content:""}.jupyter-wrapper .bp3-icon-compass:before{content:""}.jupyter-wrapper .bp3-icon-compressed:before{content:""}.jupyter-wrapper .bp3-icon-confirm:before{content:""}.jupyter-wrapper .bp3-icon-console:before{content:""}.jupyter-wrapper .bp3-icon-contrast:before{content:""}.jupyter-wrapper .bp3-icon-control:before{content:""}.jupyter-wrapper .bp3-icon-credit-card:before{content:""}.jupyter-wrapper .bp3-icon-cross:before{content:"✗"}.jupyter-wrapper .bp3-icon-crown:before{content:""}.jupyter-wrapper .bp3-icon-cube:before{content:""}.jupyter-wrapper .bp3-icon-cube-add:before{content:""}.jupyter-wrapper .bp3-icon-cube-remove:before{content:""}.jupyter-wrapper .bp3-icon-curved-range-chart:before{content:""}.jupyter-wrapper .bp3-icon-cut:before{content:""}.jupyter-wrapper .bp3-icon-dashboard:before{content:""}.jupyter-wrapper .bp3-icon-data-lineage:before{content:""}.jupyter-wrapper .bp3-icon-database:before{content:""}.jupyter-wrapper .bp3-icon-delete:before{content:""}.jupyter-wrapper .bp3-icon-delta:before{content:"Δ"}.jupyter-wrapper .bp3-icon-derive-column:before{content:""}.jupyter-wrapper .bp3-icon-desktop:before{content:""}.jupyter-wrapper .bp3-icon-diagnosis:before{content:""}.jupyter-wrapper .bp3-icon-diagram-tree:before{content:""}.jupyter-wrapper .bp3-icon-direction-left:before{content:""}.jupyter-wrapper .bp3-icon-direction-right:before{content:""}.jupyter-wrapper .bp3-icon-disable:before{content:""}.jupyter-wrapper .bp3-icon-document:before{content:""}.jupyter-wrapper .bp3-icon-document-open:before{content:""}.jupyter-wrapper .bp3-icon-document-share:before{content:""}.jupyter-wrapper .bp3-icon-dollar:before{content:"$"}.jupyter-wrapper .bp3-icon-dot:before{content:"•"}.jupyter-wrapper .bp3-icon-double-caret-horizontal:before{content:""}.jupyter-wrapper .bp3-icon-double-caret-vertical:before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-down:before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-left:before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-right:before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-up:before{content:""}.jupyter-wrapper .bp3-icon-doughnut-chart:before{content:""}.jupyter-wrapper .bp3-icon-download:before{content:""}.jupyter-wrapper .bp3-icon-drag-handle-horizontal:before{content:""}.jupyter-wrapper .bp3-icon-drag-handle-vertical:before{content:""}.jupyter-wrapper .bp3-icon-draw:before{content:""}.jupyter-wrapper .bp3-icon-drive-time:before{content:""}.jupyter-wrapper .bp3-icon-duplicate:before{content:""}.jupyter-wrapper .bp3-icon-edit:before{content:"✎"}.jupyter-wrapper .bp3-icon-eject:before{content:"⏏"}.jupyter-wrapper .bp3-icon-endorsed:before{content:""}.jupyter-wrapper .bp3-icon-envelope:before{content:"✉"}.jupyter-wrapper .bp3-icon-equals:before{content:""}.jupyter-wrapper .bp3-icon-eraser:before{content:""}.jupyter-wrapper .bp3-icon-error:before{content:""}.jupyter-wrapper .bp3-icon-euro:before{content:"€"}.jupyter-wrapper .bp3-icon-MKDOCS_exchange:before{content:""}.jupyter-wrapper .bp3-icon-exclude-row:before{content:""}.jupyter-wrapper .bp3-icon-expand-all:before{content:""}.jupyter-wrapper .bp3-icon-export:before{content:""}.jupyter-wrapper .bp3-icon-eye-off:before{content:""}.jupyter-wrapper .bp3-icon-eye-on:before{content:""}.jupyter-wrapper .bp3-icon-eye-open:before{content:""}.jupyter-wrapper .bp3-icon-fast-backward:before{content:""}.jupyter-wrapper .bp3-icon-fast-forward:before{content:""}.jupyter-wrapper .bp3-icon-feed:before{content:""}.jupyter-wrapper .bp3-icon-feed-subscribed:before{content:""}.jupyter-wrapper .bp3-icon-film:before{content:""}.jupyter-wrapper .bp3-icon-filter:before{content:""}.jupyter-wrapper .bp3-icon-filter-keep:before{content:""}.jupyter-wrapper .bp3-icon-filter-list:before{content:""}.jupyter-wrapper .bp3-icon-filter-open:before{content:""}.jupyter-wrapper .bp3-icon-filter-remove:before{content:""}.jupyter-wrapper .bp3-icon-flag:before{content:"⚑"}.jupyter-wrapper .bp3-icon-flame:before{content:""}.jupyter-wrapper .bp3-icon-flash:before{content:""}.jupyter-wrapper .bp3-icon-floppy-disk:before{content:""}.jupyter-wrapper .bp3-icon-flow-branch:before{content:""}.jupyter-wrapper .bp3-icon-flow-end:before{content:""}.jupyter-wrapper .bp3-icon-flow-linear:before{content:""}.jupyter-wrapper .bp3-icon-flow-review:before{content:""}.jupyter-wrapper .bp3-icon-flow-review-branch:before{content:""}.jupyter-wrapper .bp3-icon-flows:before{content:""}.jupyter-wrapper .bp3-icon-folder-close:before{content:""}.jupyter-wrapper .bp3-icon-folder-new:before{content:""}.jupyter-wrapper .bp3-icon-folder-open:before{content:""}.jupyter-wrapper .bp3-icon-folder-shared:before{content:""}.jupyter-wrapper .bp3-icon-folder-shared-open:before{content:""}.jupyter-wrapper .bp3-icon-follower:before{content:""}.jupyter-wrapper .bp3-icon-following:before{content:""}.jupyter-wrapper .bp3-icon-font:before{content:""}.jupyter-wrapper .bp3-icon-fork:before{content:""}.jupyter-wrapper .bp3-icon-form:before{content:""}.jupyter-wrapper .bp3-icon-full-circle:before{content:""}.jupyter-wrapper .bp3-icon-full-stacked-chart:before{content:""}.jupyter-wrapper .bp3-icon-fullscreen:before{content:""}.jupyter-wrapper .bp3-icon-function:before{content:""}.jupyter-wrapper .bp3-icon-gantt-chart:before{content:""}.jupyter-wrapper .bp3-icon-geolocation:before{content:""}.jupyter-wrapper .bp3-icon-geosearch:before{content:""}.jupyter-wrapper .bp3-icon-git-branch:before{content:""}.jupyter-wrapper .bp3-icon-git-commit:before{content:""}.jupyter-wrapper .bp3-icon-git-merge:before{content:""}.jupyter-wrapper .bp3-icon-git-new-branch:before{content:""}.jupyter-wrapper .bp3-icon-git-pull:before{content:""}.jupyter-wrapper .bp3-icon-git-push:before{content:""}.jupyter-wrapper .bp3-icon-git-repo:before{content:""}.jupyter-wrapper .bp3-icon-glass:before{content:""}.jupyter-wrapper .bp3-icon-globe:before{content:""}.jupyter-wrapper .bp3-icon-globe-network:before{content:""}.jupyter-wrapper .bp3-icon-graph:before{content:""}.jupyter-wrapper .bp3-icon-graph-remove:before{content:""}.jupyter-wrapper .bp3-icon-greater-than:before{content:""}.jupyter-wrapper .bp3-icon-greater-than-or-equal-to:before{content:""}.jupyter-wrapper .bp3-icon-grid:before{content:""}.jupyter-wrapper .bp3-icon-grid-view:before{content:""}.jupyter-wrapper .bp3-icon-group-objects:before{content:""}.jupyter-wrapper .bp3-icon-grouped-bar-chart:before{content:""}.jupyter-wrapper .bp3-icon-hand:before{content:""}.jupyter-wrapper .bp3-icon-hand-down:before{content:""}.jupyter-wrapper .bp3-icon-hand-left:before{content:""}.jupyter-wrapper .bp3-icon-hand-right:before{content:""}.jupyter-wrapper .bp3-icon-hand-up:before{content:""}.jupyter-wrapper .bp3-icon-header:before{content:""}.jupyter-wrapper .bp3-icon-header-one:before{content:""}.jupyter-wrapper .bp3-icon-header-two:before{content:""}.jupyter-wrapper .bp3-icon-headset:before{content:""}.jupyter-wrapper .bp3-icon-heart:before{content:"♥"}.jupyter-wrapper .bp3-icon-heart-broken:before{content:""}.jupyter-wrapper .bp3-icon-heat-grid:before{content:""}.jupyter-wrapper .bp3-icon-heatmap:before{content:""}.jupyter-wrapper .bp3-icon-help:before{content:"?"}.jupyter-wrapper .bp3-icon-helper-management:before{content:""}.jupyter-wrapper .bp3-icon-highlight:before{content:""}.jupyter-wrapper .bp3-icon-history:before{content:""}.jupyter-wrapper .bp3-icon-home:before{content:"⌂"}.jupyter-wrapper .bp3-icon-horizontal-bar-chart:before{content:""}.jupyter-wrapper .bp3-icon-horizontal-bar-chart-asc:before{content:""}.jupyter-wrapper .bp3-icon-horizontal-bar-chart-desc:before{content:""}.jupyter-wrapper .bp3-icon-horizontal-distribution:before{content:""}.jupyter-wrapper .bp3-icon-id-number:before{content:""}.jupyter-wrapper .bp3-icon-image-rotate-left:before{content:""}.jupyter-wrapper .bp3-icon-image-rotate-right:before{content:""}.jupyter-wrapper .bp3-icon-import:before{content:""}.jupyter-wrapper .bp3-icon-inbox:before{content:""}.jupyter-wrapper .bp3-icon-inbox-filtered:before{content:""}.jupyter-wrapper .bp3-icon-inbox-geo:before{content:""}.jupyter-wrapper .bp3-icon-inbox-search:before{content:""}.jupyter-wrapper .bp3-icon-inbox-update:before{content:""}.jupyter-wrapper .bp3-icon-info-sign:before{content:"ℹ"}.jupyter-wrapper .bp3-icon-inheritance:before{content:""}.jupyter-wrapper .bp3-icon-inner-join:before{content:""}.jupyter-wrapper .bp3-icon-insert:before{content:""}.jupyter-wrapper .bp3-icon-intersection:before{content:""}.jupyter-wrapper .bp3-icon-ip-address:before{content:""}.jupyter-wrapper .bp3-icon-issue:before{content:""}.jupyter-wrapper .bp3-icon-issue-closed:before{content:""}.jupyter-wrapper .bp3-icon-issue-new:before{content:""}.jupyter-wrapper .bp3-icon-italic:before{content:""}.jupyter-wrapper .bp3-icon-join-table:before{content:""}.jupyter-wrapper .bp3-icon-key:before{content:""}.jupyter-wrapper .bp3-icon-key-backspace:before{content:""}.jupyter-wrapper .bp3-icon-key-command:before{content:""}.jupyter-wrapper .bp3-icon-key-control:before{content:""}.jupyter-wrapper .bp3-icon-key-delete:before{content:""}.jupyter-wrapper .bp3-icon-key-enter:before{content:""}.jupyter-wrapper .bp3-icon-key-escape:before{content:""}.jupyter-wrapper .bp3-icon-key-option:before{content:""}.jupyter-wrapper .bp3-icon-key-shift:before{content:""}.jupyter-wrapper .bp3-icon-key-tab:before{content:""}.jupyter-wrapper .bp3-icon-known-vehicle:before{content:""}.jupyter-wrapper .bp3-icon-lab-test:before{content:""}.jupyter-wrapper .bp3-icon-label:before{content:""}.jupyter-wrapper .bp3-icon-layer:before{content:""}.jupyter-wrapper .bp3-icon-layers:before{content:""}.jupyter-wrapper .bp3-icon-layout:before{content:""}.jupyter-wrapper .bp3-icon-layout-auto:before{content:""}.jupyter-wrapper .bp3-icon-layout-balloon:before{content:""}.jupyter-wrapper .bp3-icon-layout-circle:before{content:""}.jupyter-wrapper .bp3-icon-layout-grid:before{content:""}.jupyter-wrapper .bp3-icon-layout-group-by:before{content:""}.jupyter-wrapper .bp3-icon-layout-hierarchy:before{content:""}.jupyter-wrapper .bp3-icon-layout-linear:before{content:""}.jupyter-wrapper .bp3-icon-layout-skew-grid:before{content:""}.jupyter-wrapper .bp3-icon-layout-sorted-clusters:before{content:""}.jupyter-wrapper .bp3-icon-learning:before{content:""}.jupyter-wrapper .bp3-icon-left-join:before{content:""}.jupyter-wrapper .bp3-icon-less-than:before{content:""}.jupyter-wrapper .bp3-icon-less-than-or-equal-to:before{content:""}.jupyter-wrapper .bp3-icon-lifesaver:before{content:""}.jupyter-wrapper .bp3-icon-lightbulb:before{content:""}.jupyter-wrapper .bp3-icon-link:before{content:""}.jupyter-wrapper .bp3-icon-list:before{content:"☰"}.jupyter-wrapper .bp3-icon-list-columns:before{content:""}.jupyter-wrapper .bp3-icon-list-detail-view:before{content:""}.jupyter-wrapper .bp3-icon-locate:before{content:""}.jupyter-wrapper .bp3-icon-lock:before{content:""}.jupyter-wrapper .bp3-icon-log-in:before{content:""}.jupyter-wrapper .bp3-icon-log-out:before{content:""}.jupyter-wrapper .bp3-icon-manual:before{content:""}.jupyter-wrapper .bp3-icon-manually-entered-data:before{content:""}.jupyter-wrapper .bp3-icon-map:before{content:""}.jupyter-wrapper .bp3-icon-map-create:before{content:""}.jupyter-wrapper .bp3-icon-map-marker:before{content:""}.jupyter-wrapper .bp3-icon-maximize:before{content:""}.jupyter-wrapper .bp3-icon-media:before{content:""}.jupyter-wrapper .bp3-icon-menu:before{content:""}.jupyter-wrapper .bp3-icon-menu-closed:before{content:""}.jupyter-wrapper .bp3-icon-menu-open:before{content:""}.jupyter-wrapper .bp3-icon-merge-columns:before{content:""}.jupyter-wrapper .bp3-icon-merge-links:before{content:""}.jupyter-wrapper .bp3-icon-minimize:before{content:""}.jupyter-wrapper .bp3-icon-minus:before{content:"−"}.jupyter-wrapper .bp3-icon-mobile-phone:before{content:""}.jupyter-wrapper .bp3-icon-mobile-video:before{content:""}.jupyter-wrapper .bp3-icon-moon:before{content:""}.jupyter-wrapper .bp3-icon-more:before{content:""}.jupyter-wrapper .bp3-icon-mountain:before{content:""}.jupyter-wrapper .bp3-icon-move:before{content:""}.jupyter-wrapper .bp3-icon-mugshot:before{content:""}.jupyter-wrapper .bp3-icon-multi-select:before{content:""}.jupyter-wrapper .bp3-icon-music:before{content:""}.jupyter-wrapper .bp3-icon-new-drawing:before{content:""}.jupyter-wrapper .bp3-icon-new-grid-item:before{content:""}.jupyter-wrapper .bp3-icon-new-layer:before{content:""}.jupyter-wrapper .bp3-icon-new-layers:before{content:""}.jupyter-wrapper .bp3-icon-new-link:before{content:""}.jupyter-wrapper .bp3-icon-new-object:before{content:""}.jupyter-wrapper .bp3-icon-new-person:before{content:""}.jupyter-wrapper .bp3-icon-new-prescription:before{content:""}.jupyter-wrapper .bp3-icon-new-text-box:before{content:""}.jupyter-wrapper .bp3-icon-ninja:before{content:""}.jupyter-wrapper .bp3-icon-not-equal-to:before{content:""}.jupyter-wrapper .bp3-icon-notifications:before{content:""}.jupyter-wrapper .bp3-icon-notifications-updated:before{content:""}.jupyter-wrapper .bp3-icon-numbered-list:before{content:""}.jupyter-wrapper .bp3-icon-numerical:before{content:""}.jupyter-wrapper .bp3-icon-office:before{content:""}.jupyter-wrapper .bp3-icon-offline:before{content:""}.jupyter-wrapper .bp3-icon-oil-field:before{content:""}.jupyter-wrapper .bp3-icon-one-column:before{content:""}.jupyter-wrapper .bp3-icon-outdated:before{content:""}.jupyter-wrapper .bp3-icon-page-layout:before{content:""}.jupyter-wrapper .bp3-icon-panel-stats:before{content:""}.jupyter-wrapper .bp3-icon-panel-table:before{content:""}.jupyter-wrapper .bp3-icon-paperclip:before{content:""}.jupyter-wrapper .bp3-icon-paragraph:before{content:""}.jupyter-wrapper .bp3-icon-path:before{content:""}.jupyter-wrapper .bp3-icon-path-search:before{content:""}.jupyter-wrapper .bp3-icon-pause:before{content:""}.jupyter-wrapper .bp3-icon-people:before{content:""}.jupyter-wrapper .bp3-icon-percentage:before{content:""}.jupyter-wrapper .bp3-icon-person:before{content:""}.jupyter-wrapper .bp3-icon-phone:before{content:"☎"}.jupyter-wrapper .bp3-icon-pie-chart:before{content:""}.jupyter-wrapper .bp3-icon-pin:before{content:""}.jupyter-wrapper .bp3-icon-pivot:before{content:""}.jupyter-wrapper .bp3-icon-pivot-table:before{content:""}.jupyter-wrapper .bp3-icon-play:before{content:""}.jupyter-wrapper .bp3-icon-plus:before{content:"+"}.jupyter-wrapper .bp3-icon-polygon-filter:before{content:""}.jupyter-wrapper .bp3-icon-power:before{content:""}.jupyter-wrapper .bp3-icon-predictive-analysis:before{content:""}.jupyter-wrapper .bp3-icon-prescription:before{content:""}.jupyter-wrapper .bp3-icon-presentation:before{content:""}.jupyter-wrapper .bp3-icon-print:before{content:"⎙"}.jupyter-wrapper .bp3-icon-projects:before{content:""}.jupyter-wrapper .bp3-icon-properties:before{content:""}.jupyter-wrapper .bp3-icon-property:before{content:""}.jupyter-wrapper .bp3-icon-publish-function:before{content:""}.jupyter-wrapper .bp3-icon-pulse:before{content:""}.jupyter-wrapper .bp3-icon-random:before{content:""}.jupyter-wrapper .bp3-icon-record:before{content:""}.jupyter-wrapper .bp3-icon-redo:before{content:""}.jupyter-wrapper .bp3-icon-refresh:before{content:""}.jupyter-wrapper .bp3-icon-regression-chart:before{content:""}.jupyter-wrapper .bp3-icon-remove:before{content:""}.jupyter-wrapper .bp3-icon-remove-column:before{content:""}.jupyter-wrapper .bp3-icon-remove-column-left:before{content:""}.jupyter-wrapper .bp3-icon-remove-column-right:before{content:""}.jupyter-wrapper .bp3-icon-remove-row-bottom:before{content:""}.jupyter-wrapper .bp3-icon-remove-row-top:before{content:""}.jupyter-wrapper .bp3-icon-repeat:before{content:""}.jupyter-wrapper .bp3-icon-reset:before{content:""}.jupyter-wrapper .bp3-icon-resolve:before{content:""}.jupyter-wrapper .bp3-icon-rig:before{content:""}.jupyter-wrapper .bp3-icon-right-join:before{content:""}.jupyter-wrapper .bp3-icon-ring:before{content:""}.jupyter-wrapper .bp3-icon-rotate-document:before{content:""}.jupyter-wrapper .bp3-icon-rotate-page:before{content:""}.jupyter-wrapper .bp3-icon-satellite:before{content:""}.jupyter-wrapper .bp3-icon-saved:before{content:""}.jupyter-wrapper .bp3-icon-scatter-plot:before{content:""}.jupyter-wrapper .bp3-icon-search:before{content:""}.jupyter-wrapper .bp3-icon-search-around:before{content:""}.jupyter-wrapper .bp3-icon-search-template:before{content:""}.jupyter-wrapper .bp3-icon-search-text:before{content:""}.jupyter-wrapper .bp3-icon-segmented-control:before{content:""}.jupyter-wrapper .bp3-icon-select:before{content:""}.jupyter-wrapper .bp3-icon-selection:before{content:"⦿"}.jupyter-wrapper .bp3-icon-send-to:before{content:""}.jupyter-wrapper .bp3-icon-send-to-graph:before{content:""}.jupyter-wrapper .bp3-icon-send-to-map:before{content:""}.jupyter-wrapper .bp3-icon-series-add:before{content:""}.jupyter-wrapper .bp3-icon-series-configuration:before{content:""}.jupyter-wrapper .bp3-icon-series-derived:before{content:""}.jupyter-wrapper .bp3-icon-series-filtered:before{content:""}.jupyter-wrapper .bp3-icon-series-search:before{content:""}.jupyter-wrapper .bp3-icon-settings:before{content:""}.jupyter-wrapper .bp3-icon-share:before{content:""}.jupyter-wrapper .bp3-icon-shield:before{content:""}.jupyter-wrapper .bp3-icon-shop:before{content:""}.jupyter-wrapper .bp3-icon-shopping-cart:before{content:""}.jupyter-wrapper .bp3-icon-signal-search:before{content:""}.jupyter-wrapper .bp3-icon-sim-card:before{content:""}.jupyter-wrapper .bp3-icon-slash:before{content:""}.jupyter-wrapper .bp3-icon-small-cross:before{content:""}.jupyter-wrapper .bp3-icon-small-minus:before{content:""}.jupyter-wrapper .bp3-icon-small-plus:before{content:""}.jupyter-wrapper .bp3-icon-small-tick:before{content:""}.jupyter-wrapper .bp3-icon-snowflake:before{content:""}.jupyter-wrapper .bp3-icon-social-media:before{content:""}.jupyter-wrapper .bp3-icon-sort:before{content:""}.jupyter-wrapper .bp3-icon-sort-alphabetical:before{content:""}.jupyter-wrapper .bp3-icon-sort-alphabetical-desc:before{content:""}.jupyter-wrapper .bp3-icon-sort-asc:before{content:""}.jupyter-wrapper .bp3-icon-sort-desc:before{content:""}.jupyter-wrapper .bp3-icon-sort-numerical:before{content:""}.jupyter-wrapper .bp3-icon-sort-numerical-desc:before{content:""}.jupyter-wrapper .bp3-icon-split-columns:before{content:""}.jupyter-wrapper .bp3-icon-square:before{content:""}.jupyter-wrapper .bp3-icon-stacked-chart:before{content:""}.jupyter-wrapper .bp3-icon-star:before{content:"★"}.jupyter-wrapper .bp3-icon-star-empty:before{content:"☆"}.jupyter-wrapper .bp3-icon-step-backward:before{content:""}.jupyter-wrapper .bp3-icon-step-chart:before{content:""}.jupyter-wrapper .bp3-icon-step-forward:before{content:""}.jupyter-wrapper .bp3-icon-stop:before{content:""}.jupyter-wrapper .bp3-icon-stopwatch:before{content:""}.jupyter-wrapper .bp3-icon-strikethrough:before{content:""}.jupyter-wrapper .bp3-icon-style:before{content:""}.jupyter-wrapper .bp3-icon-swap-horizontal:before{content:""}.jupyter-wrapper .bp3-icon-swap-vertical:before{content:""}.jupyter-wrapper .bp3-icon-symbol-circle:before{content:""}.jupyter-wrapper .bp3-icon-symbol-cross:before{content:""}.jupyter-wrapper .bp3-icon-symbol-diamond:before{content:""}.jupyter-wrapper .bp3-icon-symbol-square:before{content:""}.jupyter-wrapper .bp3-icon-symbol-triangle-down:before{content:""}.jupyter-wrapper .bp3-icon-symbol-triangle-up:before{content:""}.jupyter-wrapper .bp3-icon-tag:before{content:""}.jupyter-wrapper .bp3-icon-take-action:before{content:""}.jupyter-wrapper .bp3-icon-taxi:before{content:""}.jupyter-wrapper .bp3-icon-text-highlight:before{content:""}.jupyter-wrapper .bp3-icon-th:before{content:""}.jupyter-wrapper .bp3-icon-th-derived:before{content:""}.jupyter-wrapper .bp3-icon-th-disconnect:before{content:""}.jupyter-wrapper .bp3-icon-th-filtered:before{content:""}.jupyter-wrapper .bp3-icon-th-list:before{content:""}.jupyter-wrapper .bp3-icon-thumbs-down:before{content:""}.jupyter-wrapper .bp3-icon-thumbs-up:before{content:""}.jupyter-wrapper .bp3-icon-tick:before{content:"✓"}.jupyter-wrapper .bp3-icon-tick-circle:before{content:""}.jupyter-wrapper .bp3-icon-time:before{content:"⏲"}.jupyter-wrapper .bp3-icon-timeline-area-chart:before{content:""}.jupyter-wrapper .bp3-icon-timeline-bar-chart:before{content:""}.jupyter-wrapper .bp3-icon-timeline-events:before{content:""}.jupyter-wrapper .bp3-icon-timeline-line-chart:before{content:""}.jupyter-wrapper .bp3-icon-tint:before{content:""}.jupyter-wrapper .bp3-icon-torch:before{content:""}.jupyter-wrapper .bp3-icon-tractor:before{content:""}.jupyter-wrapper .bp3-icon-train:before{content:""}.jupyter-wrapper .bp3-icon-translate:before{content:""}.jupyter-wrapper .bp3-icon-trash:before{content:""}.jupyter-wrapper .bp3-icon-tree:before{content:""}.jupyter-wrapper .bp3-icon-trending-down:before{content:""}.jupyter-wrapper .bp3-icon-trending-up:before{content:""}.jupyter-wrapper .bp3-icon-truck:before{content:""}.jupyter-wrapper .bp3-icon-two-columns:before{content:""}.jupyter-wrapper .bp3-icon-unarchive:before{content:""}.jupyter-wrapper .bp3-icon-underline:before{content:"⎁"}.jupyter-wrapper .bp3-icon-undo:before{content:"⎌"}.jupyter-wrapper .bp3-icon-ungroup-objects:before{content:""}.jupyter-wrapper .bp3-icon-unknown-vehicle:before{content:""}.jupyter-wrapper .bp3-icon-unlock:before{content:""}.jupyter-wrapper .bp3-icon-unpin:before{content:""}.jupyter-wrapper .bp3-icon-unresolve:before{content:""}.jupyter-wrapper .bp3-icon-updated:before{content:""}.jupyter-wrapper .bp3-icon-upload:before{content:""}.jupyter-wrapper .bp3-icon-user:before{content:""}.jupyter-wrapper .bp3-icon-variable:before{content:""}.jupyter-wrapper .bp3-icon-vertical-bar-chart-asc:before{content:""}.jupyter-wrapper .bp3-icon-vertical-bar-chart-desc:before{content:""}.jupyter-wrapper .bp3-icon-vertical-distribution:before{content:""}.jupyter-wrapper .bp3-icon-video:before{content:""}.jupyter-wrapper .bp3-icon-volume-down:before{content:""}.jupyter-wrapper .bp3-icon-volume-off:before{content:""}.jupyter-wrapper .bp3-icon-volume-up:before{content:""}.jupyter-wrapper .bp3-icon-walk:before{content:""}.jupyter-wrapper .bp3-icon-warning-sign:before{content:""}.jupyter-wrapper .bp3-icon-waterfall-chart:before{content:""}.jupyter-wrapper .bp3-icon-widget:before{content:""}.jupyter-wrapper .bp3-icon-widget-button:before{content:""}.jupyter-wrapper .bp3-icon-widget-footer:before{content:""}.jupyter-wrapper .bp3-icon-widget-header:before{content:""}.jupyter-wrapper .bp3-icon-wrench:before{content:""}.jupyter-wrapper .bp3-icon-zoom-in:before{content:""}.jupyter-wrapper .bp3-icon-zoom-out:before{content:""}.jupyter-wrapper .bp3-icon-zoom-to-fit:before{content:""}.jupyter-wrapper .bp3-submenu>.bp3-popover-wrapper{display:block}.jupyter-wrapper .bp3-submenu .bp3-popover-target{display:block}.jupyter-wrapper .bp3-submenu.bp3-popover{-webkit-box-shadow:none;box-shadow:none;padding:0 5px}.jupyter-wrapper .bp3-submenu.bp3-popover>.bp3-popover-content{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33}.jupyter-wrapper .bp3-dark .bp3-submenu.bp3-popover,.jupyter-wrapper .bp3-submenu.bp3-popover.bp3-dark{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-submenu.bp3-popover>.bp3-popover-content,.jupyter-wrapper .bp3-submenu.bp3-popover.bp3-dark>.bp3-popover-content{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-menu{background:#ffffff;border-radius:3px;color:#182026;list-style:none;margin:0;min-width:180px;padding:5px;text-align:left}.jupyter-wrapper .bp3-menu-divider{border-top:1px solid rgba(16,22,26,.15);display:block;margin:5px}.jupyter-wrapper .bp3-dark .bp3-menu-divider{border-top-color:#ffffff26}.jupyter-wrapper .bp3-menu-item{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;border-radius:2px;color:inherit;line-height:20px;padding:5px 7px;text-decoration:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-menu-item>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-menu-item>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item>*{margin-right:7px}.jupyter-wrapper .bp3-menu-item:empty:before,.jupyter-wrapper .bp3-menu-item>:last-child{margin-right:0}.jupyter-wrapper .bp3-menu-item>.bp3-fill{word-break:break-word}.jupyter-wrapper .bp3-menu-item:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item{background-color:#a7b6c24d;cursor:pointer;text-decoration:none}.jupyter-wrapper .bp3-menu-item.bp3-disabled{background-color:inherit;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-menu-item{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-menu-item{background-color:#8a9ba826;color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled{background-color:inherit;color:#a7b6c299}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active{background-color:#137cbd}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active{background-color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover:before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover:after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active{background-color:#0f9960}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active{background-color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover:before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover:after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active{background-color:#d9822b}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active{background-color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover:before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover:after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active{background-color:#db3737}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active{background-color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover:before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover:after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item:before{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;margin-right:7px}.jupyter-wrapper .bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item>.bp3-icon{color:#5c7080;margin-top:2px}.jupyter-wrapper .bp3-menu-item .bp3-menu-item-label{color:#5c7080}.jupyter-wrapper .bp3-menu-item:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-active,.jupyter-wrapper .bp3-menu-item:active{background-color:#7386944d}.jupyter-wrapper .bp3-menu-item.bp3-disabled{background-color:inherit!important;color:#5c708099!important;cursor:not-allowed!important;outline:none!important}.jupyter-wrapper .bp3-menu-item.bp3-disabled:before,.jupyter-wrapper .bp3-menu-item.bp3-disabled>.bp3-icon,.jupyter-wrapper .bp3-menu-item.bp3-disabled .bp3-menu-item-label{color:#5c708099!important}.jupyter-wrapper .bp3-large .bp3-menu-item{font-size:16px;line-height:22px;padding:9px 7px}.jupyter-wrapper .bp3-large .bp3-menu-item .bp3-icon{margin-top:3px}.jupyter-wrapper .bp3-large .bp3-menu-item:before{font-family:Icons20,sans-serif;font-size:20px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;margin-right:10px;margin-top:1px}.jupyter-wrapper button.bp3-menu-item{background:none;border:none;text-align:left;width:100%}.jupyter-wrapper .bp3-menu-header{border-top:1px solid rgba(16,22,26,.15);display:block;margin:5px;cursor:default;padding-left:2px}.jupyter-wrapper .bp3-dark .bp3-menu-header{border-top-color:#ffffff26}.jupyter-wrapper .bp3-menu-header:first-of-type{border-top:none}.jupyter-wrapper .bp3-menu-header>h6{color:#182026;font-weight:600;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;line-height:17px;margin:0;padding:10px 7px 0 1px}.jupyter-wrapper .bp3-menu-header:first-of-type>h6{padding-top:0}.jupyter-wrapper .bp3-large .bp3-menu-header>h6{font-size:18px;padding-bottom:5px;padding-top:15px}.jupyter-wrapper .bp3-large .bp3-menu-header:first-of-type>h6{padding-top:0}.jupyter-wrapper .bp3-dark .bp3-menu{background:#30404d;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{background-color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active{background-color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover:before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover:after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{background-color:#0f9960}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active{background-color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover:before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover:after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{background-color:#d9822b}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active{background-color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover:before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover:after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{background-color:#db3737}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active{background-color:#c23030}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover:before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover:after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item>.bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-menu-item .bp3-menu-item-label{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item:active{background-color:#8a9ba84d}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled{color:#a7b6c299!important}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{color:#a7b6c299!important}.jupyter-wrapper .bp3-dark .bp3-menu-divider,.jupyter-wrapper .bp3-dark .bp3-menu-header{border-color:#ffffff26}.jupyter-wrapper .bp3-dark .bp3-menu-header>h6{color:#f5f8fa}.jupyter-wrapper .bp3-label .bp3-menu{margin-top:5px}.jupyter-wrapper .bp3-navbar{background-color:#fff;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 0 #10161a00,0 1px 1px #10161a33;height:50px;padding:0 15px;position:relative;width:100%;z-index:10}.jupyter-wrapper .bp3-navbar.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-navbar{background-color:#394b59}.jupyter-wrapper .bp3-navbar.bp3-dark{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-navbar{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66}.jupyter-wrapper .bp3-navbar.bp3-fixed-top{left:0;position:fixed;right:0;top:0}.jupyter-wrapper .bp3-navbar-heading{font-size:16px;margin-right:15px}.jupyter-wrapper .bp3-navbar-group{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;height:50px}.jupyter-wrapper .bp3-navbar-group.bp3-align-left{float:left}.jupyter-wrapper .bp3-navbar-group.bp3-align-right{float:right}.jupyter-wrapper .bp3-navbar-divider{border-left:1px solid rgba(16,22,26,.15);height:20px;margin:0 10px}.jupyter-wrapper .bp3-dark .bp3-navbar-divider{border-left-color:#ffffff26}.jupyter-wrapper .bp3-non-ideal-state{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center;width:100%}.jupyter-wrapper .bp3-non-ideal-state>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-non-ideal-state>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-non-ideal-state:before,.jupyter-wrapper .bp3-non-ideal-state>*{margin-bottom:20px}.jupyter-wrapper .bp3-non-ideal-state:empty:before,.jupyter-wrapper .bp3-non-ideal-state>:last-child{margin-bottom:0}.jupyter-wrapper .bp3-non-ideal-state>*{max-width:400px}.jupyter-wrapper .bp3-non-ideal-state-visual{color:#5c708099;font-size:60px}.jupyter-wrapper .bp3-dark .bp3-non-ideal-state-visual{color:#a7b6c299}.jupyter-wrapper .bp3-overflow-list{display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:nowrap;flex-wrap:nowrap;min-width:0}.jupyter-wrapper .bp3-overflow-list-spacer{-ms-flex-negative:1;flex-shrink:1;width:1px}.jupyter-wrapper body.bp3-overlay-open{overflow:hidden}.jupyter-wrapper .bp3-overlay{bottom:0;left:0;position:static;right:0;top:0;z-index:20}.jupyter-wrapper .bp3-overlay:not(.bp3-overlay-open){pointer-events:none}.jupyter-wrapper .bp3-overlay.bp3-overlay-container{overflow:hidden;position:fixed}.jupyter-wrapper .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{position:absolute}.jupyter-wrapper .bp3-overlay.bp3-overlay-scroll-container{overflow:auto;position:fixed}.jupyter-wrapper .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{position:absolute}.jupyter-wrapper .bp3-overlay.bp3-overlay-inline{display:inline;overflow:visible}.jupyter-wrapper .bp3-overlay-content{position:fixed;z-index:20}.jupyter-wrapper .bp3-overlay-inline .bp3-overlay-content,.jupyter-wrapper .bp3-overlay-scroll-container .bp3-overlay-content{position:absolute}.jupyter-wrapper .bp3-overlay-backdrop{bottom:0;left:0;position:fixed;right:0;top:0;opacity:1;background-color:#10161ab3;overflow:auto;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;z-index:20}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-enter,.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-appear{opacity:0}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-enter-active,.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-appear-active{opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-exit{opacity:1}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-exit-active{opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-overlay-backdrop:focus{outline:none}.jupyter-wrapper .bp3-overlay-inline .bp3-overlay-backdrop{position:absolute}.jupyter-wrapper .bp3-panel-stack{overflow:hidden;position:relative}.jupyter-wrapper .bp3-panel-stack-header{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-shadow:0 1px rgba(16,22,26,.15);box-shadow:0 1px #10161a26;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-negative:0;flex-shrink:0;height:30px;z-index:1}.jupyter-wrapper .bp3-dark .bp3-panel-stack-header{-webkit-box-shadow:0 1px rgba(255,255,255,.15);box-shadow:0 1px #ffffff26}.jupyter-wrapper .bp3-panel-stack-header>span{-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1;flex:1}.jupyter-wrapper .bp3-panel-stack-header .bp3-heading{margin:0 5px}.jupyter-wrapper .bp3-button.bp3-panel-stack-header-back{margin-left:5px;padding-left:0;white-space:nowrap}.jupyter-wrapper .bp3-button.bp3-panel-stack-header-back .bp3-icon{margin:0 2px}.jupyter-wrapper .bp3-panel-stack-view{bottom:0;left:0;position:absolute;right:0;top:0;background-color:#fff;border-right:1px solid rgba(16,22,26,.15);display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin-right:-1px;overflow-y:auto;z-index:1}.jupyter-wrapper .bp3-dark .bp3-panel-stack-view{background-color:#30404d}.jupyter-wrapper .bp3-panel-stack-view:nth-last-child(n+4){display:none}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-enter,.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-appear{-webkit-transform:translateX(100%);transform:translate(100%);opacity:0}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-enter-active,.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-appear-active{-webkit-transform:translate(0%);transform:translate(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-exit{-webkit-transform:translate(0%);transform:translate(0);opacity:1}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-exit-active{-webkit-transform:translateX(-50%);transform:translate(-50%);opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-enter,.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-appear{-webkit-transform:translateX(-50%);transform:translate(-50%);opacity:0}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-enter-active,.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-appear-active{-webkit-transform:translate(0%);transform:translate(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-exit{-webkit-transform:translate(0%);transform:translate(0);opacity:1}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-exit-active{-webkit-transform:translateX(100%);transform:translate(100%);opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack2{overflow:hidden;position:relative}.jupyter-wrapper .bp3-panel-stack2-header{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-shadow:0 1px rgba(16,22,26,.15);box-shadow:0 1px #10161a26;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-negative:0;flex-shrink:0;height:30px;z-index:1}.jupyter-wrapper .bp3-dark .bp3-panel-stack2-header{-webkit-box-shadow:0 1px rgba(255,255,255,.15);box-shadow:0 1px #ffffff26}.jupyter-wrapper .bp3-panel-stack2-header>span{-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1;flex:1}.jupyter-wrapper .bp3-panel-stack2-header .bp3-heading{margin:0 5px}.jupyter-wrapper .bp3-button.bp3-panel-stack2-header-back{margin-left:5px;padding-left:0;white-space:nowrap}.jupyter-wrapper .bp3-button.bp3-panel-stack2-header-back .bp3-icon{margin:0 2px}.jupyter-wrapper .bp3-panel-stack2-view{bottom:0;left:0;position:absolute;right:0;top:0;background-color:#fff;border-right:1px solid rgba(16,22,26,.15);display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin-right:-1px;overflow-y:auto;z-index:1}.jupyter-wrapper .bp3-dark .bp3-panel-stack2-view{background-color:#30404d}.jupyter-wrapper .bp3-panel-stack2-view:nth-last-child(n+4){display:none}.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-enter,.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-appear{-webkit-transform:translateX(100%);transform:translate(100%);opacity:0}.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-enter-active,.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-appear-active{-webkit-transform:translate(0%);transform:translate(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-exit{-webkit-transform:translate(0%);transform:translate(0);opacity:1}.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-exit-active{-webkit-transform:translateX(-50%);transform:translate(-50%);opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-enter,.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-appear{-webkit-transform:translateX(-50%);transform:translate(-50%);opacity:0}.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-enter-active,.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-appear-active{-webkit-transform:translate(0%);transform:translate(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-exit{-webkit-transform:translate(0%);transform:translate(0);opacity:1}.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-exit-active{-webkit-transform:translateX(100%);transform:translate(100%);opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-popover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;-webkit-transform:scale(1);transform:scale(1);border-radius:3px;display:inline-block;z-index:20}.jupyter-wrapper .bp3-popover .bp3-popover-arrow{height:30px;position:absolute;width:30px}.jupyter-wrapper .bp3-popover .bp3-popover-arrow:before{height:20px;margin:5px;width:20px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover{margin-bottom:17px;margin-top:-17px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow{bottom:-11px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(-90deg);transform:rotate(-90deg)}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover{margin-left:17px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow{left:-11px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(0);transform:rotate(0)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover{margin-top:17px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow{top:-11px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover{margin-left:-17px;margin-right:17px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow{right:-11px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.jupyter-wrapper .bp3-tether-element-attached-middle>.bp3-popover>.bp3-popover-arrow{top:50%;-webkit-transform:translateY(-50%);transform:translateY(-50%)}.jupyter-wrapper .bp3-tether-element-attached-center>.bp3-popover>.bp3-popover-arrow{right:50%;-webkit-transform:translateX(50%);transform:translate(50%)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow{top:-.3934px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow{right:-.3934px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow{left:-.3934px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow{bottom:-.3934px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:top left;transform-origin:top left}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:top center;transform-origin:top center}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:top right;transform-origin:top right}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:center left;transform-origin:center left}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:center center;transform-origin:center center}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:center right;transform-origin:center right}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:bottom left;transform-origin:bottom left}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:bottom center;transform-origin:bottom center}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:bottom right;transform-origin:bottom right}.jupyter-wrapper .bp3-popover .bp3-popover-content{background:#ffffff;color:inherit}.jupyter-wrapper .bp3-popover .bp3-popover-arrow:before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.2);box-shadow:1px 1px 6px #10161a33}.jupyter-wrapper .bp3-popover .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.1}.jupyter-wrapper .bp3-popover .bp3-popover-arrow-fill{fill:#fff}.jupyter-wrapper .bp3-popover-enter>.bp3-popover,.jupyter-wrapper .bp3-popover-appear>.bp3-popover{-webkit-transform:scale(.3);transform:scale(.3)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-popover,.jupyter-wrapper .bp3-popover-appear-active>.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-popover-exit>.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-popover{-webkit-transform:scale(.3);transform:scale(.3);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-popover .bp3-popover-content{border-radius:3px;position:relative}.jupyter-wrapper .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{max-width:350px;padding:20px}.jupyter-wrapper .bp3-popover-target+.bp3-overlay .bp3-popover.bp3-popover-content-sizing{width:350px}.jupyter-wrapper .bp3-popover.bp3-minimal{margin:0!important}.jupyter-wrapper .bp3-popover.bp3-minimal .bp3-popover-arrow{display:none}.jupyter-wrapper .bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-enter>.bp3-popover.bp3-minimal.bp3-popover,.jupyter-wrapper .bp3-popover-appear>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-popover.bp3-minimal.bp3-popover,.jupyter-wrapper .bp3-popover-appear-active>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-popover-exit>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-popover.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-popover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-content,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-content{background:#30404d;color:inherit}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow:before,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow:before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.4);box-shadow:1px 1px 6px #10161a66}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow-border,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.2}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow-fill,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow-fill{fill:#30404d}.jupyter-wrapper .bp3-popover-arrow:before{border-radius:2px;content:"";display:block;position:absolute;-webkit-transform:rotate(45deg);transform:rotate(45deg)}.jupyter-wrapper .bp3-tether-pinned .bp3-popover-arrow{display:none}.jupyter-wrapper .bp3-popover-backdrop{background:rgba(255,255,255,0)}.jupyter-wrapper .bp3-transition-container{opacity:1;display:-webkit-box;display:-ms-flexbox;display:flex;z-index:20}.jupyter-wrapper .bp3-transition-container.bp3-popover-enter,.jupyter-wrapper .bp3-transition-container.bp3-popover-appear{opacity:0}.jupyter-wrapper .bp3-transition-container.bp3-popover-enter-active,.jupyter-wrapper .bp3-transition-container.bp3-popover-appear-active{opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-transition-container.bp3-popover-exit{opacity:1}.jupyter-wrapper .bp3-transition-container.bp3-popover-exit-active{opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-transition-container:focus{outline:none}.jupyter-wrapper .bp3-transition-container.bp3-popover-leave .bp3-popover-content{pointer-events:none}.jupyter-wrapper .bp3-transition-container[data-x-out-of-boundaries]{display:none}.jupyter-wrapper span.bp3-popover-target{display:inline-block}.jupyter-wrapper .bp3-popover-wrapper.bp3-fill{width:100%}.jupyter-wrapper .bp3-portal{left:0;position:absolute;right:0;top:0}@-webkit-keyframes linear-progress-bar-stripes{0%{background-position:0 0}to{background-position:30px 0}}@keyframes linear-progress-bar-stripes{0%{background-position:0 0}to{background-position:30px 0}}.jupyter-wrapper .bp3-progress-bar{background:rgba(92,112,128,.2);border-radius:40px;display:block;height:8px;overflow:hidden;position:relative;width:100%}.jupyter-wrapper .bp3-progress-bar .bp3-progress-meter{background:linear-gradient(-45deg,rgba(255,255,255,.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.2) 50%,rgba(255,255,255,.2) 75%,transparent 75%);background-color:#5c7080cc;background-size:30px 30px;border-radius:40px;height:100%;position:absolute;-webkit-transition:width .2s cubic-bezier(.4,1,.75,.9);transition:width .2s cubic-bezier(.4,1,.75,.9);width:100%}.jupyter-wrapper .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{animation:linear-progress-bar-stripes .3s linear infinite reverse}.jupyter-wrapper .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{background-image:none}.jupyter-wrapper .bp3-dark .bp3-progress-bar{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-dark .bp3-progress-bar .bp3-progress-meter{background-color:#8a9ba8}.jupyter-wrapper .bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{background-color:#137cbd}.jupyter-wrapper .bp3-progress-bar.bp3-intent-success .bp3-progress-meter{background-color:#0f9960}.jupyter-wrapper .bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{background-color:#d9822b}.jupyter-wrapper .bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{background-color:#db3737}@-webkit-keyframes skeleton-glow{0%{background:rgba(206,217,224,.2);border-color:#ced9e033}to{background:rgba(92,112,128,.2);border-color:#5c708033}}@keyframes skeleton-glow{0%{background:rgba(206,217,224,.2);border-color:#ced9e033}to{background:rgba(92,112,128,.2);border-color:#5c708033}}.jupyter-wrapper .bp3-skeleton{-webkit-animation:1s linear infinite alternate skeleton-glow;animation:1s linear infinite alternate skeleton-glow;background:rgba(206,217,224,.2);background-clip:padding-box!important;border-color:#ced9e033!important;border-radius:2px;-webkit-box-shadow:none!important;box-shadow:none!important;color:transparent!important;cursor:default;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-skeleton:before,.jupyter-wrapper .bp3-skeleton:after,.jupyter-wrapper .bp3-skeleton *{visibility:hidden!important}.jupyter-wrapper .bp3-slider{height:40px;min-width:150px;width:100%;cursor:default;outline:none;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-slider:hover{cursor:pointer}.jupyter-wrapper .bp3-slider:active{cursor:-webkit-grabbing;cursor:grabbing}.jupyter-wrapper .bp3-slider.bp3-disabled{cursor:not-allowed;opacity:.5}.jupyter-wrapper .bp3-slider.bp3-slider-unlabeled{height:16px}.jupyter-wrapper .bp3-slider-track,.jupyter-wrapper .bp3-slider-progress{height:6px;left:0;right:0;top:5px;position:absolute}.jupyter-wrapper .bp3-slider-track{border-radius:3px;overflow:hidden}.jupyter-wrapper .bp3-slider-progress{background:rgba(92,112,128,.2)}.jupyter-wrapper .bp3-dark .bp3-slider-progress{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-slider-progress.bp3-intent-primary{background-color:#137cbd}.jupyter-wrapper .bp3-slider-progress.bp3-intent-success{background-color:#0f9960}.jupyter-wrapper .bp3-slider-progress.bp3-intent-warning{background-color:#d9822b}.jupyter-wrapper .bp3-slider-progress.bp3-intent-danger{background-color:#db3737}.jupyter-wrapper .bp3-slider-handle{background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;color:#182026;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a33,0 1px 1px #10161a33;cursor:pointer;height:16px;left:0;position:absolute;top:0;width:16px}.jupyter-wrapper .bp3-slider-handle:hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-slider-handle:active,.jupyter-wrapper .bp3-slider-handle.bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-slider-handle:disabled,.jupyter-wrapper .bp3-slider-handle.bp3-disabled{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-slider-handle:disabled.bp3-active,.jupyter-wrapper .bp3-slider-handle:disabled.bp3-active:hover,.jupyter-wrapper .bp3-slider-handle.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-slider-handle.bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-slider-handle:focus{z-index:1}.jupyter-wrapper .bp3-slider-handle:hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a33,0 1px 1px #10161a33;cursor:-webkit-grab;cursor:grab;z-index:2}.jupyter-wrapper .bp3-slider-handle.bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),inset 0 1px 1px rgba(16,22,26,.1);box-shadow:0 0 0 1px #10161a33,inset 0 1px 1px #10161a1a;cursor:-webkit-grabbing;cursor:grabbing}.jupyter-wrapper .bp3-disabled .bp3-slider-handle{background:#bfccd6;-webkit-box-shadow:none;box-shadow:none;pointer-events:none}.jupyter-wrapper .bp3-dark .bp3-slider-handle{background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover,.jupyter-wrapper .bp3-dark .bp3-slider-handle:active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-slider-handle:active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-slider-handle:disabled,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-disabled{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-slider-handle:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-slider-handle,.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover{background-color:#394b59}.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{background-color:#293742}.jupyter-wrapper .bp3-dark .bp3-disabled .bp3-slider-handle{background:#5c7080;border-color:#5c7080;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-slider-handle .bp3-slider-label{background:#394b59;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;color:#f5f8fa;margin-left:8px}.jupyter-wrapper .bp3-dark .bp3-slider-handle .bp3-slider-label{background:#e1e8ed;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66;color:#394b59}.jupyter-wrapper .bp3-disabled .bp3-slider-handle .bp3-slider-label{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-slider-handle.bp3-start,.jupyter-wrapper .bp3-slider-handle.bp3-end{width:8px}.jupyter-wrapper .bp3-slider-handle.bp3-start{border-bottom-right-radius:0;border-top-right-radius:0}.jupyter-wrapper .bp3-slider-handle.bp3-end{border-bottom-left-radius:0;border-top-left-radius:0;margin-left:8px}.jupyter-wrapper .bp3-slider-handle.bp3-end .bp3-slider-label{margin-left:0}.jupyter-wrapper .bp3-slider-label{-webkit-transform:translate(-50%,20px);transform:translate(-50%,20px);display:inline-block;font-size:12px;line-height:1;padding:2px 5px;position:absolute;vertical-align:top}.jupyter-wrapper .bp3-slider.bp3-vertical{height:150px;min-width:40px;width:40px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-track,.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-progress{bottom:0;height:auto;left:5px;top:0;width:6px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-progress{top:auto}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-label{-webkit-transform:translate(20px,50%);transform:translate(20px,50%)}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle{top:auto}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{margin-left:0;margin-top:-8px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end,.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{height:8px;margin-left:0;width:16px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{border-bottom-right-radius:3px;border-top-left-radius:0}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{-webkit-transform:translate(20px);transform:translate(20px)}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{border-bottom-left-radius:0;border-bottom-right-radius:0;border-top-left-radius:3px;margin-bottom:8px}@-webkit-keyframes pt-spinner-animation{0%{-webkit-transform:rotate(0deg);transform:rotate(0)}to{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes pt-spinner-animation{0%{-webkit-transform:rotate(0deg);transform:rotate(0)}to{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.jupyter-wrapper .bp3-spinner{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;overflow:visible;vertical-align:middle}.jupyter-wrapper .bp3-spinner svg{display:block}.jupyter-wrapper .bp3-spinner path{fill-opacity:0}.jupyter-wrapper .bp3-spinner .bp3-spinner-head{stroke:#5c7080cc;stroke-linecap:round;-webkit-transform-origin:center;transform-origin:center;-webkit-transition:stroke-dashoffset .2s cubic-bezier(.4,1,.75,.9);transition:stroke-dashoffset .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-spinner .bp3-spinner-track{stroke:#5c708033}.jupyter-wrapper .bp3-spinner-animation{-webkit-animation:pt-spinner-animation .5s linear infinite;animation:pt-spinner-animation .5s linear infinite}.jupyter-wrapper .bp3-no-spin>.bp3-spinner-animation{-webkit-animation:none;animation:none}.jupyter-wrapper .bp3-dark .bp3-spinner .bp3-spinner-head{stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-spinner .bp3-spinner-track{stroke:#10161a80}.jupyter-wrapper .bp3-spinner.bp3-intent-primary .bp3-spinner-head{stroke:#137cbd}.jupyter-wrapper .bp3-spinner.bp3-intent-success .bp3-spinner-head{stroke:#0f9960}.jupyter-wrapper .bp3-spinner.bp3-intent-warning .bp3-spinner-head{stroke:#d9822b}.jupyter-wrapper .bp3-spinner.bp3-intent-danger .bp3-spinner-head{stroke:#db3737}.jupyter-wrapper .bp3-tabs.bp3-vertical{display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab{border-radius:3px;padding:0 10px;width:100%}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab[aria-selected=true]{background-color:#137cbd33;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{background-color:#137cbd33;border-radius:3px;bottom:0;height:auto;left:0;right:0;top:0}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-panel{margin-top:0;padding-left:20px}.jupyter-wrapper .bp3-tab-list{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end;border:none;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;list-style:none;margin:0;padding:0;position:relative}.jupyter-wrapper .bp3-tab-list>*:not(:last-child){margin-right:20px}.jupyter-wrapper .bp3-tab{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;color:#182026;cursor:pointer;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;font-size:14px;line-height:30px;max-width:100%;position:relative;vertical-align:top}.jupyter-wrapper .bp3-tab a{color:inherit;display:block;text-decoration:none}.jupyter-wrapper .bp3-tab-indicator-wrapper~.bp3-tab{background-color:transparent!important;-webkit-box-shadow:none!important;box-shadow:none!important}.jupyter-wrapper .bp3-tab[aria-disabled=true]{color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-tab[aria-selected=true]{border-radius:0;-webkit-box-shadow:inset 0 -3px 0 #106ba3;box-shadow:inset 0 -3px #106ba3}.jupyter-wrapper .bp3-tab[aria-selected=true],.jupyter-wrapper .bp3-tab:not([aria-disabled=true]):hover{color:#106ba3}.jupyter-wrapper .bp3-tab:focus{-moz-outline-radius:0}.jupyter-wrapper .bp3-large>.bp3-tab{font-size:16px;line-height:40px}.jupyter-wrapper .bp3-tab-panel{margin-top:20px}.jupyter-wrapper .bp3-tab-panel[aria-hidden=true]{display:none}.jupyter-wrapper .bp3-tab-indicator-wrapper{left:0;pointer-events:none;position:absolute;top:0;-webkit-transform:translateX(0),translateY(0);transform:translate(0),translateY(0);-webkit-transition:height,width,-webkit-transform;transition:height,width,-webkit-transform;transition:height,transform,width;transition:height,transform,width,-webkit-transform;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-tab-indicator-wrapper .bp3-tab-indicator{background-color:#106ba3;bottom:0;height:3px;left:0;position:absolute;right:0}.jupyter-wrapper .bp3-tab-indicator-wrapper.bp3-no-animation{-webkit-transition:none;transition:none}.jupyter-wrapper .bp3-dark .bp3-tab{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tab[aria-disabled=true]{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tab[aria-selected=true]{-webkit-box-shadow:inset 0 -3px 0 #48aff0;box-shadow:inset 0 -3px #48aff0}.jupyter-wrapper .bp3-dark .bp3-tab[aria-selected=true],.jupyter-wrapper .bp3-dark .bp3-tab:not([aria-disabled=true]):hover{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-tab-indicator{background-color:#48aff0}.jupyter-wrapper .bp3-flex-expander{-webkit-box-flex:1;-ms-flex:1 1;flex:1 1}.jupyter-wrapper .bp3-tag{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#5c7080;border:none;border-radius:3px;-webkit-box-shadow:none;box-shadow:none;color:#f5f8fa;font-size:12px;line-height:16px;max-width:100%;min-height:20px;min-width:20px;padding:2px 6px;position:relative}.jupyter-wrapper .bp3-tag.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-interactive:hover{background-color:#5c7080d9}.jupyter-wrapper .bp3-tag.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-interactive:active{background-color:#5c7080b3}.jupyter-wrapper .bp3-tag>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag:before,.jupyter-wrapper .bp3-tag>*{margin-right:4px}.jupyter-wrapper .bp3-tag:empty:before,.jupyter-wrapper .bp3-tag>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag:focus{outline:rgba(19,124,189,.6) auto 2px;outline-offset:0;-moz-outline-radius:6px}.jupyter-wrapper .bp3-tag.bp3-round{border-radius:30px;padding-left:8px;padding-right:8px}.jupyter-wrapper .bp3-dark .bp3-tag{background-color:#bfccd6;color:#182026}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive:hover{background-color:#bfccd6d9}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive:active{background-color:#bfccd6b3}.jupyter-wrapper .bp3-dark .bp3-tag>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tag .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tag .bp3-icon-large{fill:currentColor}.jupyter-wrapper .bp3-tag>.bp3-icon,.jupyter-wrapper .bp3-tag .bp3-icon-standard,.jupyter-wrapper .bp3-tag .bp3-icon-large{fill:#fff}.jupyter-wrapper .bp3-tag.bp3-large,.jupyter-wrapper .bp3-large .bp3-tag{font-size:14px;line-height:20px;min-height:30px;min-width:30px;padding:5px 10px}.jupyter-wrapper .bp3-tag.bp3-large:before,.jupyter-wrapper .bp3-tag.bp3-large>*,.jupyter-wrapper .bp3-large .bp3-tag:before,.jupyter-wrapper .bp3-large .bp3-tag>*{margin-right:7px}.jupyter-wrapper .bp3-tag.bp3-large:empty:before,.jupyter-wrapper .bp3-tag.bp3-large>:last-child,.jupyter-wrapper .bp3-large .bp3-tag:empty:before,.jupyter-wrapper .bp3-large .bp3-tag>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag.bp3-large.bp3-round,.jupyter-wrapper .bp3-large .bp3-tag.bp3-round{padding-left:12px;padding-right:12px}.jupyter-wrapper .bp3-tag.bp3-intent-primary{background:#137cbd;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive:hover{background-color:#137cbdd9}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive:active{background-color:#137cbdb3}.jupyter-wrapper .bp3-tag.bp3-intent-success{background:#0f9960;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive:hover{background-color:#0f9960d9}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive:active{background-color:#0f9960b3}.jupyter-wrapper .bp3-tag.bp3-intent-warning{background:#d9822b;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive:hover{background-color:#d9822bd9}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive:active{background-color:#d9822bb3}.jupyter-wrapper .bp3-tag.bp3-intent-danger{background:#db3737;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive:hover{background-color:#db3737d9}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive:active{background-color:#db3737b3}.jupyter-wrapper .bp3-tag.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-tag.bp3-minimal>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal .bp3-icon-large{fill:#5c7080}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]){background-color:#8a9ba833;color:#182026}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:hover{background-color:#5c70804d}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:active{background-color:#5c708066}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]){color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:hover{background-color:#bfccd64d}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:active{background-color:#bfccd666}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-])>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]) .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]) .bp3-icon-large{fill:#a7b6c2}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary{background-color:#137cbd26;color:#106ba3}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{background-color:#137cbd40}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{background-color:#137cbd59}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{fill:#137cbd}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{background-color:#137cbd40;color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{background-color:#137cbd59}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{background-color:#137cbd73}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success{background-color:#0f996026;color:#0d8050}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{background-color:#0f996040}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{background-color:#0f996059}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{fill:#0f9960}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{background-color:#0f996040;color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{background-color:#0f996059}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{background-color:#0f996073}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning{background-color:#d9822b26;color:#bf7326}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{background-color:#d9822b40}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{background-color:#d9822b59}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{fill:#d9822b}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{background-color:#d9822b40;color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{background-color:#d9822b59}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{background-color:#d9822b73}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger{background-color:#db373726;color:#c23030}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{background-color:#db373740}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{background-color:#db373759}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{fill:#db3737}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{background-color:#db373740;color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{background-color:#db373759}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{background-color:#db373773}.jupyter-wrapper .bp3-tag-remove{background:none;border:none;color:inherit;cursor:pointer;display:-webkit-box;display:-ms-flexbox;display:flex;margin-bottom:-2px;margin-right:-6px!important;margin-top:-2px;opacity:.5;padding:2px 2px 2px 0}.jupyter-wrapper .bp3-tag-remove:hover{background:none;opacity:.8;text-decoration:none}.jupyter-wrapper .bp3-tag-remove:active{opacity:1}.jupyter-wrapper .bp3-tag-remove:empty:before{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;content:""}.jupyter-wrapper .bp3-large .bp3-tag-remove{margin-right:-10px!important;padding:0 5px 0 0}.jupyter-wrapper .bp3-large .bp3-tag-remove:empty:before{font-family:Icons20,sans-serif;font-size:20px;font-style:normal;font-weight:400;line-height:1}.jupyter-wrapper .bp3-tag-input{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;cursor:text;height:auto;line-height:inherit;min-height:30px;padding-left:5px;padding-right:0}.jupyter-wrapper .bp3-tag-input>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag-input>.bp3-tag-input-values{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-icon{color:#5c7080;margin-left:2px;margin-right:7px;margin-top:7px}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-ms-flex-item-align:stretch;align-self:stretch;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:7px;margin-top:5px;min-width:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values:before,.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{margin-right:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values:empty:before,.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{padding-left:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{margin-bottom:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag{overflow-wrap:break-word}.jupyter-wrapper .bp3-tag-input .bp3-tag.bp3-active{outline:rgba(19,124,189,.6) auto 2px;outline-offset:0;-moz-outline-radius:6px}.jupyter-wrapper .bp3-tag-input .bp3-input-ghost{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:20px;width:80px}.jupyter-wrapper .bp3-tag-input .bp3-input-ghost:disabled,.jupyter-wrapper .bp3-tag-input .bp3-input-ghost.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-tag-input .bp3-button,.jupyter-wrapper .bp3-tag-input .bp3-spinner{margin:3px 3px 3px 0}.jupyter-wrapper .bp3-tag-input .bp3-button{min-height:24px;min-width:24px;padding:0 7px}.jupyter-wrapper .bp3-tag-input.bp3-large{height:auto;min-height:40px}.jupyter-wrapper .bp3-tag-input.bp3-large:before,.jupyter-wrapper .bp3-tag-input.bp3-large>*{margin-right:10px}.jupyter-wrapper .bp3-tag-input.bp3-large:empty:before,.jupyter-wrapper .bp3-tag-input.bp3-large>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-tag-input-icon{margin-left:5px;margin-top:10px}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-input-ghost{line-height:30px}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-button{min-height:30px;min-width:30px;padding:5px 10px;margin:5px 5px 5px 0}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-spinner{margin:8px 8px 8px 0}.jupyter-wrapper .bp3-tag-input.bp3-active{background-color:#fff;-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-primary{-webkit-box-shadow:0 0 0 1px #106ba3,0 0 0 3px rgba(16,107,163,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #106ba3,0 0 0 3px #106ba34d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-success{-webkit-box-shadow:0 0 0 1px #0d8050,0 0 0 3px rgba(13,128,80,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0d8050,0 0 0 3px #0d80504d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-warning{-webkit-box-shadow:0 0 0 1px #bf7326,0 0 0 3px rgba(191,115,38,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #bf7326,0 0 0 3px #bf73264d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-danger{-webkit-box-shadow:0 0 0 1px #c23030,0 0 0 3px rgba(194,48,48,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #c23030,0 0 0 3px #c230304d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-tag-input-icon,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-tag-input-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active{background-color:#10161a4d;-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{-webkit-box-shadow:0 0 0 1px #106ba3,0 0 0 3px rgba(16,107,163,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #106ba3,0 0 0 3px #106ba34d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{-webkit-box-shadow:0 0 0 1px #0d8050,0 0 0 3px rgba(13,128,80,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #0d8050,0 0 0 3px #0d80504d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{-webkit-box-shadow:0 0 0 1px #bf7326,0 0 0 3px rgba(191,115,38,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #bf7326,0 0 0 3px #bf73264d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{-webkit-box-shadow:0 0 0 1px #c23030,0 0 0 3px rgba(194,48,48,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #c23030,0 0 0 3px #c230304d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-input-ghost{background:none;border:none;-webkit-box-shadow:none;box-shadow:none;padding:0}.jupyter-wrapper .bp3-input-ghost::-webkit-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost::-moz-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost:-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost::-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost::placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost:focus{outline:none!important}.jupyter-wrapper .bp3-toast{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;background-color:#fff;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;display:-webkit-box;display:-ms-flexbox;display:flex;margin:20px 0 0;max-width:500px;min-width:300px;pointer-events:all;position:relative!important}.jupyter-wrapper .bp3-toast.bp3-toast-enter,.jupyter-wrapper .bp3-toast.bp3-toast-appear{-webkit-transform:translateY(-40px);transform:translateY(-40px)}.jupyter-wrapper .bp3-toast.bp3-toast-enter-active,.jupyter-wrapper .bp3-toast.bp3-toast-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-toast.bp3-toast-enter~.bp3-toast,.jupyter-wrapper .bp3-toast.bp3-toast-appear~.bp3-toast{-webkit-transform:translateY(-40px);transform:translateY(-40px)}.jupyter-wrapper .bp3-toast.bp3-toast-enter-active~.bp3-toast,.jupyter-wrapper .bp3-toast.bp3-toast-appear-active~.bp3-toast{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-toast.bp3-toast-exit{opacity:1;-webkit-filter:blur(0);filter:blur(0)}.jupyter-wrapper .bp3-toast.bp3-toast-exit-active{opacity:0;-webkit-filter:blur(10px);filter:blur(10px);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:opacity,filter;transition-property:opacity,filter,-webkit-filter;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-toast.bp3-toast-exit~.bp3-toast{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-toast.bp3-toast-exit-active~.bp3-toast{-webkit-transform:translateY(-40px);transform:translateY(-40px);-webkit-transition-delay:50ms;transition-delay:50ms;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-toast .bp3-button-group{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding:5px 5px 5px 0}.jupyter-wrapper .bp3-toast>.bp3-icon{color:#5c7080;margin:12px 0 12px 12px}.jupyter-wrapper .bp3-toast.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-toast{background-color:#394b59;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-toast.bp3-dark>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-toast>.bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] a{color:#ffffffb3}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] a:hover{color:#fff}.jupyter-wrapper .bp3-toast[class*=bp3-intent-]>.bp3-icon{color:#fff}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:before,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button .bp3-icon,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:active{color:#ffffffb3!important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:focus{outline-color:#ffffff80}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:hover{background-color:#ffffff26!important;color:#fff!important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:active{background-color:#ffffff4d!important;color:#fff!important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:after{background:rgba(255,255,255,.3)!important}.jupyter-wrapper .bp3-toast.bp3-intent-primary{background-color:#137cbd;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-success{background-color:#0f9960;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-warning{background-color:#d9822b;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-danger{background-color:#db3737;color:#fff}.jupyter-wrapper .bp3-toast-message{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;padding:11px;word-break:break-word}.jupyter-wrapper .bp3-toast-container{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box!important;display:-ms-flexbox!important;display:flex!important;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;left:0;overflow:hidden;padding:0 20px 20px;pointer-events:none;right:0;z-index:40}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-in-portal{position:fixed}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-inline{position:absolute}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-top{top:0}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-bottom{bottom:0;-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;top:auto}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-left{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-right{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active)~.bp3-toast,.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active)~.bp3-toast,.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-exit-active~.bp3-toast,.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active~.bp3-toast{-webkit-transform:translateY(60px);transform:translateY(60px)}.jupyter-wrapper .bp3-tooltip{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow{height:22px;position:absolute;width:22px}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow:before{height:14px;margin:4px;width:14px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip{margin-bottom:11px;margin-top:-11px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow{bottom:-8px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(-90deg);transform:rotate(-90deg)}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip{margin-left:11px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow{left:-8px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(0);transform:rotate(0)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip{margin-top:11px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow{top:-8px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip{margin-left:-11px;margin-right:11px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow{right:-8px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.jupyter-wrapper .bp3-tether-element-attached-middle>.bp3-tooltip>.bp3-popover-arrow{top:50%;-webkit-transform:translateY(-50%);transform:translateY(-50%)}.jupyter-wrapper .bp3-tether-element-attached-center>.bp3-tooltip>.bp3-popover-arrow{right:50%;-webkit-transform:translateX(50%);transform:translate(50%)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow{top:-.22183px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow{right:-.22183px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow{left:-.22183px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow{bottom:-.22183px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:top left;transform-origin:top left}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:top center;transform-origin:top center}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:top right;transform-origin:top right}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:center left;transform-origin:center left}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:center center;transform-origin:center center}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:center right;transform-origin:center right}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:bottom left;transform-origin:bottom left}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:bottom center;transform-origin:bottom center}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:bottom right;transform-origin:bottom right}.jupyter-wrapper .bp3-tooltip .bp3-popover-content{background:#394b59;color:#f5f8fa}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow:before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.2);box-shadow:1px 1px 6px #10161a33}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.1}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow-fill{fill:#394b59}.jupyter-wrapper .bp3-popover-enter>.bp3-tooltip,.jupyter-wrapper .bp3-popover-appear>.bp3-tooltip{-webkit-transform:scale(.8);transform:scale(.8)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-tooltip,.jupyter-wrapper .bp3-popover-appear-active>.bp3-tooltip{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-popover-exit>.bp3-tooltip{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-tooltip{-webkit-transform:scale(.8);transform:scale(.8);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-tooltip .bp3-popover-content{padding:10px 12px}.jupyter-wrapper .bp3-tooltip.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-tooltip{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-content,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-content{background:#e1e8ed;color:#394b59}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow:before,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow:before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.4);box-shadow:1px 1px 6px #10161a66}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.2}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{fill:#e1e8ed}.jupyter-wrapper .bp3-tooltip.bp3-intent-primary .bp3-popover-content{background:#137cbd;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{fill:#137cbd}.jupyter-wrapper .bp3-tooltip.bp3-intent-success .bp3-popover-content{background:#0f9960;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{fill:#0f9960}.jupyter-wrapper .bp3-tooltip.bp3-intent-warning .bp3-popover-content{background:#d9822b;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{fill:#d9822b}.jupyter-wrapper .bp3-tooltip.bp3-intent-danger .bp3-popover-content{background:#db3737;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{fill:#db3737}.jupyter-wrapper .bp3-tooltip-indicator{border-bottom:dotted 1px;cursor:help}.jupyter-wrapper .bp3-tree .bp3-icon,.jupyter-wrapper .bp3-tree .bp3-icon-standard,.jupyter-wrapper .bp3-tree .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-primary{color:#137cbd}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-success{color:#0f9960}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-warning{color:#d9822b}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-danger{color:#db3737}.jupyter-wrapper .bp3-tree-node-list{list-style:none;margin:0;padding-left:0}.jupyter-wrapper .bp3-tree-root{background-color:transparent;cursor:default;padding-left:0;position:relative}.jupyter-wrapper .bp3-tree-node-content-0{padding-left:0}.jupyter-wrapper .bp3-tree-node-content-1{padding-left:23px}.jupyter-wrapper .bp3-tree-node-content-2{padding-left:46px}.jupyter-wrapper .bp3-tree-node-content-3{padding-left:69px}.jupyter-wrapper .bp3-tree-node-content-4{padding-left:92px}.jupyter-wrapper .bp3-tree-node-content-5{padding-left:115px}.jupyter-wrapper .bp3-tree-node-content-6{padding-left:138px}.jupyter-wrapper .bp3-tree-node-content-7{padding-left:161px}.jupyter-wrapper .bp3-tree-node-content-8{padding-left:184px}.jupyter-wrapper .bp3-tree-node-content-9{padding-left:207px}.jupyter-wrapper .bp3-tree-node-content-10{padding-left:230px}.jupyter-wrapper .bp3-tree-node-content-11{padding-left:253px}.jupyter-wrapper .bp3-tree-node-content-12{padding-left:276px}.jupyter-wrapper .bp3-tree-node-content-13{padding-left:299px}.jupyter-wrapper .bp3-tree-node-content-14{padding-left:322px}.jupyter-wrapper .bp3-tree-node-content-15{padding-left:345px}.jupyter-wrapper .bp3-tree-node-content-16{padding-left:368px}.jupyter-wrapper .bp3-tree-node-content-17{padding-left:391px}.jupyter-wrapper .bp3-tree-node-content-18{padding-left:414px}.jupyter-wrapper .bp3-tree-node-content-19{padding-left:437px}.jupyter-wrapper .bp3-tree-node-content-20{padding-left:460px}.jupyter-wrapper .bp3-tree-node-content{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;height:30px;padding-right:5px;width:100%}.jupyter-wrapper .bp3-tree-node-content:hover{background-color:#bfccd666}.jupyter-wrapper .bp3-tree-node-caret,.jupyter-wrapper .bp3-tree-node-caret-none{min-width:30px}.jupyter-wrapper .bp3-tree-node-caret{color:#5c7080;cursor:pointer;padding:7px;-webkit-transform:rotate(0deg);transform:rotate(0);-webkit-transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9);transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9),-webkit-transform .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-tree-node-caret:hover{color:#182026}.jupyter-wrapper .bp3-dark .bp3-tree-node-caret{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tree-node-caret:hover{color:#f5f8fa}.jupyter-wrapper .bp3-tree-node-caret.bp3-tree-node-caret-open{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tree-node-caret.bp3-icon-standard:before{content:""}.jupyter-wrapper .bp3-tree-node-icon{margin-right:7px;position:relative}.jupyter-wrapper .bp3-tree-node-label{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-tree-node-label span{display:inline}.jupyter-wrapper .bp3-tree-node-secondary-label{padding:0 5px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-tree-node-secondary-label .bp3-popover-wrapper,.jupyter-wrapper .bp3-tree-node-secondary-label .bp3-popover-target{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-content{background-color:inherit;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-caret,.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-icon{color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content{background-color:#137cbd}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon-standard,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon-large{color:#fff}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-tree-node-caret:before{color:#ffffffb3}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-tree-node-caret:hover:before{color:#fff}.jupyter-wrapper .bp3-dark .bp3-tree-node-content:hover{background-color:#5c70804d}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{color:#0f9960}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{color:#d9822b}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{color:#db3737}.jupyter-wrapper .bp3-dark .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content{background-color:#137cbd}.jupyter-wrapper .bp3-omnibar{-webkit-filter:blur(0);filter:blur(0);opacity:1;background-color:#fff;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 4px 8px #10161a33,0 18px 46px 6px #10161a33;left:calc(50% - 250px);top:20vh;width:500px;z-index:21}.jupyter-wrapper .bp3-omnibar.bp3-overlay-enter,.jupyter-wrapper .bp3-omnibar.bp3-overlay-appear{-webkit-filter:blur(20px);filter:blur(20px);opacity:.2}.jupyter-wrapper .bp3-omnibar.bp3-overlay-enter-active,.jupyter-wrapper .bp3-omnibar.bp3-overlay-appear-active{-webkit-filter:blur(0);filter:blur(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:filter,opacity;transition-property:filter,opacity,-webkit-filter;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-omnibar.bp3-overlay-exit{-webkit-filter:blur(0);filter:blur(0);opacity:1}.jupyter-wrapper .bp3-omnibar.bp3-overlay-exit-active{-webkit-filter:blur(20px);filter:blur(20px);opacity:.2;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:filter,opacity;transition-property:filter,opacity,-webkit-filter;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-omnibar .bp3-input{background-color:transparent;border-radius:0}.jupyter-wrapper .bp3-omnibar .bp3-input,.jupyter-wrapper .bp3-omnibar .bp3-input:focus{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-omnibar .bp3-menu{background-color:transparent;border-radius:0;-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.15);box-shadow:inset 0 1px #10161a26;max-height:calc(60vh - 40px);overflow:auto}.jupyter-wrapper .bp3-omnibar .bp3-menu:empty{display:none}.jupyter-wrapper .bp3-dark .bp3-omnibar,.jupyter-wrapper .bp3-omnibar.bp3-dark{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 4px 8px #10161a66,0 18px 46px 6px #10161a66}.jupyter-wrapper .bp3-omnibar-overlay .bp3-overlay-backdrop{background-color:#10161a33}.jupyter-wrapper .bp3-multi-select{min-width:150px}.jupyter-wrapper .bp3-multi-select-popover .bp3-menu{max-height:300px;max-width:400px;overflow:auto}.jupyter-wrapper .bp3-select-popover .bp3-popover-content{padding:5px}.jupyter-wrapper .bp3-select-popover .bp3-input-group{margin-bottom:0}.jupyter-wrapper .bp3-select-popover .bp3-menu{max-height:300px;max-width:400px;overflow:auto;padding:0}.jupyter-wrapper .bp3-select-popover .bp3-menu:not(:first-child){padding-top:5px}.jupyter-wrapper :root{--jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);--jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);--jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);--jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-build: url(data:image/svg+xml;base64,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);--jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);--jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);--jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);--jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);--jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);--jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);--jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);--jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);--jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);--jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);--jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);--jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-jupyter: url(data:image/svg+xml;base64,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);--jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);--jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);--jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);--jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);--jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);--jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);--jp-icon-listings-info: url(data:image/svg+xml;base64,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);--jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);--jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);--jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);--jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);--jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);--jp-icon-python: url(data:image/svg+xml;base64,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);--jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);--jp-icon-react: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMTUwIDE1MCA1NDEuOSAyOTUuMyI+CiAgPGcgY2xhc3M9ImpwLWljb24tYnJhbmQyIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxREFGQiI+CiAgICA8cGF0aCBkPSJNNjY2LjMgMjk2LjVjMC0zMi41LTQwLjctNjMuMy0xMDMuMS04Mi40IDE0LjQtNjMuNiA4LTExNC4yLTIwLjItMTMwLjQtNi41LTMuOC0xNC4xLTUuNi0yMi40LTUuNnYyMi4zYzQuNiAwIDguMy45IDExLjQgMi42IDEzLjYgNy44IDE5LjUgMzcuNSAxNC45IDc1LjctMS4xIDkuNC0yLjkgMTkuMy01LjEgMjkuNC0xOS42LTQuOC00MS04LjUtNjMuNS0xMC45LTEzLjUtMTguNS0yNy41LTM1LjMtNDEuNi01MCAzMi42LTMwLjMgNjMuMi00Ni45IDg0LTQ2LjlWNzhjLTI3LjUgMC02My41IDE5LjYtOTkuOSA1My42LTM2LjQtMzMuOC03Mi40LTUzLjItOTkuOS01My4ydjIyLjNjMjAuNyAwIDUxLjQgMTYuNSA4NCA0Ni42LTE0IDE0LjctMjggMzEuNC00MS4zIDQ5LjktMjIuNiAyLjQtNDQgNi4xLTYzLjYgMTEtMi4zLTEwLTQtMTkuNy01LjItMjktNC43LTM4LjIgMS4xLTY3LjkgMTQuNi03NS44IDMtMS44IDYuOS0yLjYgMTEuNS0yLjZWNzguNWMtOC40IDAtMTYgMS44LTIyLjYgNS42LTI4LjEgMTYuMi0zNC40IDY2LjctMTkuOSAxMzAuMS02Mi4yIDE5LjItMTAyLjcgNDkuOS0xMDIuNyA4Mi4zIDAgMzIuNSA0MC43IDYzLjMgMTAzLjEgODIuNC0xNC40IDYzLjYtOCAxMTQuMiAyMC4yIDEzMC40IDYuNSAzLjggMTQuMSA1LjYgMjIuNSA1LjYgMjcuNSAwIDYzLjUtMTkuNiA5OS45LTUzLjYgMzYuNCAzMy44IDcyLjQgNTMuMiA5OS45IDUzLjIgOC40IDAgMTYtMS44IDIyLjYtNS42IDI4LjEtMTYuMiAzNC40LTY2LjcgMTkuOS0xMzAuMSA2Mi0xOS4xIDEwMi41LTQ5LjkgMTAyLjUtODIuM3ptLTEzMC4yLTY2LjdjLTMuNyAxMi45LTguMyAyNi4yLTEzLjUgMzkuNS00LjEtOC04LjQtMTYtMTMuMS0yNC00LjYtOC05LjUtMTUuOC0xNC40LTIzLjQgMTQuMiAyLjEgMjcuOSA0LjcgNDEgNy45em0tNDUuOCAxMDYuNWMtNy44IDEzLjUtMTUuOCAyNi4zLTI0LjEgMzguMi0xNC45IDEuMy0zMCAyLTQ1LjIgMi0xNS4xIDAtMzAuMi0uNy00NS0xLjktOC4zLTExLjktMTYuNC0yNC42LTI0LjItMzgtNy42LTEzLjEtMTQuNS0yNi40LTIwLjgtMzkuOCA2LjItMTMuNCAxMy4yLTI2LjggMjAuNy0zOS45IDcuOC0xMy41IDE1LjgtMjYuMyAyNC4xLTM4LjIgMTQuOS0xLjMgMzAtMiA0NS4yLTIgMTUuMSAwIDMwLjIuNyA0NSAxLjkgOC4zIDExLjkgMTYuNCAyNC42IDI0LjIgMzggNy42IDEzLjEgMTQuNSAyNi40IDIwLjggMzkuOC02LjMgMTMuNC0xMy4yIDI2LjgtMjAuNyAzOS45em0zMi4zLTEzYzUuNCAxMy40IDEwIDI2LjggMTMuOCAzOS44LTEzLjEgMy4yLTI2LjkgNS45LTQxLjIgOCA0LjktNy43IDkuOC0xNS42IDE0LjQtMjMuNyA0LjYtOCA4LjktMTYuMSAxMy0yNC4xek00MjEuMiA0MzBjLTkuMy05LjYtMTguNi0yMC4zLTI3LjgtMzIgOSAuNCAxOC4yLjcgMjcuNS43IDkuNCAwIDE4LjctLjIgMjcuOC0uNy05IDExLjctMTguMyAyMi40LTI3LjUgMzJ6bS03NC40LTU4LjljLTE0LjItMi4xLTI3LjktNC43LTQxLTcuOSAzLjctMTIuOSA4LjMtMjYuMiAxMy41LTM5LjUgNC4xIDggOC40IDE2IDEzLjEgMjQgNC43IDggOS41IDE1LjggMTQuNCAyMy40ek00MjAuNyAxNjNjOS4zIDkuNiAxOC42IDIwLjMgMjcuOCAzMi05LS40LTE4LjItLjctMjcuNS0uNy05LjQgMC0xOC43LjItMjcuOC43IDktMTEuNyAxOC4zLTIyLjQgMjcuNS0zMnptLTc0IDU4LjljLTQuOSA3LjctOS44IDE1LjYtMTQuNCAyMy43LTQuNiA4LTguOSAxNi0xMyAyNC01LjQtMTMuNC0xMC0yNi44LTEzLjgtMzkuOCAxMy4xLTMuMSAyNi45LTUuOCA0MS4yLTcuOXptLTkwLjUgMTI1LjJjLTM1LjQtMTUuMS01OC4zLTM0LjktNTguMy01MC42IDAtMTUuNyAyMi45LTM1LjYgNTguMy01MC42IDguNi0zLjcgMTgtNyAyNy43LTEwLjEgNS43IDE5LjYgMTMuMiA0MCAyMi41IDYwLjktOS4yIDIwLjgtMTYuNiA0MS4xLTIyLjIgNjAuNi05LjktMy4xLTE5LjMtNi41LTI4LTEwLjJ6TTMxMCA0OTBjLTEzLjYtNy44LTE5LjUtMzcuNS0xNC45LTc1LjcgMS4xLTkuNCAyLjktMTkuMyA1LjEtMjkuNCAxOS42IDQuOCA0MSA4LjUgNjMuNSAxMC45IDEzLjUgMTguNSAyNy41IDM1LjMgNDEuNiA1MC0zMi42IDMwLjMtNjMuMiA0Ni45LTg0IDQ2LjktNC41LS4xLTguMy0xLTExLjMtMi43em0yMzcuMi03Ni4yYzQuNyAzOC4yLTEuMSA2Ny45LTE0LjYgNzUuOC0zIDEuOC02LjkgMi42LTExLjUgMi42LTIwLjcgMC01MS40LTE2LjUtODQtNDYuNiAxNC0xNC43IDI4LTMxLjQgNDEuMy00OS45IDIyLjYtMi40IDQ0LTYuMSA2My42LTExIDIuMyAxMC4xIDQuMSAxOS44IDUuMiAyOS4xem0zOC41LTY2LjdjLTguNiAzLjctMTggNy0yNy43IDEwLjEtNS43LTE5LjYtMTMuMi00MC0yMi41LTYwLjkgOS4yLTIwLjggMTYuNi00MS4xIDIyLjItNjAuNiA5LjkgMy4xIDE5LjMgNi41IDI4LjEgMTAuMiAzNS40IDE1LjEgNTguMyAzNC45IDU4LjMgNTAuNi0uMSAxNS43LTIzIDM1LjYtNTguNCA1MC42ek0zMjAuOCA3OC40eiIvPgogICAgPGNpcmNsZSBjeD0iNDIwLjkiIGN5PSIyOTYuNSIgcj0iNDUuNyIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);--jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);--jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4=);--jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-terminal: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0IiA+CiAgICA8cmVjdCBjbGFzcz0ianAtdGVybWluYWwtaWNvbi1iYWNrZ3JvdW5kLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgd2lkdGg9IjIwIiBoZWlnaHQ9IjIwIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgyIDIpIiBmaWxsPSIjMzMzMzMzIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtdGVybWluYWwtaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUtaW52ZXJzZSIgZD0iTTUuMDU2NjQgOC43NjE3MkM1LjA1NjY0IDguNTk3NjYgNS4wMzEyNSA4LjQ1MzEyIDQuOTgwNDcgOC4zMjgxMkM0LjkzMzU5IDguMTk5MjIgNC44NTU0NyA4LjA4MjAzIDQuNzQ2MDkgNy45NzY1NkM0LjY0MDYyIDcuODcxMDkgNC41IDcuNzc1MzkgNC4zMjQyMiA3LjY4OTQ1QzQuMTUyMzQgNy41OTk2MSAzLjk0MzM2IDcuNTExNzIgMy42OTcyNyA3LjQyNTc4QzMuMzAyNzMgNy4yODUxNiAyLjk0MzM2IDcuMTM2NzIgMi42MTkxNCA2Ljk4MDQ3QzIuMjk0OTIgNi44MjQyMiAyLjAxNzU4IDYuNjQyNTggMS43ODcxMSA2LjQzNTU1QzEuNTYwNTUgNi4yMjg1MiAxLjM4NDc3IDUuOTg4MjggMS4yNTk3NyA1LjcxNDg0QzEuMTM0NzcgNS40Mzc1IDEuMDcyMjcgNS4xMDkzOCAxLjA3MjI3IDQuNzMwNDdDMS4wNzIyNyA0LjM5ODQ0IDEuMTI4OTEgNC4wOTU3IDEuMjQyMTkgMy44MjIyN0MxLjM1NTQ3IDMuNTQ0OTIgMS41MTU2MiAzLjMwNDY5IDEuNzIyNjYgMy4xMDE1NkMxLjkyOTY5IDIuODk4NDQgMi4xNzk2OSAyLjczNDM3IDIuNDcyNjYgMi42MDkzOEMyLjc2NTYyIDIuNDg0MzggMy4wOTE4IDIuNDA0MyAzLjQ1MTE3IDIuMzY5MTRWMS4xMDkzOEg0LjM4ODY3VjIuMzgwODZDNC43NDAyMyAyLjQyNzczIDUuMDU2NjQgMi41MjM0NCA1LjMzNzg5IDIuNjY3OTdDNS42MTkxNCAyLjgxMjUgNS44NTc0MiAzLjAwMTk1IDYuMDUyNzMgMy4yMzYzM0M2LjI1MTk1IDMuNDY2OCA2LjQwNDMgMy43NDAyMyA2LjUwOTc3IDQuMDU2NjRDNi42MTkxNCA0LjM2OTE0IDYuNjczODMgNC43MjA3IDYuNjczODMgNS4xMTEzM0g1LjA0NDkyQzUuMDQ0OTIgNC42Mzg2NyA0LjkzNzUgNC4yODEyNSA0LjcyMjY2IDQuMDM5MDZDNC41MDc4MSAzLjc5Mjk3IDQuMjE2OCAzLjY2OTkyIDMuODQ5NjEgMy42Njk5MkMzLjY1MDM5IDMuNjY5OTIgMy40NzY1NiAzLjY5NzI3IDMuMzI4MTIgMy43NTE5NUMzLjE4MzU5IDMuODAyNzMgMy4wNjQ0NSAzLjg3Njk1IDIuOTcwNyAzLjk3NDYxQzIuODc2OTUgNC4wNjgzNiAyLjgwNjY0IDQuMTc5NjkgMi43NTk3NyA0LjMwODU5QzIuNzE2OCA0LjQzNzUgMi42OTUzMSA0LjU3ODEyIDIuNjk1MzEgNC43MzA0N0MyLjY5NTMxIDQuODgyODEgMi43MTY4IDUuMDE5NTMgMi43NTk3NyA1LjE0MDYyQzIuODA2NjQgNS4yNTc4MSAyLjg4MjgxIDUuMzY3MTkgMi45ODgyOCA1LjQ2ODc1QzMuMDk3NjYgNS41NzAzMSAzLjI0MDIzIDUuNjY3OTcgMy40MTYwMiA1Ljc2MTcyQzMuNTkxOCA1Ljg1MTU2IDMuODEwNTUgNS45NDMzNiA0LjA3MjI3IDYuMDM3MTFDNC40NjY4IDYuMTg1NTUgNC44MjQyMiA2LjMzOTg0IDUuMTQ0NTMgNi41QzUuNDY0ODQgNi42NTYyNSA1LjczODI4IDYuODM5ODQgNS45NjQ4NCA3LjA1MDc4QzYuMTk1MzEgNy4yNTc4MSA2LjM3MTA5IDcuNSA2LjQ5MjE5IDcuNzc3MzRDNi42MTcxOSA4LjA1MDc4IDYuNjc5NjkgOC4zNzUgNi42Nzk2OSA4Ljc1QzYuNjc5NjkgOS4wOTM3NSA2LjYyMzA1IDkuNDA0MyA2LjUwOTc3IDkuNjgxNjRDNi4zOTY0OCA5Ljk1NTA4IDYuMjM0MzggMTAuMTkxNCA2LjAyMzQ0IDEwLjM5MDZDNS44MTI1IDEwLjU4OTggNS41NTg1OSAxMC43NSA1LjI2MTcyIDEwLjg3MTFDNC45NjQ4NCAxMC45ODgzIDQuNjMyODEgMTEuMDY0NSA0LjI2NTYyIDExLjA5OTZWMTIuMjQ4SDMuMzMzOThWMTEuMDk5NkMzLjAwMTk1IDExLjA2ODQgMi42Nzk2OSAxMC45OTYxIDIuMzY3MTkgMTAuODgyOEMyLjA1NDY5IDEwLjc2NTYgMS43NzczNCAxMC41OTc3IDEuNTM1MTYgMTAuMzc4OUMxLjI5Njg4IDEwLjE2MDIgMS4xMDU0NyA5Ljg4NDc3IDAuOTYwOTM4IDkuNTUyNzNDMC44MTY0MDYgOS4yMTY4IDAuNzQ0MTQxIDguODE0NDUgMC43NDQxNDEgOC4zNDU3SDIuMzc4OTFDMi4zNzg5MSA4LjYyNjk1IDIuNDE5OTIgOC44NjMyOCAyLjUwMTk1IDkuMDU0NjlDMi41ODM5OCA5LjI0MjE5IDIuNjg5NDUgOS4zOTI1OCAyLjgxODM2IDkuNTA1ODZDMi45NTExNyA5LjYxNTIzIDMuMTAxNTYgOS42OTMzNiAzLjI2OTUzIDkuNzQwMjNDMy40Mzc1IDkuNzg3MTEgMy42MDkzOCA5LjgxMDU1IDMuNzg1MTYgOS44MTA1NUM0LjIwMzEyIDkuODEwNTUgNC41MTk1MyA5LjcxMjg5IDQuNzM0MzggOS41MTc1OEM0Ljk0OTIyIDkuMzIyMjcgNS4wNTY2NCA5LjA3MDMxIDUuMDU2NjQgOC43NjE3MlpNMTMuNDE4IDEyLjI3MTVIOC4wNzQyMlYxMUgxMy40MThWMTIuMjcxNVoiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMuOTUyNjQgNikiIGZpbGw9IndoaXRlIi8+Cjwvc3ZnPgo=);--jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);--jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4=);--jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);--jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+);--jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);--jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K)}.jupyter-wrapper .jp-AddAboveIcon{background-image:var(--jp-icon-add-above)}.jupyter-wrapper .jp-AddBelowIcon{background-image:var(--jp-icon-add-below)}.jupyter-wrapper .jp-AddIcon{background-image:var(--jp-icon-add)}.jupyter-wrapper .jp-BellIcon{background-image:var(--jp-icon-bell)}.jupyter-wrapper .jp-BugDotIcon{background-image:var(--jp-icon-bug-dot)}.jupyter-wrapper .jp-BugIcon{background-image:var(--jp-icon-bug)}.jupyter-wrapper .jp-BuildIcon{background-image:var(--jp-icon-build)}.jupyter-wrapper .jp-CaretDownEmptyIcon{background-image:var(--jp-icon-caret-down-empty)}.jupyter-wrapper .jp-CaretDownEmptyThinIcon{background-image:var(--jp-icon-caret-down-empty-thin)}.jupyter-wrapper .jp-CaretDownIcon{background-image:var(--jp-icon-caret-down)}.jupyter-wrapper .jp-CaretLeftIcon{background-image:var(--jp-icon-caret-left)}.jupyter-wrapper .jp-CaretRightIcon{background-image:var(--jp-icon-caret-right)}.jupyter-wrapper .jp-CaretUpEmptyThinIcon{background-image:var(--jp-icon-caret-up-empty-thin)}.jupyter-wrapper .jp-CaretUpIcon{background-image:var(--jp-icon-caret-up)}.jupyter-wrapper .jp-CaseSensitiveIcon{background-image:var(--jp-icon-case-sensitive)}.jupyter-wrapper .jp-CheckIcon{background-image:var(--jp-icon-check)}.jupyter-wrapper .jp-CircleEmptyIcon{background-image:var(--jp-icon-circle-empty)}.jupyter-wrapper .jp-CircleIcon{background-image:var(--jp-icon-circle)}.jupyter-wrapper .jp-ClearIcon{background-image:var(--jp-icon-clear)}.jupyter-wrapper .jp-CloseIcon{background-image:var(--jp-icon-close)}.jupyter-wrapper .jp-CodeIcon{background-image:var(--jp-icon-code)}.jupyter-wrapper .jp-ConsoleIcon{background-image:var(--jp-icon-console)}.jupyter-wrapper .jp-CopyIcon{background-image:var(--jp-icon-copy)}.jupyter-wrapper .jp-CopyrightIcon{background-image:var(--jp-icon-copyright)}.jupyter-wrapper .jp-CutIcon{background-image:var(--jp-icon-cut)}.jupyter-wrapper .jp-DeleteIcon{background-image:var(--jp-icon-delete)}.jupyter-wrapper .jp-DownloadIcon{background-image:var(--jp-icon-download)}.jupyter-wrapper .jp-DuplicateIcon{background-image:var(--jp-icon-duplicate)}.jupyter-wrapper .jp-EditIcon{background-image:var(--jp-icon-edit)}.jupyter-wrapper .jp-EllipsesIcon{background-image:var(--jp-icon-ellipses)}.jupyter-wrapper .jp-ExtensionIcon{background-image:var(--jp-icon-extension)}.jupyter-wrapper .jp-FastForwardIcon{background-image:var(--jp-icon-fast-forward)}.jupyter-wrapper .jp-FileIcon{background-image:var(--jp-icon-file)}.jupyter-wrapper .jp-FileUploadIcon{background-image:var(--jp-icon-file-upload)}.jupyter-wrapper .jp-FilterListIcon{background-image:var(--jp-icon-filter-list)}.jupyter-wrapper .jp-FolderFavoriteIcon{background-image:var(--jp-icon-folder-favorite)}.jupyter-wrapper .jp-FolderIcon{background-image:var(--jp-icon-folder)}.jupyter-wrapper .jp-HomeIcon{background-image:var(--jp-icon-home)}.jupyter-wrapper .jp-Html5Icon{background-image:var(--jp-icon-html5)}.jupyter-wrapper .jp-ImageIcon{background-image:var(--jp-icon-image)}.jupyter-wrapper .jp-InspectorIcon{background-image:var(--jp-icon-inspector)}.jupyter-wrapper .jp-JsonIcon{background-image:var(--jp-icon-json)}.jupyter-wrapper .jp-JuliaIcon{background-image:var(--jp-icon-julia)}.jupyter-wrapper .jp-JupyterFaviconIcon{background-image:var(--jp-icon-jupyter-favicon)}.jupyter-wrapper .jp-JupyterIcon{background-image:var(--jp-icon-jupyter)}.jupyter-wrapper .jp-JupyterlabWordmarkIcon{background-image:var(--jp-icon-jupyterlab-wordmark)}.jupyter-wrapper .jp-KernelIcon{background-image:var(--jp-icon-kernel)}.jupyter-wrapper .jp-KeyboardIcon{background-image:var(--jp-icon-keyboard)}.jupyter-wrapper .jp-LaunchIcon{background-image:var(--jp-icon-launch)}.jupyter-wrapper .jp-LauncherIcon{background-image:var(--jp-icon-launcher)}.jupyter-wrapper .jp-LineFormIcon{background-image:var(--jp-icon-line-form)}.jupyter-wrapper .jp-LinkIcon{background-image:var(--jp-icon-link)}.jupyter-wrapper .jp-ListIcon{background-image:var(--jp-icon-list)}.jupyter-wrapper .jp-ListingsInfoIcon{background-image:var(--jp-icon-listings-info)}.jupyter-wrapper .jp-MarkdownIcon{background-image:var(--jp-icon-markdown)}.jupyter-wrapper .jp-MoveDownIcon{background-image:var(--jp-icon-move-down)}.jupyter-wrapper .jp-MoveUpIcon{background-image:var(--jp-icon-move-up)}.jupyter-wrapper .jp-NewFolderIcon{background-image:var(--jp-icon-new-folder)}.jupyter-wrapper .jp-NotTrustedIcon{background-image:var(--jp-icon-not-trusted)}.jupyter-wrapper .jp-NotebookIcon{background-image:var(--jp-icon-notebook)}.jupyter-wrapper .jp-NumberingIcon{background-image:var(--jp-icon-numbering)}.jupyter-wrapper .jp-OfflineBoltIcon{background-image:var(--jp-icon-offline-bolt)}.jupyter-wrapper .jp-PaletteIcon{background-image:var(--jp-icon-palette)}.jupyter-wrapper .jp-PasteIcon{background-image:var(--jp-icon-paste)}.jupyter-wrapper .jp-PdfIcon{background-image:var(--jp-icon-pdf)}.jupyter-wrapper .jp-PythonIcon{background-image:var(--jp-icon-python)}.jupyter-wrapper .jp-RKernelIcon{background-image:var(--jp-icon-r-kernel)}.jupyter-wrapper .jp-ReactIcon{background-image:var(--jp-icon-react)}.jupyter-wrapper .jp-RedoIcon{background-image:var(--jp-icon-redo)}.jupyter-wrapper .jp-RefreshIcon{background-image:var(--jp-icon-refresh)}.jupyter-wrapper .jp-RegexIcon{background-image:var(--jp-icon-regex)}.jupyter-wrapper .jp-RunIcon{background-image:var(--jp-icon-run)}.jupyter-wrapper .jp-RunningIcon{background-image:var(--jp-icon-running)}.jupyter-wrapper .jp-SaveIcon{background-image:var(--jp-icon-save)}.jupyter-wrapper .jp-SearchIcon{background-image:var(--jp-icon-search)}.jupyter-wrapper .jp-SettingsIcon{background-image:var(--jp-icon-settings)}.jupyter-wrapper .jp-ShareIcon{background-image:var(--jp-icon-share)}.jupyter-wrapper .jp-SpreadsheetIcon{background-image:var(--jp-icon-spreadsheet)}.jupyter-wrapper .jp-StopIcon{background-image:var(--jp-icon-stop)}.jupyter-wrapper .jp-TabIcon{background-image:var(--jp-icon-tab)}.jupyter-wrapper .jp-TableRowsIcon{background-image:var(--jp-icon-table-rows)}.jupyter-wrapper .jp-TagIcon{background-image:var(--jp-icon-tag)}.jupyter-wrapper .jp-TerminalIcon{background-image:var(--jp-icon-terminal)}.jupyter-wrapper .jp-TextEditorIcon{background-image:var(--jp-icon-text-editor)}.jupyter-wrapper .jp-TocIcon{background-image:var(--jp-icon-toc)}.jupyter-wrapper .jp-TreeViewIcon{background-image:var(--jp-icon-tree-view)}.jupyter-wrapper .jp-TrustedIcon{background-image:var(--jp-icon-trusted)}.jupyter-wrapper .jp-UndoIcon{background-image:var(--jp-icon-undo)}.jupyter-wrapper .jp-UserIcon{background-image:var(--jp-icon-user)}.jupyter-wrapper .jp-UsersIcon{background-image:var(--jp-icon-users)}.jupyter-wrapper .jp-VegaIcon{background-image:var(--jp-icon-vega)}.jupyter-wrapper .jp-YamlIcon{background-image:var(--jp-icon-yaml)}.jupyter-wrapper .jp-Icon,.jupyter-wrapper .jp-MaterialIcon{background-position:center;background-repeat:no-repeat;background-size:16px;min-width:16px;min-height:16px}.jupyter-wrapper .jp-Icon-cover{background-position:center;background-repeat:no-repeat;background-size:cover}.jupyter-wrapper .jp-Icon-16{background-size:16px;min-width:16px;min-height:16px}.jupyter-wrapper .jp-Icon-18{background-size:18px;min-width:18px;min-height:18px}.jupyter-wrapper .jp-Icon-20{background-size:20px;min-width:20px;min-height:20px}.jupyter-wrapper .lm-TabBar .lm-TabBar-addButton{align-items:center;display:flex;padding:4px 4px 5px;margin-right:1px;background-color:var(--jp-layout-color2)}.jupyter-wrapper .lm-TabBar .lm-TabBar-addButton:hover{background-color:var(--jp-layout-color1)}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-tab{width:var(--jp-private-horizontal-tab-width)}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-content{flex:unset}.jupyter-wrapper .lm-DockPanel-tabBar[data-orientation=horizontal]{flex:1 1 auto}.jupyter-wrapper .jp-icon0[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon1[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon2[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon3[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon4[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon0[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon1[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon2[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon3[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon4[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-accent0[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-accent1[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-accent2[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-accent3[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-accent4[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-accent0[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-accent1[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-accent2[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-accent3[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-accent4[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-none[fill]{fill:none}.jupyter-wrapper .jp-icon-none[stroke]{stroke:none}.jupyter-wrapper .jp-icon-brand0[fill]{fill:var(--jp-brand-color0)}.jupyter-wrapper .jp-icon-brand1[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper .jp-icon-brand2[fill]{fill:var(--jp-brand-color2)}.jupyter-wrapper .jp-icon-brand3[fill]{fill:var(--jp-brand-color3)}.jupyter-wrapper .jp-icon-brand4[fill]{fill:var(--jp-brand-color4)}.jupyter-wrapper .jp-icon-brand0[stroke]{stroke:var(--jp-brand-color0)}.jupyter-wrapper .jp-icon-brand1[stroke]{stroke:var(--jp-brand-color1)}.jupyter-wrapper .jp-icon-brand2[stroke]{stroke:var(--jp-brand-color2)}.jupyter-wrapper .jp-icon-brand3[stroke]{stroke:var(--jp-brand-color3)}.jupyter-wrapper .jp-icon-brand4[stroke]{stroke:var(--jp-brand-color4)}.jupyter-wrapper .jp-icon-warn0[fill]{fill:var(--jp-warn-color0)}.jupyter-wrapper .jp-icon-warn1[fill]{fill:var(--jp-warn-color1)}.jupyter-wrapper .jp-icon-warn2[fill]{fill:var(--jp-warn-color2)}.jupyter-wrapper .jp-icon-warn3[fill]{fill:var(--jp-warn-color3)}.jupyter-wrapper .jp-icon-warn0[stroke]{stroke:var(--jp-warn-color0)}.jupyter-wrapper .jp-icon-warn1[stroke]{stroke:var(--jp-warn-color1)}.jupyter-wrapper .jp-icon-warn2[stroke]{stroke:var(--jp-warn-color2)}.jupyter-wrapper .jp-icon-warn3[stroke]{stroke:var(--jp-warn-color3)}.jupyter-wrapper .jp-icon-contrast0[fill]{fill:var(--jp-icon-contrast-color0)}.jupyter-wrapper .jp-icon-contrast1[fill]{fill:var(--jp-icon-contrast-color1)}.jupyter-wrapper .jp-icon-contrast2[fill]{fill:var(--jp-icon-contrast-color2)}.jupyter-wrapper .jp-icon-contrast3[fill]{fill:var(--jp-icon-contrast-color3)}.jupyter-wrapper .jp-icon-contrast0[stroke]{stroke:var(--jp-icon-contrast-color0)}.jupyter-wrapper .jp-icon-contrast1[stroke]{stroke:var(--jp-icon-contrast-color1)}.jupyter-wrapper .jp-icon-contrast2[stroke]{stroke:var(--jp-icon-contrast-color2)}.jupyter-wrapper .jp-icon-contrast3[stroke]{stroke:var(--jp-icon-contrast-color3)}.jupyter-wrapper .jp-jupyter-icon-color[fill]{fill:var(--jp-jupyter-icon-color, var(--jp-warn-color0))}.jupyter-wrapper .jp-notebook-icon-color[fill]{fill:var(--jp-notebook-icon-color, var(--jp-warn-color0))}.jupyter-wrapper .jp-json-icon-color[fill]{fill:var(--jp-json-icon-color, var(--jp-warn-color1))}.jupyter-wrapper .jp-console-icon-color[fill]{fill:var(--jp-console-icon-color, white)}.jupyter-wrapper .jp-console-icon-background-color[fill]{fill:var(--jp-console-icon-background-color, var(--jp-brand-color1))}.jupyter-wrapper .jp-terminal-icon-color[fill]{fill:var(--jp-terminal-icon-color, var(--jp-layout-color2))}.jupyter-wrapper .jp-terminal-icon-background-color[fill]{fill:var(--jp-terminal-icon-background-color, var(--jp-inverse-layout2))}.jupyter-wrapper .jp-text-editor-icon-color[fill]{fill:var(--jp-text-editor-icon-color, var(--jp-inverse-layout3))}.jupyter-wrapper .jp-inspector-icon-color[fill]{fill:var(--jp-inspector-icon-color, var(--jp-inverse-layout3))}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill],.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-hover :hover .jp-icon-selectable[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-hover :hover .jp-icon-selectable-inverse[fill]{fill:#fff}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon3[fill]{fill:none}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty.jp-mod-active>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:#fff}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon3[fill]{fill:none}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper #jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper #jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper :root{--jp-warn-color0: var(--md-orange-700)}.jupyter-wrapper .jp-DragIcon{margin-right:4px}.jupyter-wrapper .jp-icon-alt .jp-icon0[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon1[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon2[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon3[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon4[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon0[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon1[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon2[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon3[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon4[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent0[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent1[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent2[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent3[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent4[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent0[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent1[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent2[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent3[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent4[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content{display:none!important}.jupyter-wrapper .jp-icon-hover :hover .jp-icon0-hover[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon1-hover[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon2-hover[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon3-hover[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon4-hover[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon0-hover[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon1-hover[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon2-hover[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon3-hover[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon4-hover[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent0-hover[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent1-hover[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent2-hover[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent3-hover[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent4-hover[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent0-hover[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent1-hover[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent2-hover[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent3-hover[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent4-hover[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-none-hover[fill]{fill:none}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-none-hover[stroke]{stroke:none}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-switch{display:flex;align-items:center;padding-left:4px;padding-right:4px;font-size:var(--jp-ui-font-size1);background-color:transparent;color:var(--jp-ui-font-color1);border:none;height:20px}.jupyter-wrapper .jp-switch:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-switch-label{margin-right:5px}.jupyter-wrapper .jp-switch-track{cursor:pointer;background-color:var(--jp-switch-color, var(--jp-border-color1));-webkit-transition:.4s;transition:.4s;border-radius:34px;height:16px;width:35px;position:relative}.jupyter-wrapper .jp-switch-track:before{content:"";position:absolute;height:10px;width:10px;margin:3px;left:0;background-color:var(--jp-ui-inverse-font-color1);-webkit-transition:.4s;transition:.4s;border-radius:50%}.jupyter-wrapper .jp-switch[aria-checked=true] .jp-switch-track{background-color:var(--jp-switch-true-position-color, var(--jp-warn-color0))}.jupyter-wrapper .jp-switch[aria-checked=true] .jp-switch-track:before{left:19px}.jupyter-wrapper html{box-sizing:unset}.jupyter-wrapper *,.jupyter-wrapper *:before,.jupyter-wrapper *:after{box-sizing:unset}.jupyter-wrapper body{color:unset;font-family:var(--jp-ui-font-family)}.jupyter-wrapper :focus{outline:unset;outline-offset:unset;-moz-outline-radius:unset}.jupyter-wrapper .jp-Button{border-radius:var(--jp-border-radius);padding:0 12px;font-size:var(--jp-ui-font-size1)}.jupyter-wrapper button.jp-Button.bp3-button.bp3-minimal:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-Button.minimal{color:unset!important}.jupyter-wrapper .jp-Button.jp-ToolbarButtonComponent{text-transform:none}.jupyter-wrapper .jp-InputGroup input{box-sizing:border-box;border-radius:0;background-color:transparent;color:var(--jp-ui-font-color0);box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color)}.jupyter-wrapper .jp-InputGroup input:focus{box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-active-box-shadow-color),inset 0 0 0 3px var(--jp-input-active-box-shadow-color)}.jupyter-wrapper .jp-InputGroup input::placeholder,.jupyter-wrapper input::placeholder{color:var(--jp-ui-font-color3)}.jupyter-wrapper .jp-BPIcon{display:inline-block;vertical-align:middle;margin:auto}.jupyter-wrapper .bp3-icon.jp-BPIcon>svg:not([fill]){fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-InputGroupAction{padding:6px}.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select{background-color:initial;border:none;border-radius:0;box-shadow:none;color:var(--jp-ui-font-color0);display:block;font-size:var(--jp-ui-font-size1);height:24px;line-height:14px;padding:0 25px 0 10px;text-align:left;-moz-appearance:none;-webkit-appearance:none}.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select:hover,.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select>option{background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color0)}.jupyter-wrapper select{box-sizing:border-box}.jupyter-wrapper .jp-Collapse{display:flex;flex-direction:column;align-items:stretch;border-top:1px solid var(--jp-border-color2);border-bottom:1px solid var(--jp-border-color2)}.jupyter-wrapper .jp-Collapse-header{padding:1px 12px;color:var(--jp-ui-font-color1);background-color:var(--jp-layout-color1);font-size:var(--jp-ui-font-size2)}.jupyter-wrapper .jp-Collapse-header:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-Collapse-contents{padding:0 12px;background-color:var(--jp-layout-color1);color:var(--jp-ui-font-color1);overflow:auto}.jupyter-wrapper :root{--jp-private-commandpalette-search-height: 28px}.jupyter-wrapper .lm-CommandPalette{padding-bottom:0;color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .jp-ModalCommandPalette{position:absolute;z-index:10000;top:38px;left:30%;margin:0;padding:4px;width:40%;box-shadow:var(--jp-elevation-z4);border-radius:4px;background:var(--jp-layout-color0)}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette{max-height:40vh}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon:after{display:none}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header{display:none}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item{margin-left:4px;margin-right:4px}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item.lm-mod-disabled{display:none}.jupyter-wrapper .lm-CommandPalette-search{padding:4px;background-color:var(--jp-layout-color1);z-index:2}.jupyter-wrapper .lm-CommandPalette-wrapper{overflow:overlay;padding:0 9px;background-color:var(--jp-input-active-background);height:30px;box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color)}.jupyter-wrapper .lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper{box-shadow:inset 0 0 0 1px var(--jp-input-active-box-shadow-color),inset 0 0 0 3px var(--jp-input-active-box-shadow-color)}.jupyter-wrapper .jp-SearchIconGroup{color:#fff;background-color:var(--jp-brand-color1);position:absolute;top:4px;right:4px;padding:5px 5px 1px}.jupyter-wrapper .jp-SearchIconGroup svg{height:20px;width:20px}.jupyter-wrapper .jp-SearchIconGroup .jp-icon3[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .lm-CommandPalette-input{background:transparent;width:calc(100% - 18px);float:left;border:none;outline:none;font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);line-height:var(--jp-private-commandpalette-search-height)}.jupyter-wrapper .lm-CommandPalette-input::-webkit-input-placeholder,.jupyter-wrapper .lm-CommandPalette-input::-moz-placeholder,.jupyter-wrapper .lm-CommandPalette-input:-ms-input-placeholder{color:var(--jp-ui-font-color2);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .lm-CommandPalette-header:first-child{margin-top:0}.jupyter-wrapper .lm-CommandPalette-header{border-bottom:solid var(--jp-border-width) var(--jp-border-color2);color:var(--jp-ui-font-color1);cursor:pointer;display:flex;font-size:var(--jp-ui-font-size0);font-weight:600;letter-spacing:1px;margin-top:8px;padding:8px 0 8px 12px;text-transform:uppercase}.jupyter-wrapper .lm-CommandPalette-header.lm-mod-active{background:var(--jp-layout-color2)}.jupyter-wrapper .lm-CommandPalette-header>mark{background-color:transparent;font-weight:700;color:var(--jp-ui-font-color1)}.jupyter-wrapper .lm-CommandPalette-item{padding:4px 12px 4px 4px;color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);font-weight:400;display:flex}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled{color:var(--jp-ui-font-color2)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active{color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel>mark{color:var(--jp-ui-inverse-font-color0)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled){color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.jupyter-wrapper .lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled){background:var(--jp-layout-color2)}.jupyter-wrapper .lm-CommandPalette-itemContent{overflow:hidden}.jupyter-wrapper .lm-CommandPalette-itemLabel>mark{color:var(--jp-ui-font-color0);background-color:transparent;font-weight:700}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled mark{color:var(--jp-ui-font-color2)}.jupyter-wrapper .lm-CommandPalette-item .lm-CommandPalette-itemIcon{margin:0 4px 0 0;position:relative;width:16px;top:2px;flex:0 0 auto}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon{opacity:.6}.jupyter-wrapper .lm-CommandPalette-item .lm-CommandPalette-itemShortcut{flex:0 0 auto}.jupyter-wrapper .lm-CommandPalette-itemCaption{display:none}.jupyter-wrapper .lm-CommandPalette-content{background-color:var(--jp-layout-color1)}.jupyter-wrapper .lm-CommandPalette-content:empty:after{content:"No results";margin:20px auto auto;width:100px;display:block;font-size:var(--jp-ui-font-size2);font-family:var(--jp-ui-font-family);font-weight:lighter}.jupyter-wrapper .lm-CommandPalette-emptyMessage{text-align:center;margin-top:24px;line-height:1.32;padding:0 8px;color:var(--jp-content-font-color3)}.jupyter-wrapper .jp-Dialog{position:absolute;z-index:10000;display:flex;flex-direction:column;align-items:center;justify-content:center;top:0;left:0;margin:0;padding:0;width:100%;height:100%;background:var(--jp-dialog-background)}.jupyter-wrapper .jp-Dialog-content{display:flex;flex-direction:column;margin-left:auto;margin-right:auto;background:var(--jp-layout-color1);padding:24px 24px 12px;min-width:300px;min-height:150px;max-width:1000px;max-height:500px;box-sizing:border-box;box-shadow:var(--jp-elevation-z20);word-wrap:break-word;border-radius:var(--jp-border-radius);font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color1);resize:both}.jupyter-wrapper .jp-Dialog-content.jp-Dialog-content-small{max-width:500px}.jupyter-wrapper .jp-Dialog-button{overflow:visible}.jupyter-wrapper button.jp-Dialog-button:focus{outline:1px solid var(--jp-brand-color1);outline-offset:4px;-moz-outline-radius:0px}.jupyter-wrapper button.jp-Dialog-button:focus::-moz-focus-inner{border:0}.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus{outline-offset:4px;-moz-outline-radius:0px}.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus{outline:1px solid var(--md-blue-700)}.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus{outline:1px solid var(--md-red-600)}.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus{outline:1px solid var(--md-grey-700)}.jupyter-wrapper button.jp-Dialog-close-button{padding:0;height:100%;min-width:unset;min-height:unset}.jupyter-wrapper .jp-Dialog-header{display:flex;justify-content:space-between;flex:0 0 auto;padding-bottom:12px;font-size:var(--jp-ui-font-size3);font-weight:400;color:var(--jp-ui-font-color0)}.jupyter-wrapper .jp-Dialog-body{display:flex;flex-direction:column;flex:1 1 auto;font-size:var(--jp-ui-font-size1);background:var(--jp-layout-color1);overflow:auto}.jupyter-wrapper .jp-Dialog-footer{display:flex;flex-direction:row;justify-content:flex-end;align-items:center;flex:0 0 auto;margin-left:-12px;margin-right:-12px;padding:12px}.jupyter-wrapper .jp-Dialog-checkbox{padding-right:5px}.jupyter-wrapper .jp-Dialog-checkbox>input:focus-visible{outline:1px solid var(--jp-input-active-border-color);outline-offset:1px}.jupyter-wrapper .jp-Dialog-spacer{flex:1 1 auto}.jupyter-wrapper .jp-Dialog-title{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .jp-Dialog-body>.jp-select-wrapper{width:100%}.jupyter-wrapper .jp-Dialog-body>button{padding:0 16px}.jupyter-wrapper .jp-Dialog-body>label{line-height:1.4;color:var(--jp-ui-font-color0)}.jupyter-wrapper .jp-Dialog-button.jp-mod-styled:not(:last-child){margin-right:12px}.jupyter-wrapper .jp-HoverBox{position:fixed}.jupyter-wrapper .jp-HoverBox.jp-mod-outofview{display:none}.jupyter-wrapper .jp-IFrame{width:100%;height:100%}.jupyter-wrapper .jp-IFrame>iframe{border:none}.jupyter-wrapper body.lm-mod-override-cursor .jp-IFrame{position:relative}.jupyter-wrapper body.lm-mod-override-cursor .jp-IFrame:before{content:"";position:absolute;top:0;left:0;right:0;bottom:0;background:transparent}.jupyter-wrapper .jp-Input-Boolean-Dialog{flex-direction:row-reverse;align-items:end;width:100%}.jupyter-wrapper .jp-Input-Boolean-Dialog>label{flex:1 1 auto}.jupyter-wrapper .jp-MainAreaWidget>:focus{outline:none}.jupyter-wrapper .jp-MainAreaWidget .jp-MainAreaWidget-error{padding:6px}.jupyter-wrapper .jp-MainAreaWidget .jp-MainAreaWidget-error>pre{width:auto;padding:10px;background:var(--jp-error-color3);border:var(--jp-border-width) solid var(--jp-error-color1);border-radius:var(--jp-border-radius);color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);white-space:pre-wrap;word-wrap:break-word}.jupyter-wrapper .jp-MainAreaWidget{contain:strict}.jupyter-wrapper :root{--md-red-50: #ffebee;--md-red-100: #ffcdd2;--md-red-200: #ef9a9a;--md-red-300: #e57373;--md-red-400: #ef5350;--md-red-500: #f44336;--md-red-600: #e53935;--md-red-700: #d32f2f;--md-red-800: #c62828;--md-red-900: #b71c1c;--md-red-A100: #ff8a80;--md-red-A200: #ff5252;--md-red-A400: #ff1744;--md-red-A700: #d50000;--md-pink-50: #fce4ec;--md-pink-100: #f8bbd0;--md-pink-200: #f48fb1;--md-pink-300: #f06292;--md-pink-400: #ec407a;--md-pink-500: #e91e63;--md-pink-600: #d81b60;--md-pink-700: #c2185b;--md-pink-800: #ad1457;--md-pink-900: #880e4f;--md-pink-A100: #ff80ab;--md-pink-A200: #ff4081;--md-pink-A400: #f50057;--md-pink-A700: #c51162;--md-purple-50: #f3e5f5;--md-purple-100: #e1bee7;--md-purple-200: #ce93d8;--md-purple-300: #ba68c8;--md-purple-400: #ab47bc;--md-purple-500: #9c27b0;--md-purple-600: #8e24aa;--md-purple-700: #7b1fa2;--md-purple-800: #6a1b9a;--md-purple-900: #4a148c;--md-purple-A100: #ea80fc;--md-purple-A200: #e040fb;--md-purple-A400: #d500f9;--md-purple-A700: #aa00ff;--md-deep-purple-50: #ede7f6;--md-deep-purple-100: #d1c4e9;--md-deep-purple-200: #b39ddb;--md-deep-purple-300: #9575cd;--md-deep-purple-400: #7e57c2;--md-deep-purple-500: #673ab7;--md-deep-purple-600: #5e35b1;--md-deep-purple-700: #512da8;--md-deep-purple-800: #4527a0;--md-deep-purple-900: #311b92;--md-deep-purple-A100: #b388ff;--md-deep-purple-A200: #7c4dff;--md-deep-purple-A400: #651fff;--md-deep-purple-A700: #6200ea;--md-indigo-50: #e8eaf6;--md-indigo-100: #c5cae9;--md-indigo-200: #9fa8da;--md-indigo-300: #7986cb;--md-indigo-400: #5c6bc0;--md-indigo-500: #3f51b5;--md-indigo-600: #3949ab;--md-indigo-700: #303f9f;--md-indigo-800: #283593;--md-indigo-900: #1a237e;--md-indigo-A100: #8c9eff;--md-indigo-A200: #536dfe;--md-indigo-A400: #3d5afe;--md-indigo-A700: #304ffe;--md-blue-50: #e3f2fd;--md-blue-100: #bbdefb;--md-blue-200: #90caf9;--md-blue-300: #64b5f6;--md-blue-400: #42a5f5;--md-blue-500: #2196f3;--md-blue-600: #1e88e5;--md-blue-700: #1976d2;--md-blue-800: #1565c0;--md-blue-900: #0d47a1;--md-blue-A100: #82b1ff;--md-blue-A200: #448aff;--md-blue-A400: #2979ff;--md-blue-A700: #2962ff;--md-light-blue-50: #e1f5fe;--md-light-blue-100: #b3e5fc;--md-light-blue-200: #81d4fa;--md-light-blue-300: #4fc3f7;--md-light-blue-400: #29b6f6;--md-light-blue-500: #03a9f4;--md-light-blue-600: #039be5;--md-light-blue-700: #0288d1;--md-light-blue-800: #0277bd;--md-light-blue-900: #01579b;--md-light-blue-A100: #80d8ff;--md-light-blue-A200: #40c4ff;--md-light-blue-A400: #00b0ff;--md-light-blue-A700: #0091ea;--md-cyan-50: #e0f7fa;--md-cyan-100: #b2ebf2;--md-cyan-200: #80deea;--md-cyan-300: #4dd0e1;--md-cyan-400: #26c6da;--md-cyan-500: #00bcd4;--md-cyan-600: #00acc1;--md-cyan-700: #0097a7;--md-cyan-800: #00838f;--md-cyan-900: #006064;--md-cyan-A100: #84ffff;--md-cyan-A200: #18ffff;--md-cyan-A400: #00e5ff;--md-cyan-A700: #00b8d4;--md-teal-50: #e0f2f1;--md-teal-100: #b2dfdb;--md-teal-200: #80cbc4;--md-teal-300: #4db6ac;--md-teal-400: #26a69a;--md-teal-500: #009688;--md-teal-600: #00897b;--md-teal-700: #00796b;--md-teal-800: #00695c;--md-teal-900: #004d40;--md-teal-A100: #a7ffeb;--md-teal-A200: #64ffda;--md-teal-A400: #1de9b6;--md-teal-A700: #00bfa5;--md-green-50: #e8f5e9;--md-green-100: #c8e6c9;--md-green-200: #a5d6a7;--md-green-300: #81c784;--md-green-400: #66bb6a;--md-green-500: #4caf50;--md-green-600: #43a047;--md-green-700: #388e3c;--md-green-800: #2e7d32;--md-green-900: #1b5e20;--md-green-A100: #b9f6ca;--md-green-A200: #69f0ae;--md-green-A400: #00e676;--md-green-A700: #00c853;--md-light-green-50: #f1f8e9;--md-light-green-100: #dcedc8;--md-light-green-200: #c5e1a5;--md-light-green-300: #aed581;--md-light-green-400: #9ccc65;--md-light-green-500: #8bc34a;--md-light-green-600: #7cb342;--md-light-green-700: #689f38;--md-light-green-800: #558b2f;--md-light-green-900: #33691e;--md-light-green-A100: #ccff90;--md-light-green-A200: #b2ff59;--md-light-green-A400: #76ff03;--md-light-green-A700: #64dd17;--md-lime-50: #f9fbe7;--md-lime-100: #f0f4c3;--md-lime-200: #e6ee9c;--md-lime-300: #dce775;--md-lime-400: #d4e157;--md-lime-500: #cddc39;--md-lime-600: #c0ca33;--md-lime-700: #afb42b;--md-lime-800: #9e9d24;--md-lime-900: #827717;--md-lime-A100: #f4ff81;--md-lime-A200: #eeff41;--md-lime-A400: #c6ff00;--md-lime-A700: #aeea00;--md-yellow-50: #fffde7;--md-yellow-100: #fff9c4;--md-yellow-200: #fff59d;--md-yellow-300: #fff176;--md-yellow-400: #ffee58;--md-yellow-500: #ffeb3b;--md-yellow-600: #fdd835;--md-yellow-700: #fbc02d;--md-yellow-800: #f9a825;--md-yellow-900: #f57f17;--md-yellow-A100: #ffff8d;--md-yellow-A200: #ffff00;--md-yellow-A400: #ffea00;--md-yellow-A700: #ffd600;--md-amber-50: #fff8e1;--md-amber-100: #ffecb3;--md-amber-200: #ffe082;--md-amber-300: #ffd54f;--md-amber-400: #ffca28;--md-amber-500: #ffc107;--md-amber-600: #ffb300;--md-amber-700: #ffa000;--md-amber-800: #ff8f00;--md-amber-900: #ff6f00;--md-amber-A100: #ffe57f;--md-amber-A200: #ffd740;--md-amber-A400: #ffc400;--md-amber-A700: #ffab00;--md-orange-50: #fff3e0;--md-orange-100: #ffe0b2;--md-orange-200: #ffcc80;--md-orange-300: #ffb74d;--md-orange-400: #ffa726;--md-orange-500: #ff9800;--md-orange-600: #fb8c00;--md-orange-700: #f57c00;--md-orange-800: #ef6c00;--md-orange-900: #e65100;--md-orange-A100: #ffd180;--md-orange-A200: #ffab40;--md-orange-A400: #ff9100;--md-orange-A700: #ff6d00;--md-deep-orange-50: #fbe9e7;--md-deep-orange-100: #ffccbc;--md-deep-orange-200: #ffab91;--md-deep-orange-300: #ff8a65;--md-deep-orange-400: #ff7043;--md-deep-orange-500: #ff5722;--md-deep-orange-600: #f4511e;--md-deep-orange-700: #e64a19;--md-deep-orange-800: #d84315;--md-deep-orange-900: #bf360c;--md-deep-orange-A100: #ff9e80;--md-deep-orange-A200: #ff6e40;--md-deep-orange-A400: #ff3d00;--md-deep-orange-A700: #dd2c00;--md-brown-50: #efebe9;--md-brown-100: #d7ccc8;--md-brown-200: #bcaaa4;--md-brown-300: #a1887f;--md-brown-400: #8d6e63;--md-brown-500: #795548;--md-brown-600: #6d4c41;--md-brown-700: #5d4037;--md-brown-800: #4e342e;--md-brown-900: #3e2723;--md-grey-50: #fafafa;--md-grey-100: #f5f5f5;--md-grey-200: #eeeeee;--md-grey-300: #e0e0e0;--md-grey-400: #bdbdbd;--md-grey-500: #9e9e9e;--md-grey-600: #757575;--md-grey-700: #616161;--md-grey-800: #424242;--md-grey-900: #212121;--md-blue-grey-50: #eceff1;--md-blue-grey-100: #cfd8dc;--md-blue-grey-200: #b0bec5;--md-blue-grey-300: #90a4ae;--md-blue-grey-400: #78909c;--md-blue-grey-500: #607d8b;--md-blue-grey-600: #546e7a;--md-blue-grey-700: #455a64;--md-blue-grey-800: #37474f;--md-blue-grey-900: #263238}.jupyter-wrapper .jp-Spinner{position:absolute;display:flex;justify-content:center;align-items:center;z-index:10;left:0;top:0;width:100%;height:100%;background:var(--jp-layout-color0);outline:none}.jupyter-wrapper .jp-SpinnerContent{font-size:10px;margin:50px auto;text-indent:-9999em;width:3em;height:3em;border-radius:50%;background:var(--jp-brand-color3);background:linear-gradient(to right,#f37626 10%,rgba(255,255,255,0) 42%);position:relative;animation:load3 1s infinite linear,fadeIn 1s}.jupyter-wrapper .jp-SpinnerContent:before{width:50%;height:50%;background:#f37626;border-radius:100% 0 0;position:absolute;top:0;left:0;content:""}.jupyter-wrapper .jp-SpinnerContent:after{background:var(--jp-layout-color0);width:75%;height:75%;border-radius:50%;content:"";margin:auto;position:absolute;top:0;left:0;bottom:0;right:0}@keyframes fadeIn{0%{opacity:0}to{opacity:1}}@keyframes load3{0%{transform:rotate(0)}to{transform:rotate(360deg)}}.jupyter-wrapper button.jp-mod-styled{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);border:none;box-sizing:border-box;text-align:center;line-height:32px;height:32px;padding:0 12px;letter-spacing:.8px;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper input.jp-mod-styled{background:var(--jp-input-background);height:28px;box-sizing:border-box;border:var(--jp-border-width) solid var(--jp-border-color1);padding-left:7px;padding-right:7px;font-size:var(--jp-ui-font-size2);color:var(--jp-ui-font-color0);outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper input[type=checkbox].jp-mod-styled{appearance:checkbox;-webkit-appearance:checkbox;-moz-appearance:checkbox;height:auto}.jupyter-wrapper input.jp-mod-styled:focus{border:var(--jp-border-width) solid var(--md-blue-500);box-shadow:inset 0 0 4px var(--md-blue-300)}.jupyter-wrapper .jp-FileDialog-Checkbox{margin-top:35px;display:flex;flex-direction:row;align-items:end;width:100%}.jupyter-wrapper .jp-FileDialog-Checkbox>label{flex:1 1 auto}.jupyter-wrapper .jp-select-wrapper{display:flex;position:relative;flex-direction:column;padding:1px;background-color:var(--jp-layout-color1);height:28px;box-sizing:border-box;margin-bottom:12px}.jupyter-wrapper .jp-select-wrapper.jp-mod-focused select.jp-mod-styled{border:var(--jp-border-width) solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow);background-color:var(--jp-input-active-background)}.jupyter-wrapper select.jp-mod-styled:hover{background-color:var(--jp-layout-color1);cursor:pointer;color:var(--jp-ui-font-color0);background-color:var(--jp-input-hover-background);box-shadow:inset 0 0 1px #00000080}.jupyter-wrapper select.jp-mod-styled{flex:1 1 auto;height:32px;width:100%;font-size:var(--jp-ui-font-size2);background:var(--jp-input-background);color:var(--jp-ui-font-color0);padding:0 25px 0 8px;border:var(--jp-border-width) solid var(--jp-input-border-color);border-radius:0;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper :root{--jp-private-toolbar-height: calc( 28px + var(--jp-border-width) )}.jupyter-wrapper .jp-Toolbar{color:var(--jp-ui-font-color1);flex:0 0 auto;display:flex;flex-direction:row;border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);box-shadow:var(--jp-toolbar-box-shadow);background:var(--jp-toolbar-background);min-height:var(--jp-toolbar-micro-height);padding:2px;z-index:8;overflow-x:hidden}.jupyter-wrapper .jp-Toolbar>.jp-Toolbar-item.jp-Toolbar-spacer{flex-grow:1;flex-shrink:1}.jupyter-wrapper .jp-Toolbar-item.jp-Toolbar-kernelStatus{display:inline-block;width:32px;background-repeat:no-repeat;background-position:center;background-size:16px}.jupyter-wrapper .jp-Toolbar>.jp-Toolbar-item{flex:0 0 auto;display:flex;padding-left:1px;padding-right:1px;font-size:var(--jp-ui-font-size1);line-height:var(--jp-private-toolbar-height);height:100%}.jupyter-wrapper div.jp-ToolbarButton{color:transparent;border:none;box-sizing:border-box;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none;padding:0;margin:0}.jupyter-wrapper button.jp-ToolbarButtonComponent{background:var(--jp-layout-color1);border:none;box-sizing:border-box;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none;padding:0 6px;margin:0;height:24px;border-radius:var(--jp-border-radius);display:flex;align-items:center;text-align:center;font-size:14px;min-width:unset;min-height:unset}.jupyter-wrapper button.jp-ToolbarButtonComponent:disabled{opacity:.4}.jupyter-wrapper button.jp-ToolbarButtonComponent span{padding:0;flex:0 0 auto}.jupyter-wrapper button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label{font-size:var(--jp-ui-font-size1);line-height:100%;padding-left:2px;color:var(--jp-ui-font-color1)}.jupyter-wrapper #jp-main-dock-panel[data-mode=single-document] .jp-MainAreaWidget>.jp-Toolbar.jp-Toolbar-micro{padding:0;min-height:0}.jupyter-wrapper #jp-main-dock-panel[data-mode=single-document] .jp-MainAreaWidget>.jp-Toolbar{border:none;box-shadow:none}.jupyter-wrapper body.p-mod-override-cursor *,.jupyter-wrapper body.lm-mod-override-cursor *{cursor:inherit!important}.jupyter-wrapper .jp-JSONEditor{display:flex;flex-direction:column;width:100%}.jupyter-wrapper .jp-JSONEditor-host{flex:1 1 auto;border:var(--jp-border-width) solid var(--jp-input-border-color);border-radius:0;background:var(--jp-layout-color0);min-height:50px;padding:1px}.jupyter-wrapper .jp-JSONEditor.jp-mod-error .jp-JSONEditor-host{border-color:red;outline-color:red}.jupyter-wrapper .jp-JSONEditor-header{display:flex;flex:1 0 auto;padding:0 0 0 12px}.jupyter-wrapper .jp-JSONEditor-header label{flex:0 0 auto}.jupyter-wrapper .jp-JSONEditor-commitButton{height:16px;width:16px;background-size:18px;background-repeat:no-repeat;background-position:center}.jupyter-wrapper .jp-JSONEditor-host.jp-mod-focused{background-color:var(--jp-input-active-background);border:1px solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow)}.jupyter-wrapper .jp-Editor.jp-mod-dropTarget{border:var(--jp-border-width) solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow)}.jupyter-wrapper .jp-Statusbar-ProgressCircle svg{display:block;margin:0 auto;width:16px;height:24px;align-self:normal}.jupyter-wrapper .jp-Statusbar-ProgressCircle path{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-Statusbar-ProgressBar-progress-bar{height:10px;width:100px;border:solid .25px var(--jp-brand-color2);border-radius:3px;overflow:hidden;align-self:center}.jupyter-wrapper .jp-Statusbar-ProgressBar-progress-bar>div{background-color:var(--jp-brand-color2);background-image:linear-gradient(-45deg,rgba(255,255,255,.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.2) 50%,rgba(255,255,255,.2) 75%,transparent 75%,transparent);background-size:40px 40px;float:left;width:0%;height:100%;font-size:12px;line-height:14px;color:#fff;text-align:center;animation:jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite}.jupyter-wrapper .jp-Statusbar-ProgressBar-progress-bar p{color:var(--jp-ui-font-color1);font-family:var(--jp-ui-font-family);font-size:var(--jp-ui-font-size1);line-height:10px;width:100px}@keyframes jp-Statusbar-ExecutionTime-progress-bar{0%{background-position:0 0}to{background-position:40px 40px}}.jupyter-wrapper .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.jupyter-wrapper .CodeMirror-lines{padding:4px 0}.jupyter-wrapper .CodeMirror pre.CodeMirror-line,.jupyter-wrapper .CodeMirror pre.CodeMirror-line-like{padding:0 4px}.jupyter-wrapper .CodeMirror-scrollbar-filler,.jupyter-wrapper .CodeMirror-gutter-filler{background-color:#fff}.jupyter-wrapper .CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.jupyter-wrapper .CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.jupyter-wrapper .CodeMirror-guttermarker{color:#000}.jupyter-wrapper .CodeMirror-guttermarker-subtle{color:#999}.jupyter-wrapper .CodeMirror-cursor{border-left:1px solid black;border-right:none;width:0}.jupyter-wrapper .CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.jupyter-wrapper .cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.jupyter-wrapper .cm-fat-cursor div.CodeMirror-cursors{z-index:1}.jupyter-wrapper .cm-fat-cursor-mark{background-color:#14ff1480;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite}.jupyter-wrapper .cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.jupyter-wrapper .cm-tab{display:inline-block;text-decoration:inherit}.jupyter-wrapper .CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:0;overflow:hidden}.jupyter-wrapper .CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.jupyter-wrapper .cm-s-default .cm-header{color:#00f}.jupyter-wrapper .cm-s-default .cm-quote{color:#090}.jupyter-wrapper .cm-negative{color:#d44}.jupyter-wrapper .cm-positive{color:#292}.jupyter-wrapper .cm-header,.jupyter-wrapper .cm-strong{font-weight:700}.jupyter-wrapper .cm-em{font-style:italic}.jupyter-wrapper .cm-link{text-decoration:underline}.jupyter-wrapper .cm-strikethrough{text-decoration:line-through}.jupyter-wrapper .cm-s-default .cm-keyword{color:#708}.jupyter-wrapper .cm-s-default .cm-atom{color:#219}.jupyter-wrapper .cm-s-default .cm-number{color:#164}.jupyter-wrapper .cm-s-default .cm-def{color:#00f}.jupyter-wrapper .cm-s-default .cm-variable-2{color:#05a}.jupyter-wrapper .cm-s-default .cm-variable-3,.jupyter-wrapper .cm-s-default .cm-type{color:#085}.jupyter-wrapper .cm-s-default .cm-comment{color:#a50}.jupyter-wrapper .cm-s-default .cm-string{color:#a11}.jupyter-wrapper .cm-s-default .cm-string-2{color:#f50}.jupyter-wrapper .cm-s-default .cm-meta,.jupyter-wrapper .cm-s-default .cm-qualifier{color:#555}.jupyter-wrapper .cm-s-default .cm-builtin{color:#30a}.jupyter-wrapper .cm-s-default .cm-bracket{color:#997}.jupyter-wrapper .cm-s-default .cm-tag{color:#170}.jupyter-wrapper .cm-s-default .cm-attribute{color:#00c}.jupyter-wrapper .cm-s-default .cm-hr{color:#999}.jupyter-wrapper .cm-s-default .cm-link{color:#00c}.jupyter-wrapper .cm-s-default .cm-error,.jupyter-wrapper .cm-invalidchar{color:red}.jupyter-wrapper .CodeMirror-composing{border-bottom:2px solid}.jupyter-wrapper div.CodeMirror span.CodeMirror-matchingbracket{color:#0b0}.jupyter-wrapper div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#a22}.jupyter-wrapper .CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.jupyter-wrapper .CodeMirror-activeline-background{background:#e8f2ff}.jupyter-wrapper .CodeMirror{position:relative;overflow:hidden;background:white}.jupyter-wrapper .CodeMirror-scroll{overflow:scroll!important;margin-bottom:-50px;margin-right:-50px;padding-bottom:50px;height:100%;outline:none;position:relative}.jupyter-wrapper .CodeMirror-sizer{position:relative;border-right:50px solid transparent}.jupyter-wrapper .CodeMirror-vscrollbar,.jupyter-wrapper .CodeMirror-hscrollbar,.jupyter-wrapper .CodeMirror-scrollbar-filler,.jupyter-wrapper .CodeMirror-gutter-filler{position:absolute;z-index:6;display:none;outline:none}.jupyter-wrapper .CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.jupyter-wrapper .CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.jupyter-wrapper .CodeMirror-scrollbar-filler{right:0;bottom:0}.jupyter-wrapper .CodeMirror-gutter-filler{left:0;bottom:0}.jupyter-wrapper .CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.jupyter-wrapper .CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-50px}.jupyter-wrapper .CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:none!important;border:none!important}.jupyter-wrapper .CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.jupyter-wrapper .CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.jupyter-wrapper .CodeMirror-gutter-wrapper ::selection{background-color:transparent}.jupyter-wrapper .CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.jupyter-wrapper .CodeMirror-lines{cursor:text;min-height:1px}.jupyter-wrapper .CodeMirror pre.CodeMirror-line,.jupyter-wrapper .CodeMirror pre.CodeMirror-line-like{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:transparent;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.jupyter-wrapper .CodeMirror-wrap pre.CodeMirror-line,.jupyter-wrapper .CodeMirror-wrap pre.CodeMirror-line-like{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.jupyter-wrapper .CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.jupyter-wrapper .CodeMirror-linewidget{position:relative;z-index:2;padding:.1px}.jupyter-wrapper .CodeMirror-rtl pre{direction:rtl}.jupyter-wrapper .CodeMirror-code{outline:none}.jupyter-wrapper .CodeMirror-scroll,.jupyter-wrapper .CodeMirror-sizer,.jupyter-wrapper .CodeMirror-gutter,.jupyter-wrapper .CodeMirror-gutters,.jupyter-wrapper .CodeMirror-linenumber{-moz-box-sizing:content-box;box-sizing:content-box}.jupyter-wrapper .CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.jupyter-wrapper .CodeMirror-cursor{position:absolute;pointer-events:none}.jupyter-wrapper .CodeMirror-measure pre{position:static}.jupyter-wrapper div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}.jupyter-wrapper div.CodeMirror-dragcursors,.jupyter-wrapper .CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.jupyter-wrapper .CodeMirror-selected{background:#d9d9d9}.jupyter-wrapper .CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.jupyter-wrapper .CodeMirror-crosshair{cursor:crosshair}.jupyter-wrapper .CodeMirror-line::selection,.jupyter-wrapper .CodeMirror-line>span::selection,.jupyter-wrapper .CodeMirror-line>span>span::selection{background:#d7d4f0}.jupyter-wrapper .CodeMirror-line::-moz-selection,.jupyter-wrapper .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.jupyter-wrapper .cm-searching{background-color:#ffa;background-color:#ff06}.jupyter-wrapper .cm-force-border{padding-right:.1px}@media print{.jupyter-wrapper .CodeMirror div.CodeMirror-cursors{visibility:hidden}}.jupyter-wrapper .cm-tab-wrap-hack:after{content:""}.jupyter-wrapper span.CodeMirror-selectedtext{background:none}.jupyter-wrapper .CodeMirror-dialog{position:absolute;left:0;right:0;background:inherit;z-index:15;padding:.1em .8em;overflow:hidden;color:inherit}.jupyter-wrapper .CodeMirror-dialog-top{border-bottom:1px solid #eee;top:0}.jupyter-wrapper .CodeMirror-dialog-bottom{border-top:1px solid #eee;bottom:0}.jupyter-wrapper .CodeMirror-dialog input{border:none;outline:none;background:transparent;width:20em;color:inherit;font-family:monospace}.jupyter-wrapper .CodeMirror-dialog button{font-size:70%}.jupyter-wrapper .CodeMirror-foldmarker{color:#00f;text-shadow:#b9f 1px 1px 2px,#b9f -1px -1px 2px,#b9f 1px -1px 2px,#b9f -1px 1px 2px;font-family:arial;line-height:.3;cursor:pointer}.jupyter-wrapper .CodeMirror-foldgutter{width:.7em}.jupyter-wrapper .CodeMirror-foldgutter-open,.jupyter-wrapper .CodeMirror-foldgutter-folded{cursor:pointer}.jupyter-wrapper .CodeMirror-foldgutter-open:after{content:"▾"}.jupyter-wrapper .CodeMirror-foldgutter-folded:after{content:"▸"}.jupyter-wrapper .CodeMirror{line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);font-family:var(--jp-code-font-family);border:0;border-radius:0;height:auto}.jupyter-wrapper .CodeMirror pre{padding:0 var(--jp-code-padding)}.jupyter-wrapper .CodeMirror.cm-fat-cursor .cm-overlay.cm-searching{opacity:.5}.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-dialog{background-color:var(--jp-layout-color0);color:var(--jp-content-font-color1)}.jupyter-wrapper .CodeMirror-lines{padding:var(--jp-code-padding) 0}.jupyter-wrapper .CodeMirror-linenumber{padding:0 8px}.jupyter-wrapper .jp-CodeMirrorEditor{cursor:text}.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color)}@media screen and (min-width: 2138px) and (max-width: 4319px){.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width1) solid var(--jp-editor-cursor-color)}}@media screen and (min-width: 4320px){.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width2) solid var(--jp-editor-cursor-color)}}.jupyter-wrapper .CodeMirror.jp-mod-readOnly .CodeMirror-cursor{display:none}.jupyter-wrapper .CodeMirror-gutters{border-right:1px solid var(--jp-border-color2);background-color:var(--jp-layout-color0)}.jupyter-wrapper .jp-CollaboratorCursor{border-left:5px solid transparent;border-right:5px solid transparent;border-top:none;border-bottom:3px solid;background-clip:content-box;margin-left:-5px;margin-right:-5px}.jupyter-wrapper .CodeMirror-selectedtext.cm-searching{background-color:var(--jp-search-selected-match-background-color)!important;color:var(--jp-search-selected-match-color)!important}.jupyter-wrapper .cm-searching{background-color:var(--jp-search-unselected-match-background-color)!important;color:var(--jp-search-unselected-match-color)!important}.jupyter-wrapper .cm-trailingspace{background-image:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);background-position:center left;background-repeat:repeat-x}.jupyter-wrapper .CodeMirror-focused .CodeMirror-selected{background-color:var(--jp-editor-selected-focused-background)}.jupyter-wrapper .CodeMirror-selected{background-color:var(--jp-editor-selected-background)}.jupyter-wrapper .jp-CollaboratorCursor-hover{position:absolute;z-index:1;transform:translate(-50%);color:#fff;border-radius:3px;padding:1px 4px;text-align:center;font-size:var(--jp-ui-font-size1);white-space:nowrap}.jupyter-wrapper .jp-CodeMirror-ruler{border-left:1px dashed var(--jp-border-color2)}.jupyter-wrapper .CodeMirror.cm-s-jupyter{background:var(--jp-layout-color0);color:var(--jp-content-font-color1)}.jupyter-wrapper .jp-CodeConsole .CodeMirror.cm-s-jupyter,.jupyter-wrapper .jp-Notebook .CodeMirror.cm-s-jupyter{background:transparent}.jupyter-wrapper .cm-s-jupyter .CodeMirror-cursor{border-left:var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color)}.jupyter-wrapper .cm-s-jupyter span.cm-keyword{color:var(--jp-mirror-editor-keyword-color);font-weight:700}.jupyter-wrapper .cm-s-jupyter span.cm-atom{color:var(--jp-mirror-editor-atom-color)}.jupyter-wrapper .cm-s-jupyter span.cm-number{color:var(--jp-mirror-editor-number-color)}.jupyter-wrapper .cm-s-jupyter span.cm-def{color:var(--jp-mirror-editor-def-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable{color:var(--jp-mirror-editor-variable-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable-2{color:var(--jp-mirror-editor-variable-2-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable-3{color:var(--jp-mirror-editor-variable-3-color)}.jupyter-wrapper .cm-s-jupyter span.cm-punctuation{color:var(--jp-mirror-editor-punctuation-color)}.jupyter-wrapper .cm-s-jupyter span.cm-property{color:var(--jp-mirror-editor-property-color)}.jupyter-wrapper .cm-s-jupyter span.cm-operator{color:var(--jp-mirror-editor-operator-color);font-weight:700}.jupyter-wrapper .cm-s-jupyter span.cm-comment{color:var(--jp-mirror-editor-comment-color);font-style:italic}.jupyter-wrapper .cm-s-jupyter span.cm-string{color:var(--jp-mirror-editor-string-color)}.jupyter-wrapper .cm-s-jupyter span.cm-string-2{color:var(--jp-mirror-editor-string-2-color)}.jupyter-wrapper .cm-s-jupyter span.cm-meta{color:var(--jp-mirror-editor-meta-color)}.jupyter-wrapper .cm-s-jupyter span.cm-qualifier{color:var(--jp-mirror-editor-qualifier-color)}.jupyter-wrapper .cm-s-jupyter span.cm-builtin{color:var(--jp-mirror-editor-builtin-color)}.jupyter-wrapper .cm-s-jupyter span.cm-bracket{color:var(--jp-mirror-editor-bracket-color)}.jupyter-wrapper .cm-s-jupyter span.cm-tag{color:var(--jp-mirror-editor-tag-color)}.jupyter-wrapper .cm-s-jupyter span.cm-attribute{color:var(--jp-mirror-editor-attribute-color)}.jupyter-wrapper .cm-s-jupyter span.cm-header{color:var(--jp-mirror-editor-header-color)}.jupyter-wrapper .cm-s-jupyter span.cm-quote{color:var(--jp-mirror-editor-quote-color)}.jupyter-wrapper .cm-s-jupyter span.cm-link{color:var(--jp-mirror-editor-link-color)}.jupyter-wrapper .cm-s-jupyter span.cm-error{color:var(--jp-mirror-editor-error-color)}.jupyter-wrapper .cm-s-jupyter span.cm-hr{color:#999}.jupyter-wrapper .cm-s-jupyter span.cm-tab{background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);background-position:right;background-repeat:no-repeat}.jupyter-wrapper .cm-s-jupyter .CodeMirror-activeline-background,.jupyter-wrapper .cm-s-jupyter .CodeMirror-gutter{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-CodeMirrorEditor .remote-caret{position:relative;border-left:2px solid black;margin-left:-1px;margin-right:-1px;box-sizing:border-box}.jupyter-wrapper .jp-CodeMirrorEditor .remote-caret>div{white-space:nowrap;position:absolute;top:-1.15em;padding-bottom:.05em;left:-2px;font-size:.95em;background-color:#fa8100;font-family:var(--jp-ui-font-family);font-weight:700;line-height:normal;-webkit-user-select:none;user-select:none;color:#fff;padding-left:2px;padding-right:2px;z-index:3;transition:opacity .3s ease-in-out}.jupyter-wrapper .jp-CodeMirrorEditor .remote-caret.hide-name>div{transition-delay:.7s;opacity:0}.jupyter-wrapper .jp-CodeMirrorEditor .remote-caret:hover>div[style]{opacity:1;transition-delay:0s}.jupyter-wrapper :root{--jp-private-code-span-padding: calc( (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2 )}.jupyter-wrapper .jp-RenderedText{text-align:left;padding-left:var(--jp-code-padding);line-height:var(--jp-code-line-height);font-family:var(--jp-code-font-family)}.jupyter-wrapper .jp-RenderedText pre,.jupyter-wrapper .jp-RenderedJavaScript pre,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore pre{color:var(--jp-content-font-color1);font-size:var(--jp-code-font-size);border:none;margin:0;padding:0}.jupyter-wrapper .jp-RenderedText pre a:link{text-decoration:none;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedText pre a:hover{text-decoration:underline;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedText pre a:visited{text-decoration:none;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedText pre .ansi-black-fg{color:#3e424d}.jupyter-wrapper .jp-RenderedText pre .ansi-red-fg{color:#e75c58}.jupyter-wrapper .jp-RenderedText pre .ansi-green-fg{color:#00a250}.jupyter-wrapper .jp-RenderedText pre .ansi-yellow-fg{color:#ddb62b}.jupyter-wrapper .jp-RenderedText pre .ansi-blue-fg{color:#208ffb}.jupyter-wrapper .jp-RenderedText pre .ansi-magenta-fg{color:#d160c4}.jupyter-wrapper .jp-RenderedText pre .ansi-cyan-fg{color:#60c6c8}.jupyter-wrapper .jp-RenderedText pre .ansi-white-fg{color:#c5c1b4}.jupyter-wrapper .jp-RenderedText pre .ansi-black-bg{background-color:#3e424d;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-red-bg{background-color:#e75c58;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-green-bg{background-color:#00a250;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-yellow-bg{background-color:#ddb62b;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-blue-bg{background-color:#208ffb;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-magenta-bg{background-color:#d160c4;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-cyan-bg{background-color:#60c6c8;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-white-bg{background-color:#c5c1b4;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-black-intense-fg{color:#282c36}.jupyter-wrapper .jp-RenderedText pre .ansi-red-intense-fg{color:#b22b31}.jupyter-wrapper .jp-RenderedText pre .ansi-green-intense-fg{color:#007427}.jupyter-wrapper .jp-RenderedText pre .ansi-yellow-intense-fg{color:#b27d12}.jupyter-wrapper .jp-RenderedText pre .ansi-blue-intense-fg{color:#0065ca}.jupyter-wrapper .jp-RenderedText pre .ansi-magenta-intense-fg{color:#a03196}.jupyter-wrapper .jp-RenderedText pre .ansi-cyan-intense-fg{color:#258f8f}.jupyter-wrapper .jp-RenderedText pre .ansi-white-intense-fg{color:#a1a6b2}.jupyter-wrapper .jp-RenderedText pre .ansi-black-intense-bg{background-color:#282c36;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-red-intense-bg{background-color:#b22b31;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-green-intense-bg{background-color:#007427;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-yellow-intense-bg{background-color:#b27d12;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-blue-intense-bg{background-color:#0065ca;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-magenta-intense-bg{background-color:#a03196;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-cyan-intense-bg{background-color:#258f8f;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-white-intense-bg{background-color:#a1a6b2;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-default-inverse-fg{color:var(--jp-ui-inverse-font-color0)}.jupyter-wrapper .jp-RenderedText pre .ansi-default-inverse-bg{background-color:var(--jp-inverse-layout-color0);padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-bold{font-weight:700}.jupyter-wrapper .jp-RenderedText pre .ansi-underline{text-decoration:underline}.jupyter-wrapper .jp-RenderedText[data-mime-type="application/vnd.jupyter.stderr"]{background:var(--jp-rendermime-error-background);padding-top:var(--jp-code-padding)}.jupyter-wrapper .jp-RenderedLatex{color:var(--jp-content-font-color1);font-size:var(--jp-content-font-size1);line-height:var(--jp-content-line-height)}.jupyter-wrapper .jp-OutputArea-output.jp-RenderedLatex{padding:var(--jp-code-padding);text-align:left}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore{color:var(--jp-content-font-color1);font-family:var(--jp-content-font-family);font-size:var(--jp-content-font-size1);line-height:var(--jp-content-line-height);padding-right:20px}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore em{font-style:italic}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore strong{font-weight:700}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore u{text-decoration:underline}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore a:link{text-decoration:none;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore a:hover{text-decoration:underline;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore a:visited{text-decoration:none;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h1,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h2,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h3,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h4,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h5,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h6{line-height:var(--jp-content-heading-line-height);font-weight:var(--jp-content-heading-font-weight);font-style:normal;margin:var(--jp-content-heading-margin-top) 0 var(--jp-content-heading-margin-bottom) 0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h1:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h2:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h3:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h4:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h5:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h6:first-child{margin-top:calc(.5 * var(--jp-content-heading-margin-top))}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h1:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h2:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h3:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h4:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h5:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h6:last-child{margin-bottom:calc(.5 * var(--jp-content-heading-margin-bottom))}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h1{font-size:var(--jp-content-font-size5)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h2{font-size:var(--jp-content-font-size4)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h3{font-size:var(--jp-content-font-size3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h4{font-size:var(--jp-content-font-size2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h5{font-size:var(--jp-content-font-size1)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h6{font-size:var(--jp-content-font-size0)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul:not(.list-inline),.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol:not(.list-inline){padding-left:2em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul{list-style:disc}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul ul{list-style:square}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul ul ul{list-style:circle}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol{list-style:decimal}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol{list-style:upper-alpha}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol ol{list-style:lower-alpha}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol ol ol{list-style:lower-roman}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol ol ol ol{list-style:decimal}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul{margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul ul,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul ol,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ul,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore hr{color:var(--jp-border-color2);background-color:var(--jp-border-color1);margin-top:1em;margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore>pre{margin:1.5em 2em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore pre,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore code{border:0;background-color:var(--jp-layout-color0);color:var(--jp-content-font-color1);font-family:var(--jp-code-font-family);font-size:inherit;line-height:var(--jp-code-line-height);padding:0;white-space:pre-wrap}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore :not(pre)>code{background-color:var(--jp-layout-color2);padding:1px 5px}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore table{border-collapse:collapse;border-spacing:0;border:none;color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);table-layout:fixed;margin-left:auto;margin-right:auto}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore thead{border-bottom:var(--jp-border-width) solid var(--jp-border-color1);vertical-align:bottom}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore td,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore th,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore tr{vertical-align:middle;padding:.5em;line-height:normal;white-space:normal;max-width:none;border:none}.jupyter-wrapper .jp-RenderedMarkdown.jp-RenderedHTMLCommon-ignore td,.jupyter-wrapper .jp-RenderedMarkdown.jp-RenderedHTMLCommon-ignore th{max-width:none}.jupyter-wrapper :not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon-ignore td,.jupyter-wrapper :not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon-ignore th,.jupyter-wrapper :not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon-ignore tr{text-align:right}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore th{font-weight:700}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore tbody tr:nth-child(odd){background:var(--jp-layout-color0)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore tbody tr:nth-child(2n){background:var(--jp-rendermime-table-row-background)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore tbody tr:hover{background:var(--jp-rendermime-table-row-hover-background)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore table{margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore p{text-align:left;margin:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore p{margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore img{-moz-force-broken-image-icon:1}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore>img{display:block;margin-left:0;margin-right:0;margin-bottom:1em}.jupyter-wrapper [data-jp-theme-light=false] .jp-RenderedImage img.jp-needs-light-background,.jupyter-wrapper [data-jp-theme-light=true] .jp-RenderedImage img.jp-needs-dark-background{background-color:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore img,.jupyter-wrapper .jp-RenderedImage img,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore svg,.jupyter-wrapper .jp-RenderedSVG svg{max-width:100%;height:auto}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore img.jp-mod-unconfined,.jupyter-wrapper .jp-RenderedImage img.jp-mod-unconfined,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore svg.jp-mod-unconfined,.jupyter-wrapper .jp-RenderedSVG svg.jp-mod-unconfined{max-width:none}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert{padding:var(--jp-notebook-padding);border:var(--jp-border-width) solid transparent;border-radius:var(--jp-border-radius);margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-info{color:var(--jp-info-color0);background-color:var(--jp-info-color3);border-color:var(--jp-info-color2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-info hr{border-color:var(--jp-info-color3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-info>p:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-info>ul:last-child{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-warning{color:var(--jp-warn-color0);background-color:var(--jp-warn-color3);border-color:var(--jp-warn-color2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-warning hr{border-color:var(--jp-warn-color3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-warning>p:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-warning>ul:last-child{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-success{color:var(--jp-success-color0);background-color:var(--jp-success-color3);border-color:var(--jp-success-color2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-success hr{border-color:var(--jp-success-color3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-success>p:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-success>ul:last-child{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-danger{color:var(--jp-error-color0);background-color:var(--jp-error-color3);border-color:var(--jp-error-color2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-danger hr{border-color:var(--jp-error-color3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-danger>p:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-danger>ul:last-child{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore blockquote{margin:1em 2em;padding:0 1em;border-left:5px solid var(--jp-border-color2)}.jupyter-wrapper a.jp-InternalAnchorLink{visibility:hidden;margin-left:8px;color:var(--md-blue-800)}.jupyter-wrapper h1:hover .jp-InternalAnchorLink,.jupyter-wrapper h2:hover .jp-InternalAnchorLink,.jupyter-wrapper h3:hover .jp-InternalAnchorLink,.jupyter-wrapper h4:hover .jp-InternalAnchorLink,.jupyter-wrapper h5:hover .jp-InternalAnchorLink,.jupyter-wrapper h6:hover .jp-InternalAnchorLink{visibility:visible}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore kbd{background-color:var(--jp-rendermime-table-row-background);border:1px solid var(--jp-border-color0);border-bottom-color:var(--jp-border-color2);border-radius:3px;box-shadow:inset 0 -1px #00000040;display:inline-block;font-size:var(--jp-ui-font-size0);line-height:1em;padding:.2em .5em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore>*:last-child{margin-bottom:.5em}.jupyter-wrapper .jp-MimeDocument{outline:none}.jupyter-wrapper :root{--jp-private-filebrowser-button-height: 28px;--jp-private-filebrowser-button-width: 48px}.jupyter-wrapper .jp-FileBrowser{display:flex;flex-direction:column;color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .jp-FileBrowser-toolbar.jp-Toolbar{border-bottom:none;height:auto;margin:8px 12px 0;padding:0;box-shadow:none;justify-content:flex-start}.jupyter-wrapper .jp-BreadCrumbs{flex:0 0 auto;margin:8px 12px}.jupyter-wrapper .jp-BreadCrumbs-item{margin:0 2px;padding:0 2px;border-radius:var(--jp-border-radius);cursor:pointer}.jupyter-wrapper .jp-BreadCrumbs-item:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-BreadCrumbs-item:first-child{margin-left:0}.jupyter-wrapper .jp-BreadCrumbs-item.jp-mod-dropTarget{background-color:var(--jp-brand-color2);opacity:.7}.jupyter-wrapper .jp-FileBrowser-toolbar>.jp-Toolbar-item{flex:0 0 auto;padding-left:0;padding-right:2px}.jupyter-wrapper .jp-FileBrowser-toolbar>.jp-Toolbar-item .jp-ToolbarButtonComponent{width:40px}.jupyter-wrapper .jp-FileBrowser-toolbar .jp-ToolbarButtonComponent[data-command="filebrowser:create-main-launcher"]{width:72px;background:var(--jp-brand-color1)}.jupyter-wrapper .jp-FileBrowser-toolbar .jp-ToolbarButtonComponent[data-command="filebrowser:create-main-launcher"]:hover,.jupyter-wrapper .jp-FileBrowser-toolbar .jp-ToolbarButtonComponent[data-command="filebrowser:create-main-launcher"]:focus-visible{background-color:var(--jp-brand-color0)!important}.jupyter-wrapper .jp-FileBrowser-toolbar .jp-ToolbarButtonComponent[data-command="filebrowser:create-main-launcher"] .jp-icon3{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-FileDialog.jp-mod-conflict input{color:var(--jp-error-color1)}.jupyter-wrapper .jp-FileDialog .jp-new-name-title{margin-top:12px}.jupyter-wrapper .jp-LastModified-hidden{display:none}.jupyter-wrapper .jp-FileBrowser-filterBox{padding:0;flex:0 0 auto;margin:8px 12px 0}.jupyter-wrapper .jp-DirListing{flex:1 1 auto;display:flex;flex-direction:column;outline:0}.jupyter-wrapper .jp-DirListing:focus-visible{outline:1px solid var(--jp-brand-color1);outline-offset:-2px}.jupyter-wrapper .jp-DirListing-header{flex:0 0 auto;display:flex;flex-direction:row;overflow:hidden;border-top:var(--jp-border-width) solid var(--jp-border-color2);border-bottom:var(--jp-border-width) solid var(--jp-border-color1);box-shadow:var(--jp-toolbar-box-shadow);z-index:2}.jupyter-wrapper .jp-DirListing-headerItem{padding:4px 12px 2px;font-weight:500}.jupyter-wrapper .jp-DirListing-headerItem:hover{background:var(--jp-layout-color2)}.jupyter-wrapper .jp-DirListing-headerItem.jp-id-name{flex:1 0 84px}.jupyter-wrapper .jp-DirListing-headerItem.jp-id-modified{flex:0 0 112px;border-left:var(--jp-border-width) solid var(--jp-border-color2);text-align:right}.jupyter-wrapper .jp-id-narrow{display:none;flex:0 0 5px;padding:4px;border-left:var(--jp-border-width) solid var(--jp-border-color2);text-align:right;color:var(--jp-border-color2)}.jupyter-wrapper .jp-DirListing-narrow .jp-id-narrow{display:block}.jupyter-wrapper .jp-DirListing-narrow .jp-id-modified,.jupyter-wrapper .jp-DirListing-narrow .jp-DirListing-itemModified{display:none}.jupyter-wrapper .jp-DirListing-headerItem.jp-mod-selected{font-weight:600}.jupyter-wrapper .jp-DirListing-content{flex:1 1 auto;margin:0;padding:0;list-style-type:none;overflow:auto;background-color:var(--jp-layout-color1)}.jupyter-wrapper .jp-DirListing-content mark{color:var(--jp-ui-font-color0);background-color:transparent;font-weight:700}.jupyter-wrapper .jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark{color:var(--jp-ui-inverse-font-color0)}.jupyter-wrapper .jp-DirListing.jp-mod-native-drop .jp-DirListing-content{outline:5px dashed rgba(128,128,128,.5);outline-offset:-10px;cursor:copy}.jupyter-wrapper .jp-DirListing-item{display:flex;flex-direction:row;padding:4px 12px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .jp-DirListing-item[data-is-dot]{opacity:75%}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected{color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.jupyter-wrapper .jp-DirListing-item.jp-mod-dropTarget{background:var(--jp-brand-color3)}.jupyter-wrapper .jp-DirListing-item:hover:not(.jp-mod-selected){background:var(--jp-layout-color2)}.jupyter-wrapper .jp-DirListing-itemIcon{flex:0 0 20px;margin-right:4px}.jupyter-wrapper .jp-DirListing-itemText{flex:1 0 64px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;user-select:none}.jupyter-wrapper .jp-DirListing-itemModified{flex:0 0 125px;text-align:right}.jupyter-wrapper .jp-DirListing-editor{flex:1 0 64px;outline:none;border:none;color:var(--jp-ui-font-color1);background-color:var(--jp-layout-color1)}.jupyter-wrapper .jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before{color:var(--jp-success-color1);content:"●";font-size:8px;position:absolute;left:-8px}.jupyter-wrapper .jp-DirListing-item.jp-mod-running.jp-mod-selected .jp-DirListing-itemIcon:before{color:var(--jp-ui-inverse-font-color1)}.jupyter-wrapper .jp-DirListing-item.lm-mod-drag-image,.jupyter-wrapper .jp-DirListing-item.jp-mod-selected.lm-mod-drag-image{font-size:var(--jp-ui-font-size1);padding-left:4px;margin-left:4px;width:160px;background-color:var(--jp-ui-inverse-font-color2);box-shadow:var(--jp-elevation-z2);border-radius:0;color:var(--jp-ui-font-color1);transform:translate(-40%) translateY(-58%)}.jupyter-wrapper .jp-Document{min-width:120px;min-height:120px;outline:none}.jupyter-wrapper .jp-OutputArea{overflow-y:auto}.jupyter-wrapper .jp-OutputArea-child{display:flex;flex-direction:row}.jupyter-wrapper body[data-format=mobile] .jp-OutputArea-child{flex-direction:column}.jupyter-wrapper .jp-OutputPrompt{flex:0 0 var(--jp-cell-prompt-width);color:var(--jp-cell-outprompt-font-color);font-family:var(--jp-cell-prompt-font-family);padding:var(--jp-code-padding);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent;opacity:var(--jp-cell-prompt-opacity);text-align:right;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper body[data-format=mobile] .jp-OutputPrompt{flex:0 0 auto;text-align:left}.jupyter-wrapper .jp-OutputArea-output{height:auto;overflow:auto;user-select:text;-moz-user-select:text;-webkit-user-select:text;-ms-user-select:text}.jupyter-wrapper .jp-OutputArea-child .jp-OutputArea-output{flex-grow:1;flex-shrink:1}.jupyter-wrapper body[data-format=mobile] .jp-OutputArea-child .jp-OutputArea-output{margin-left:var(--jp-notebook-padding)}.jupyter-wrapper .jp-OutputArea-output.jp-mod-isolated{width:100%;display:block}.jupyter-wrapper body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated{position:relative}.jupyter-wrapper body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before{content:"";position:absolute;top:0;left:0;right:0;bottom:0;background:transparent}.jupyter-wrapper .jp-OutputArea-output pre{border:none;margin:0;padding:0;overflow-x:auto;overflow-y:auto;word-break:break-all;word-wrap:break-word;white-space:pre-wrap}.jupyter-wrapper .jp-OutputArea-output.jp-RenderedHTMLCommon-ignore table{margin-left:0;margin-right:0}.jupyter-wrapper .jp-OutputArea-output dl,.jupyter-wrapper .jp-OutputArea-output dt,.jupyter-wrapper .jp-OutputArea-output dd{display:block}.jupyter-wrapper .jp-OutputArea-output dl{width:100%;overflow:hidden;padding:0;margin:0}.jupyter-wrapper .jp-OutputArea-output dt{font-weight:700;float:left;width:20%;padding:0;margin:0}.jupyter-wrapper .jp-OutputArea-output dd{float:left;width:80%;padding:0;margin:0}.jupyter-wrapper .jp-TrimmedOutputs a{margin:10px;text-decoration:none;cursor:pointer}.jupyter-wrapper .jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt{display:none}.jupyter-wrapper .jp-OutputArea-prompt:empty{padding:0;border:0}.jupyter-wrapper .jp-OutputArea-output.jp-OutputArea-executeResult{margin-left:0;flex:1 1 auto}.jupyter-wrapper .jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output{padding-top:var(--jp-code-padding);border-top:var(--jp-border-width) solid transparent}.jupyter-wrapper .jp-Stdin-prompt{color:var(--jp-content-font-color0);padding-right:var(--jp-code-padding);vertical-align:baseline;flex:0 0 auto}.jupyter-wrapper .jp-Stdin-input{font-family:var(--jp-code-font-family);font-size:inherit;color:inherit;background-color:inherit;width:42%;min-width:200px;vertical-align:baseline;padding:0 .25em;margin:0 .25em;flex:0 0 70%}.jupyter-wrapper .jp-Stdin-input::placeholder{opacity:0}.jupyter-wrapper .jp-Stdin-input:focus{box-shadow:none}.jupyter-wrapper .jp-Stdin-input:focus::placeholder{opacity:1}.jupyter-wrapper .jp-LinkedOutputView .jp-OutputArea{height:100%;display:block}.jupyter-wrapper .jp-LinkedOutputView .jp-OutputArea-output:only-child{height:100%}.jupyter-wrapper .jp-Collapser{flex:0 0 var(--jp-cell-collapser-width);padding:0;margin:0;border:none;outline:none;background:transparent;border-radius:var(--jp-border-radius);opacity:1}.jupyter-wrapper .jp-Collapser-child{display:block;width:100%;box-sizing:border-box;position:absolute;top:0;bottom:0}.jupyter-wrapper .jp-CellHeader,.jupyter-wrapper .jp-CellFooter{height:0px;width:100%;padding:0;margin:0;border:none;outline:none;background:transparent}.jupyter-wrapper .jp-InputArea{display:flex;flex-direction:row;overflow:hidden}.jupyter-wrapper body[data-format=mobile] .jp-InputArea{flex-direction:column}.jupyter-wrapper .jp-InputArea-editor{flex:1 1 auto;overflow:hidden}.jupyter-wrapper .jp-InputArea-editor{border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);border-radius:0;background:var(--jp-cell-editor-background)}.jupyter-wrapper body[data-format=mobile] .jp-InputArea-editor{margin-left:var(--jp-notebook-padding)}.jupyter-wrapper .jp-InputPrompt{flex:0 0 var(--jp-cell-prompt-width);color:var(--jp-cell-inprompt-font-color);font-family:var(--jp-cell-prompt-font-family);padding:var(--jp-code-padding);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent;opacity:var(--jp-cell-prompt-opacity);text-align:right;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper body[data-format=mobile] .jp-InputPrompt{flex:0 0 auto;text-align:left}.jupyter-wrapper .jp-Placeholder{display:flex;flex-direction:row;flex:1 1 auto}.jupyter-wrapper .jp-Placeholder-prompt{box-sizing:border-box}.jupyter-wrapper .jp-Placeholder-content{flex:1 1 auto;border:none;background:transparent;height:20px;box-sizing:border-box}.jupyter-wrapper .jp-Placeholder-content .jp-MoreHorizIcon{width:32px;height:16px;border:1px solid transparent;border-radius:var(--jp-border-radius)}.jupyter-wrapper .jp-Placeholder-content .jp-MoreHorizIcon:hover{border:1px solid var(--jp-border-color1);box-shadow:0 0 2px #00000040;background-color:var(--jp-layout-color0)}.jupyter-wrapper :root{--jp-private-cell-scrolling-output-offset: 5px}.jupyter-wrapper .jp-Cell{padding:var(--jp-cell-padding);margin:0;border:none;outline:none;background:transparent}.jupyter-wrapper .jp-Cell-inputWrapper,.jupyter-wrapper .jp-Cell-outputWrapper{display:flex;flex-direction:row;padding:0;margin:0;overflow:visible}.jupyter-wrapper .jp-Cell-inputArea,.jupyter-wrapper .jp-Cell-outputArea{flex:1 1 auto}.jupyter-wrapper .jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser{border:none!important;background:transparent!important}.jupyter-wrapper .jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser{min-height:var(--jp-cell-collapser-min-height)}.jupyter-wrapper .jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper{margin-top:5px}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea{overflow-y:auto;max-height:24em;margin-left:var(--jp-private-cell-scrolling-output-offset)}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea:after{content:" ";box-shadow:inset 0 0 6px 2px #0000004d;width:100%;height:100%;position:sticky;bottom:0;top:0;margin-top:-50%;float:left;display:block;pointer-events:none}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child{padding-top:6px}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt{flex:0 0 calc(var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset))}.jupyter-wrapper .jp-MarkdownOutput{flex:1 1 auto;margin-top:0;margin-bottom:0;padding-left:var(--jp-code-padding)}.jupyter-wrapper .jp-MarkdownOutput.jp-RenderedHTMLCommon-ignore{overflow:auto}.jupyter-wrapper .jp-collapseHeadingButton{display:none;min-height:var(--jp-cell-collapser-min-height);font-size:var(--jp-code-font-size);position:absolute;right:0;top:0;bottom:0;background-color:transparent;background-size:25px;background-repeat:no-repeat;background-position-x:center;background-position-y:top;background-image:var(--jp-icon-caret-down);border:none;cursor:pointer}.jupyter-wrapper .jp-collapseHeadingButton:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-collapseHeadingButton.jp-mod-collapsed{background-image:var(--jp-icon-caret-right)}.jupyter-wrapper :is(.jp-MarkdownCell:hover,.jp-mod-active) .jp-collapseHeadingButton{display:flex}.jupyter-wrapper .jp-MarkdownCell .jp-InputPrompt{font-size:var(--jp-content-font-size1)}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="1"]{font-size:var(--jp-content-font-size5);background-position-y:calc(.3 * var(--jp-content-font-size5))}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="2"]{font-size:var(--jp-content-font-size4);background-position-y:calc(.3 * var(--jp-content-font-size4))}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="3"]{font-size:var(--jp-content-font-size3);background-position-y:calc(.3 * var(--jp-content-font-size3))}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="4"]{font-size:var(--jp-content-font-size2);background-position-y:calc(.3 * var(--jp-content-font-size2))}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="5"]{font-size:var(--jp-content-font-size1);background-position-y:top}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="6"]{font-size:var(--jp-content-font-size0);background-position-y:top}.jupyter-wrapper .jp-showHiddenCellsButton{margin-left:calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));margin-top:var(--jp-code-padding);border:1px solid var(--jp-border-color2);background-color:var(--jp-border-color3)!important;color:var(--jp-content-font-color0)!important}.jupyter-wrapper .jp-showHiddenCellsButton:hover{background-color:var(--jp-border-color2)!important}.jupyter-wrapper :root{--jp-notebook-toolbar-padding: 2px 5px 2px 2px}.jupyter-wrapper .jp-NotebookPanel-toolbar{padding:var(--jp-notebook-toolbar-padding)}.jupyter-wrapper .jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused{border:none;box-shadow:none}.jupyter-wrapper .jp-Notebook-toolbarCellTypeDropdown select{height:24px;font-size:var(--jp-ui-font-size1);line-height:14px;border-radius:0;display:block}.jupyter-wrapper .jp-Notebook-toolbarCellTypeDropdown span{top:5px!important}.jupyter-wrapper .jp-Toolbar-responsive-popup{position:absolute;height:fit-content;display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);box-shadow:var(--jp-toolbar-box-shadow);background:var(--jp-toolbar-background);min-height:var(--jp-toolbar-micro-height);padding:var(--jp-notebook-toolbar-padding);z-index:1;right:0;top:0}.jupyter-wrapper .jp-Toolbar>.jp-Toolbar-responsive-opener{margin-left:auto}.jupyter-wrapper .jp-Notebook-ExecutionIndicator{position:relative;display:inline-block;height:100%;z-index:9997}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-tooltip{visibility:hidden;height:auto;width:max-content;width:-moz-max-content;background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color1);text-align:justify;border-radius:6px;padding:0 5px;position:fixed;display:table}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-tooltip.up{transform:translate(-50%) translateY(-100%) translateY(-32px)}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-tooltip.down{transform:translate(calc(-100% + 16px)) translateY(5px)}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-tooltip.hidden{display:none}.jupyter-wrapper .jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip{visibility:visible}.jupyter-wrapper .jp-Notebook-ExecutionIndicator span{font-size:var(--jp-ui-font-size1);font-family:var(--jp-ui-font-family);color:var(--jp-ui-font-color1);line-height:24px;display:block}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-progress-bar{display:flex;justify-content:center;height:100%}.jupyter-wrapper :root{--jp-private-notebook-dragImage-width: 304px;--jp-private-notebook-dragImage-height: 36px;--jp-private-notebook-selected-color: var(--md-blue-400);--jp-private-notebook-active-color: var(--md-green-400)}.jupyter-wrapper .jp-NotebookPanel{display:block;height:100%}.jupyter-wrapper .jp-NotebookPanel.jp-Document{min-width:240px;min-height:120px}.jupyter-wrapper .jp-Notebook{padding:var(--jp-notebook-padding);outline:none;overflow:auto}.jupyter-wrapper .jp-Notebook.jp-mod-scrollPastEnd:after{display:block;content:"";min-height:var(--jp-notebook-scroll-padding)}.jupyter-wrapper .jp-MainAreaWidget-ContainStrict .jp-Notebook *{contain:strict}.jupyter-wrapper .jp-Notebook .jp-Cell{overflow:visible}.jupyter-wrapper .jp-Notebook .jp-Cell .jp-InputPrompt{cursor:move;float:left}.jupyter-wrapper .jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt{opacity:var(--jp-cell-prompt-not-active-opacity);color:var(--jp-cell-prompt-not-active-font-color)}.jupyter-wrapper .jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt{opacity:var(--jp-cell-prompt-not-active-opacity);color:var(--jp-cell-prompt-not-active-font-color)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser{background:var(--jp-brand-color1)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt{color:var(--jp-warn-color1)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt:before{color:var(--jp-warn-color1);content:"•"}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser{background:var(--jp-warn-color1)}.jupyter-wrapper .jp-Notebook .jp-Cell .jp-Collapser:hover{box-shadow:var(--jp-elevation-z2);background:var(--jp-brand-color1);opacity:var(--jp-cell-collapser-not-active-hover-opacity)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover{background:var(--jp-brand-color0);opacity:1}.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected{background:var(--jp-notebook-multiselected-color)}.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected){background:transparent}.jupyter-wrapper .jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor{border:var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);box-shadow:var(--jp-input-box-shadow);background-color:var(--jp-cell-editor-active-background)}.jupyter-wrapper .jp-Notebook-cell.jp-mod-dropSource{opacity:.5}.jupyter-wrapper .jp-Notebook-cell.jp-mod-dropTarget,.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget{border-top-color:var(--jp-private-notebook-selected-color);border-top-style:solid;border-top-width:2px}.jupyter-wrapper .jp-dragImage{display:block;flex-direction:row;width:var(--jp-private-notebook-dragImage-width);height:var(--jp-private-notebook-dragImage-height);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background);overflow:visible}.jupyter-wrapper .jp-dragImage-singlePrompt{box-shadow:2px 2px 4px #0000001f}.jupyter-wrapper .jp-dragImage .jp-dragImage-content{flex:1 1 auto;z-index:2;font-size:var(--jp-code-font-size);font-family:var(--jp-code-font-family);line-height:var(--jp-code-line-height);padding:var(--jp-code-padding);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background-color);color:var(--jp-content-font-color3);text-align:left;margin:4px 4px 4px 0}.jupyter-wrapper .jp-dragImage .jp-dragImage-prompt{flex:0 0 auto;min-width:36px;color:var(--jp-cell-inprompt-font-color);padding:var(--jp-code-padding);padding-left:12px;font-family:var(--jp-cell-prompt-font-family);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:1.9;font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent}.jupyter-wrapper .jp-dragImage-multipleBack{z-index:-1;position:absolute;height:32px;width:300px;top:8px;left:8px;background:var(--jp-layout-color2);border:var(--jp-border-width) solid var(--jp-input-border-color);box-shadow:2px 2px 4px #0000001f}.jupyter-wrapper .jp-NotebookTools{display:block;min-width:var(--jp-sidebar-min-width);color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1);overflow:auto}.jupyter-wrapper .jp-NotebookTools-tool{padding:0 12px}.jupyter-wrapper .jp-ActiveCellTool{padding:12px;background-color:var(--jp-layout-color1);border-top:none!important}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-prompt{flex:0 0 auto;padding-left:0}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-editor{flex:1 1 auto;background:var(--jp-cell-editor-background);border-color:var(--jp-cell-editor-border-color)}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-editor .CodeMirror{background:transparent}.jupyter-wrapper .jp-MetadataEditorTool{flex-direction:column;padding:12px 0}.jupyter-wrapper .jp-RankedPanel>:not(:first-child){margin-top:12px}.jupyter-wrapper .jp-KeySelector select.jp-mod-styled{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);border:var(--jp-border-width) solid var(--jp-border-color1)}.jupyter-wrapper .jp-KeySelector label,.jupyter-wrapper .jp-MetadataEditorTool label{line-height:1.4}.jupyter-wrapper .jp-NotebookTools .jp-select-wrapper{margin-top:4px;margin-bottom:0}.jupyter-wrapper .jp-NotebookTools .jp-Collapse{margin-top:16px}.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook{--jp-content-font-size1: var(--jp-content-presentation-font-size1);--jp-code-font-size: var(--jp-code-presentation-font-size)}.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt{flex:0 0 110px}.jupyter-wrapper :root{--jp-side-by-side-output-size: 1fr;--jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size)}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell{margin:3em 5%}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell{display:grid;grid-template-columns:minmax(0,1fr) min-content minmax(0,var(--jp-side-by-side-output-size));grid-template-rows:auto minmax(0,1fr) auto;grid-template-areas:"header header header" "input handle output" "footer footer footer"}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell{grid-template-columns:minmax(0,1fr) min-content minmax(0,var(--jp-side-by-side-resized-cell))}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader{grid-area:header}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper{grid-area:input}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper{margin-top:0;grid-area:output}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter{grid-area:footer}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle{grid-area:handle;-webkit-user-select:none;user-select:none;display:block;height:100%;cursor:ew-resize;padding:0 var(--jp-cell-padding)}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle:after{content:"";display:block;background:var(--jp-border-color2);height:100%;width:5px}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell .jp-CellResizeHandle:after{background:var(--jp-border-color0)}.jupyter-wrapper .jp-CellResizeHandle{display:none}.jupyter-wrapper .jp-Cell-Placeholder{padding-left:55px}.jupyter-wrapper .jp-Cell-Placeholder-wrapper{background:#fff;border:1px solid;border-color:#e5e6e9 #dfe0e4 #d0d1d5;border-radius:4px;-webkit-border-radius:4px;margin:10px 15px}.jupyter-wrapper .jp-Cell-Placeholder-wrapper-inner{padding:15px;position:relative}.jupyter-wrapper .jp-Cell-Placeholder-wrapper-body{background-repeat:repeat;background-size:50% auto}.jupyter-wrapper .jp-Cell-Placeholder-wrapper-body div{background:#f6f7f8;background-image:-webkit-linear-gradient(left,#f6f7f8 0%,#edeef1 20%,#f6f7f8 40%,#f6f7f8 100%);background-repeat:no-repeat;background-size:800px 104px;height:104px;position:relative}.jupyter-wrapper .jp-Cell-Placeholder-wrapper-body div{position:absolute;right:15px;left:15px;top:15px}.jupyter-wrapper div.jp-Cell-Placeholder-h1{top:20px;height:20px;left:15px;width:150px}.jupyter-wrapper div.jp-Cell-Placeholder-h2{left:15px;top:50px;height:10px;width:100px}.jupyter-wrapper div.jp-Cell-Placeholder-content-1,.jupyter-wrapper div.jp-Cell-Placeholder-content-2,.jupyter-wrapper div.jp-Cell-Placeholder-content-3{left:15px;right:15px;height:10px}.jupyter-wrapper div.jp-Cell-Placeholder-content-1{top:100px}.jupyter-wrapper div.jp-Cell-Placeholder-content-2{top:120px}.jupyter-wrapper div.jp-Cell-Placeholder-content-3{top:140px}.jupyter-wrapper table.dataframe{table-layout:auto!important}.jupyter-wrapper .md-typeset__scrollwrap{margin:0}.jupyter-wrapper .jp-MarkdownOutput{padding:0}.jupyter-wrapper h1 .anchor-link,.jupyter-wrapper h2 .anchor-link,.jupyter-wrapper h3 .anchor-link,.jupyter-wrapper h4 .anchor-link,.jupyter-wrapper h5 .anchor-link,.jupyter-wrapper h6 .anchor-link{display:none;margin-left:.5rem;color:var(--md-default-fg-color--lighter)}.jupyter-wrapper h1 .anchor-link:hover,.jupyter-wrapper h2 .anchor-link:hover,.jupyter-wrapper h3 .anchor-link:hover,.jupyter-wrapper h4 .anchor-link:hover,.jupyter-wrapper h5 .anchor-link:hover,.jupyter-wrapper h6 .anchor-link:hover{text-decoration:none;color:var(--md-accent-fg-color)}.jupyter-wrapper h1:hover .anchor-link,.jupyter-wrapper h2:hover .anchor-link,.jupyter-wrapper h3:hover .anchor-link,.jupyter-wrapper h4:hover .anchor-link,.jupyter-wrapper h5:hover .anchor-link,.jupyter-wrapper h6:hover .anchor-link{display:inline-block}.jupyter-wrapper .jp-InputArea,.jupyter-wrapper .jp-Cell-inputArea,.jupyter-wrapper .jp-RenderedHTMLCommon{width:100%}.jupyter-wrapper .jp-Cell-inputWrapper .jp-InputPrompt{display:none}.jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt{display:block}.jupyter-wrapper .jp-Cell .jp-InputPrompt{cursor:normal}.jupyter-wrapper .highlight pre{background-color:#f5f5f5;padding:10px;overflow:auto}.jupyter-wrapper .celltoolbar{border:none;background:#eee;border-radius:2px 2px 0 0;width:100%;height:29px;padding-right:4px;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch;box-pack:end;justify-content:flex-start;display:-webkit-flex}.jupyter-wrapper .celltoolbar .tags_button_container{display:flex}.jupyter-wrapper .celltoolbar .tags_button_container .tag-container{display:flex;flex-direction:row;flex-grow:1;overflow:hidden;position:relative}.jupyter-wrapper .celltoolbar .tags_button_container .tag-container .cell-tag{display:inline-flex;align-items:center;background-color:#fff;white-space:nowrap;margin:3px 4px;padding:0 4px;border-radius:1px;border:1px solid #ccc;box-shadow:none;width:inherit;font-size:11px;font-family:Roboto Mono,SFMono-Regular,Consolas,Menlo,monospace;height:17px}.jupyter-wrapper .jp-InputArea-editor{width:1px}.jupyter-wrapper .jp-InputPrompt,.jupyter-wrapper .jp-OutputPrompt{overflow:unset}.jupyter-wrapper .jp-RenderedText{font-size:var(--jp-code-font-size)}.jupyter-wrapper .highlight-ipynb{overflow:auto}.jupyter-wrapper .highlight-ipynb pre{margin:0;padding:5px 10px}.jupyter-wrapper table{width:max-content}.jupyter-wrapper table.dataframe{margin-left:auto;margin-right:auto;border:none;border-collapse:collapse;border-spacing:0;color:#000;font-size:12px;table-layout:fixed}.jupyter-wrapper table.dataframe thead{border-bottom:1px solid black;vertical-align:bottom}.jupyter-wrapper table.dataframe tr,.jupyter-wrapper table.dataframe th,.jupyter-wrapper table.dataframe td{text-align:right;vertical-align:middle;padding:.5em;line-height:normal;white-space:normal;max-width:none;border:none}.jupyter-wrapper table.dataframe th{font-weight:700}.jupyter-wrapper table.dataframe tbody tr:nth-child(odd){background:#f5f5f5}.jupyter-wrapper table.dataframe tbody tr:hover{background:rgba(66,165,245,.2)}.jupyter-wrapper *+table{margin-top:1em}.jupyter-wrapper .jp-InputArea-editor{position:relative}.jupyter-wrapper .zeroclipboard-container{position:absolute;top:-3px;right:0;z-index:1}.jupyter-wrapper .zeroclipboard-container clipboard-copy{-webkit-appearance:button;-moz-appearance:button;padding:7px 5px;font:11px system-ui,sans-serif;display:inline-block;cursor:default}.jupyter-wrapper .zeroclipboard-container clipboard-copy:hover{cursor:pointer}.jupyter-wrapper .zeroclipboard-container .clipboard-copy-icon{width:15px;padding:2px 0;color:#57606a;vertical-align:text-bottom}.jupyter-wrapper .clipboard-copy-txt{display:none}[data-md-color-scheme=slate] .highlight pre{background-color:#21222c;padding:10px;overflow:auto}[data-md-color-scheme=slate] .clipboard-copy-icon{color:#555!important}[data-md-color-scheme=slate] .celltoolbar{background:#333!important}[data-md-color-scheme=slate] .celltoolbar .tags_button_container .tag-container .cell-tag{background-color:transparent!important;border:1px solid #666!important}[data-md-color-scheme=slate] table.dataframe{color:#e9ebfc}[data-md-color-scheme=slate] table.dataframe thead{border-bottom:1px solid rgba(233,235,252,.12)}[data-md-color-scheme=slate] table.dataframe tbody tr:nth-child(odd){background:#222}[data-md-color-scheme=slate] table.dataframe tbody tr:hover{background:rgba(66,165,245,.2)}table{width:max-content}
</style>
<style type="text/css">
.jupyter-wrapper{--jp-shadow-base-lightness: 0;--jp-shadow-umbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .2 );--jp-shadow-penumbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .14 );--jp-shadow-ambient-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .12 );--jp-elevation-z0: none;--jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color), 0px 1px 1px 0px var(--jp-shadow-penumbra-color), 0px 1px 3px 0px var(--jp-shadow-ambient-color);--jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color), 0px 2px 2px 0px var(--jp-shadow-penumbra-color), 0px 1px 5px 0px var(--jp-shadow-ambient-color);--jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color), 0px 4px 5px 0px var(--jp-shadow-penumbra-color), 0px 1px 10px 0px var(--jp-shadow-ambient-color);--jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color), 0px 6px 10px 0px var(--jp-shadow-penumbra-color), 0px 1px 18px 0px var(--jp-shadow-ambient-color);--jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color), 0px 8px 10px 1px var(--jp-shadow-penumbra-color), 0px 3px 14px 2px var(--jp-shadow-ambient-color);--jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color), 0px 12px 17px 2px var(--jp-shadow-penumbra-color), 0px 5px 22px 4px var(--jp-shadow-ambient-color);--jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color), 0px 16px 24px 2px var(--jp-shadow-penumbra-color), 0px 6px 30px 5px var(--jp-shadow-ambient-color);--jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color), 0px 20px 31px 3px var(--jp-shadow-penumbra-color), 0px 8px 38px 7px var(--jp-shadow-ambient-color);--jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color), 0px 24px 38px 3px var(--jp-shadow-penumbra-color), 0px 9px 46px 8px var(--jp-shadow-ambient-color);--jp-border-width: 1px;--jp-border-color0: var(--md-grey-400);--jp-border-color1: var(--md-grey-400);--jp-border-color2: var(--md-grey-300);--jp-border-color3: var(--md-grey-200);--jp-inverse-border-color: var(--md-grey-600);--jp-border-radius: 2px;--jp-ui-font-scale-factor: 1.2;--jp-ui-font-size0: .83333em;--jp-ui-font-size1: 13px;--jp-ui-font-size2: 1.2em;--jp-ui-font-size3: 1.44em;--jp-ui-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-ui-font-color0: rgba(0, 0, 0, 1);--jp-ui-font-color1: rgba(0, 0, 0, .87);--jp-ui-font-color2: rgba(0, 0, 0, .54);--jp-ui-font-color3: rgba(0, 0, 0, .38);--jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);--jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);--jp-ui-inverse-font-color2: rgba(255, 255, 255, .7);--jp-ui-inverse-font-color3: rgba(255, 255, 255, .5);--jp-content-line-height: 1.6;--jp-content-font-scale-factor: 1.2;--jp-content-font-size0: .83333em;--jp-content-font-size1: 14px;--jp-content-font-size2: 1.2em;--jp-content-font-size3: 1.44em;--jp-content-font-size4: 1.728em;--jp-content-font-size5: 2.0736em;--jp-content-presentation-font-size1: 17px;--jp-content-heading-line-height: 1;--jp-content-heading-margin-top: 1.2em;--jp-content-heading-margin-bottom: .8em;--jp-content-heading-font-weight: 500;--jp-content-font-color0: rgba(0, 0, 0, 1);--jp-content-font-color1: rgba(0, 0, 0, .87);--jp-content-font-color2: rgba(0, 0, 0, .54);--jp-content-font-color3: rgba(0, 0, 0, .38);--jp-content-link-color: var(--md-blue-700);--jp-content-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-code-font-size: 13px;--jp-code-line-height: 1.3077;--jp-code-padding: 5px;--jp-code-font-family-default: Menlo, Consolas, "DejaVu Sans Mono", monospace;--jp-code-font-family: var(--jp-code-font-family-default);--jp-code-presentation-font-size: 16px;--jp-code-cursor-width0: 1.4px;--jp-code-cursor-width1: 2px;--jp-code-cursor-width2: 4px;--jp-layout-color0: white;--jp-layout-color1: white;--jp-layout-color2: var(--md-grey-200);--jp-layout-color3: var(--md-grey-400);--jp-layout-color4: var(--md-grey-600);--jp-inverse-layout-color0: #111111;--jp-inverse-layout-color1: var(--md-grey-900);--jp-inverse-layout-color2: var(--md-grey-800);--jp-inverse-layout-color3: var(--md-grey-700);--jp-inverse-layout-color4: var(--md-grey-600);--jp-brand-color0: var(--md-blue-900);--jp-brand-color1: var(--md-blue-700);--jp-brand-color2: var(--md-blue-300);--jp-brand-color3: var(--md-blue-100);--jp-brand-color4: var(--md-blue-50);--jp-accent-color0: var(--md-green-900);--jp-accent-color1: var(--md-green-700);--jp-accent-color2: var(--md-green-300);--jp-accent-color3: var(--md-green-100);--jp-warn-color0: var(--md-orange-900);--jp-warn-color1: var(--md-orange-700);--jp-warn-color2: var(--md-orange-300);--jp-warn-color3: var(--md-orange-100);--jp-error-color0: var(--md-red-900);--jp-error-color1: var(--md-red-700);--jp-error-color2: var(--md-red-300);--jp-error-color3: var(--md-red-100);--jp-success-color0: var(--md-green-900);--jp-success-color1: var(--md-green-700);--jp-success-color2: var(--md-green-300);--jp-success-color3: var(--md-green-100);--jp-info-color0: var(--md-cyan-900);--jp-info-color1: var(--md-cyan-700);--jp-info-color2: var(--md-cyan-300);--jp-info-color3: var(--md-cyan-100);--jp-cell-padding: 5px;--jp-cell-collapser-width: 8px;--jp-cell-collapser-min-height: 20px;--jp-cell-collapser-not-active-hover-opacity: .6;--jp-cell-editor-background: var(--md-grey-100);--jp-cell-editor-border-color: var(--md-grey-300);--jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-cell-editor-active-background: var(--jp-layout-color0);--jp-cell-editor-active-border-color: var(--jp-brand-color1);--jp-cell-prompt-width: 64px;--jp-cell-prompt-font-family: var(--jp-code-font-family-default);--jp-cell-prompt-letter-spacing: 0px;--jp-cell-prompt-opacity: 1;--jp-cell-prompt-not-active-opacity: .5;--jp-cell-prompt-not-active-font-color: var(--md-grey-700);--jp-cell-inprompt-font-color: #307fc1;--jp-cell-outprompt-font-color: #bf5b3d;--jp-notebook-padding: 10px;--jp-notebook-select-background: var(--jp-layout-color1);--jp-notebook-multiselected-color: var(--md-blue-50);--jp-notebook-scroll-padding: calc( 100% - var(--jp-code-font-size) * var(--jp-code-line-height) - var(--jp-code-padding) - var(--jp-cell-padding) - 1px );--jp-rendermime-error-background: #fdd;--jp-rendermime-table-row-background: var(--md-grey-100);--jp-rendermime-table-row-hover-background: var(--md-light-blue-50);--jp-dialog-background: rgba(0, 0, 0, .25);--jp-console-padding: 10px;--jp-toolbar-border-color: var(--jp-border-color1);--jp-toolbar-micro-height: 8px;--jp-toolbar-background: var(--jp-layout-color1);--jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, .24);--jp-toolbar-header-margin: 4px 4px 0px 4px;--jp-toolbar-active-background: var(--md-grey-300);--jp-statusbar-height: 24px;--jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-input-active-background: var(--jp-layout-color1);--jp-input-hover-background: var(--jp-layout-color1);--jp-input-background: var(--md-grey-100);--jp-input-border-color: var(--jp-inverse-border-color);--jp-input-active-border-color: var(--jp-brand-color1);--jp-input-active-box-shadow-color: rgba(19, 124, 189, .3);--jp-editor-selected-background: #d9d9d9;--jp-editor-selected-focused-background: #d7d4f0;--jp-editor-cursor-color: var(--jp-ui-font-color0);--jp-mirror-editor-keyword-color: #008000;--jp-mirror-editor-atom-color: #88f;--jp-mirror-editor-number-color: #080;--jp-mirror-editor-def-color: #00f;--jp-mirror-editor-variable-color: var(--md-grey-900);--jp-mirror-editor-variable-2-color: #05a;--jp-mirror-editor-variable-3-color: #085;--jp-mirror-editor-punctuation-color: #05a;--jp-mirror-editor-property-color: #05a;--jp-mirror-editor-operator-color: #aa22ff;--jp-mirror-editor-comment-color: #408080;--jp-mirror-editor-string-color: #ba2121;--jp-mirror-editor-string-2-color: #708;--jp-mirror-editor-meta-color: #aa22ff;--jp-mirror-editor-qualifier-color: #555;--jp-mirror-editor-builtin-color: #008000;--jp-mirror-editor-bracket-color: #997;--jp-mirror-editor-tag-color: #170;--jp-mirror-editor-attribute-color: #00c;--jp-mirror-editor-header-color: blue;--jp-mirror-editor-quote-color: #090;--jp-mirror-editor-link-color: #00c;--jp-mirror-editor-error-color: #f00;--jp-mirror-editor-hr-color: #999;--jp-collaborator-color1: #ffad8e;--jp-collaborator-color2: #dac83d;--jp-collaborator-color3: #72dd76;--jp-collaborator-color4: #00e4d0;--jp-collaborator-color5: #45d4ff;--jp-collaborator-color6: #e2b1ff;--jp-collaborator-color7: #ff9de6;--jp-vega-background: white;--jp-sidebar-min-width: 250px;--jp-search-toggle-off-opacity: .5;--jp-search-toggle-hover-opacity: .8;--jp-search-toggle-on-opacity: 1;--jp-search-selected-match-background-color: rgb(245, 200, 0);--jp-search-selected-match-color: black;--jp-search-unselected-match-background-color: var( --jp-inverse-layout-color0 );--jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);--jp-icon-contrast-color0: var(--md-purple-600);--jp-icon-contrast-color1: var(--md-green-600);--jp-icon-contrast-color2: var(--md-pink-600);--jp-icon-contrast-color3: var(--md-blue-600);--jp-jupyter-icon-color: #f37626;--jp-notebook-icon-color: #f37626;--jp-json-icon-color: var(--md-orange-700);--jp-console-icon-background-color: var(--md-blue-700);--jp-console-icon-color: white;--jp-terminal-icon-background-color: var(--md-grey-800);--jp-terminal-icon-color: var(--md-grey-200);--jp-text-editor-icon-color: var(--md-grey-700);--jp-inspector-icon-color: var(--md-grey-700);--jp-switch-color: var(--md-grey-400);--jp-switch-true-position-color: var(--md-orange-900)}
</style>
<!-- Load mathjax -->
<script src=""> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --><div class="jupyter-wrapper">
<div class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="shaprfecv-vs-sklearn-rfecv">ShapRFECV vs sklearn RFECV<a class="anchor-link" href="#shaprfecv-vs-sklearn-rfecv">¶</a></h1><p><a href="https://colab.research.google.com/github/ing-bank/probatus/blob/master/docs/discussion/nb_rfecv_vs_shaprfecv.ipynb"><img alt="open in colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<p>In this section we will compare the performance of the model trained on the features selected using the probatus <a href="https://ing-bank.github.io/probatus/api/feature_elimination.html">ShapRFECV</a> and the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html">sklearn RFECV</a>.</p>
<p>In order to compare them let's first prepare a dataset, and a model that will be applied:</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-1">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="o">%%</span><span class="n">capture</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">probatus</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">lightgbm</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-1">%%capture
!pip install probatus
!pip install lightgbm</div>
</div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-2">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">lightgbm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFECV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>

<span class="kn">from</span> <span class="nn">probatus.feature_elimination</span> <span class="kn">import</span> <span class="n">ShapRFECV</span>

<span class="c1"># Prepare train and test data:</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">class_sep</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Set up the model:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lightgbm</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_leaves</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-2">import lightgbm
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.feature_selection import RFECV
from sklearn.model_selection import cross_val_score, train_test_split

from probatus.feature_elimination import ShapRFECV

# Prepare train and test data:
X, y = make_classification(
    n_samples=10000, class_sep=0.1, n_informative=40, n_features=50, random_state=0, n_clusters_per_class=10
)
X = pd.DataFrame(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# Set up the model:
model = lightgbm.LGBMClassifier(n_estimators=10, num_leaves=7, random_state=0)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Now, we can run ShapRFECV and RFECV with the same parameters, to extract the optimal feature sets:</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [4]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-3">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Run RFECV and ShapRFECV with the same parameters</span>
<span class="n">rfe</span> <span class="o">=</span> <span class="n">RFECV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">"roc_auc"</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">shap_elimination</span> <span class="o">=</span> <span class="n">ShapRFECV</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">"roc_auc"</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">shap_report</span> <span class="o">=</span> <span class="n">shap_elimination</span><span class="o">.</span><span class="n">fit_compute</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compare the CV Validation AUC for different number of features in each method.</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">"RFECV Validation AUC"</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">rfe</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">"mean_test_score"</span><span class="p">])),</span>
        <span class="s2">"ShapRFECV Validation AUC"</span><span class="p">:</span> <span class="n">shap_report</span><span class="p">[</span><span class="s2">"val_metric_mean"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
    <span class="p">},</span>
    <span class="n">index</span><span class="o">=</span><span class="n">shap_report</span><span class="p">[</span><span class="s2">"num_features"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
<span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="n">rot</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Comparison of RFECV and ShapRFECV"</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Model Performance"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Number of features"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_xaxis</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-3"># Run RFECV and ShapRFECV with the same parameters
rfe = RFECV(model, step=1, cv=20, scoring="roc_auc", n_jobs=3).fit(X_train, y_train)
shap_elimination = ShapRFECV(model=model, step=1, cv=20, scoring="roc_auc", n_jobs=3, random_state=0)
shap_report = shap_elimination.fit_compute(X_train, y_train)

# Compare the CV Validation AUC for different number of features in each method.
ax = pd.DataFrame(
    {
        "RFECV Validation AUC": list(reversed(rfe.cv_results_["mean_test_score"])),
        "ShapRFECV Validation AUC": shap_report["val_metric_mean"].values.tolist(),
    },
    index=shap_report["num_features"].values.tolist(),
).plot(ylim=(0.5, 0.7), rot=10, title="Comparison of RFECV and ShapRFECV", figsize=(10, 5))
ax.set_ylabel("Model Performance")
ax.set_xlabel("Number of features")
ax.invert_xaxis()
plt.show()</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001171 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000838 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001032 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000915 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000906 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000902 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000969 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001013 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000805 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001116 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000886 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000970 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001410 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001604 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001092 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001650 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001176 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001065 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002925 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000933 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43

[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001145 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000738 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002417 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001140 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001589 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000719 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001476 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000732 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000826 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000758 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001101 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001061 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000744 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000675 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000796 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000693 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000771 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000663 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000914 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000762 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000652 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000953 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000638 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001017 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000763 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000634 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001231 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000919 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000732 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000767 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000560 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000651 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000600 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000616 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001152 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000696 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000742 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000655 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000635 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000759 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001001 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001169 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 5355[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000636 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000577 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000666 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000703 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000565 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000704 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000601 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000619 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000737 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000650 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000528 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000647 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001021 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001064 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001713 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000833 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001018 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000810 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000934 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001791 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47

[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001296 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000978 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001019 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001132 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000754 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000823 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000774 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001024 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001015 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000966 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000889 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001031 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000770 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001033 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000755 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000710 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000976 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001023 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Total Bins 9180

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000851 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000546 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000951 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000927 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001165 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000577 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001255 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000964 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001337 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000660 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000767 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000666 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140[LightGBM] [Info] Total Bins 7140

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001279 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000626 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000576 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000607 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000648 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000650 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000599 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000645 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 5610[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000635 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000535 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000557 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.

[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000577 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000578 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000862 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000589 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000533 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000573 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000582 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000911 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001022 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001027 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001878 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002549 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000901 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000914 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000832 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Total Bins 11730

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000722 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001255 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000951 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001408 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000849 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000956 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001019 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000918 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000988 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000851 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000762 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000908 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000768 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000751 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000968 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000661 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002441 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001430 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000646 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000661 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000674 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000624 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000787 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000765 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000629 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000715 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000603 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001460 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000499 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000589 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000984 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000780 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000678 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000627 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000633 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000540 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000532 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000766 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000671 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000995 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000976 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000778 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000810 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000956 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000854 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000981 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000920 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001306 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000863 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002509 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000995 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000788 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001166 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000770 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000951 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000892 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000863 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000710 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001001 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000916 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000745 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001078 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001134 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000819 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000818 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000813 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000790 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000736 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000958 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000832 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000660 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000835 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000713 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000694 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000743 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000714 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000636 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000993 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000712 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000956 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000610 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000577 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000723 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000644 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000792 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000586 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000714 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000696 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000596 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000693 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000868 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000499 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000645 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000549 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000621 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000661 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000642 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000214 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000549 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000669 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000922 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000589 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000674 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000710 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 1530[LightGBM] [Info] Total Bins 1275

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000244 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000586 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000813 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001162 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000900 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001097 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000925 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000950 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000815 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000865 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001350 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000817 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000756 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000809 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000863 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000900 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001188 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001219 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001398 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000905 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000777 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001114 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001046 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000631 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000785 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000571 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000838 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000666 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000684 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000715 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000830 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001378 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000789 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001250 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000958 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001040 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001056 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Total Bins 7905[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000830 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001342 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000833 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000678 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000660 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000950 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000653 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001178 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000671 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000748 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000626 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000627 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000724 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000762 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000596 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000774 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000789 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000594 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000592 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000646 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000555 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000694 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000524 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000620 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000559 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000767 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000462 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805[LightGBM] [Info] Total Bins 3315

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000757 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000642 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000802 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000802 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000643 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000559 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000670 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000864 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000922 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000833 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000956 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000952 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000961 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000857 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000757 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000924 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001759 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000985 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000959 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11985[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000794 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000880 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000835 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000782 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000767 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000977 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000808 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000886 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000791 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000750 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000635 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000793 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001027 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000911 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000766 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002575 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000761 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000731 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001577 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000760 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000728 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000749 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000883 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001877 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000961 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000939 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000739 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000696 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000813 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001136 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000622 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001098 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000638 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000829 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000716 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000957 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000807 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000541 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000850 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Total Bins 6630

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Total Bins 5610

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000653 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000626 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000641 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000801 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000950 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000524 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000636 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000629 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000580 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000567 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000484 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000885 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000880 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000850 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001362 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000850 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000974 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001340 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000826 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684[LightGBM] [Info] Number of positive: 2377, number of negative: 2373

[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000914 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000822 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000644 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000829 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000653 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000762 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000851 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000808 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000659 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000736 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000746 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000851 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000596 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000670 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000607 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000532 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000624 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35[LightGBM] [Info] Start training from score 0.001684

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000658 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000588 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000644 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000595 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000611 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000571 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000582 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000609 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000627 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000620 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000546 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684

[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16

[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000475 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000540 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000862 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315[LightGBM] [Info] Total Bins 3570

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Start training from score 0.001684

[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000658 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000759 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000754 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000715 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000617 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000636 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000696 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000546 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000580 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000576 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000531 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000594 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000540 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001125 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000943 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000782 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000995 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001858 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002042 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001591 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001118 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001139 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000932 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001077 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001122 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001114 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001157 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000990 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001032 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001778 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000966 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000921 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000936 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000922 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002404 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001091 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001023 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001356 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001079 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000790 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000947 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.001684[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000736 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Total Bins 12495
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 49
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001230 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000995 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000849 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000935 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000951 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001752 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000862 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000822 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000918 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001061 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000824 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000944 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001010 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000768 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000908 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001012 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000702 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 12240
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 48
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000806 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001020 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000935 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001040 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001105 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001324 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001142 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000938 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000793 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001065 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001023 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001080 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001028 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001020 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000785 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000791 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11985
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 47[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684

[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001006 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001135 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001095 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002085 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001180 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001126 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001208 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001242 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001082 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000969 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001000 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001213 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001452 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000944 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000992 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000932 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11730
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 46
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000867 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000925 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001075 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001112 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001116 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000711 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000913 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000943 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001062 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000818 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000906 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.001684[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000904 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 11475
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 45
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000981 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000719 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001437 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000886 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001070 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000686 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000805 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000814 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001093 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000915 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000874 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684

[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000754 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Total Bins 11220
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 44[LightGBM] [Info] Start training from score 0.001684

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001088 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43

[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001953 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001081 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000956 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000978 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001015 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001131 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000926 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001212 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000856 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001033 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000815 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000969 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000809 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000647 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10965
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 43
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000938 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000578 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000948 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Total Bins 10710

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001847 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000771 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001128 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001163 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000927 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001178 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000770 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000824 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10710
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000905 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001030 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000793 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000778 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000945 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000898 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000964 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000814 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000649 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41

[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000899 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000731 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000625 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10455
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 41
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000751 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000794 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000834 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000720 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000879 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001080 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001815 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000934 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000799 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001029 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000722 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000704 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 10200
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 40
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000810 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000560 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000763 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000814 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001155 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000911 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000850 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000823 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000723 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000868 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000900 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000762 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000764 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] Total Bins 9945
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 39
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000945 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000850 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001290 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001440 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001340 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000715 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000728 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002314 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001034 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001010 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001148 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001238 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001011 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000926 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000630 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9690
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 38
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000943 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000754 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000755 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000921 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000807 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000749 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000707 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000782 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001737 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000817 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000693 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9435
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 37
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684

[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001027 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001055 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000665 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000698 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000689 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000774 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000782 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001002 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001234 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001151 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000634 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001654 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001170 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001103 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000594 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000698 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9180
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 36
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001094 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000749 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000749 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000731 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000737 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000981 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000736 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 8925
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 35
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000838 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000777 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000647 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000718 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8670[LightGBM] [Info] Total Bins 8670

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000926 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000560 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000627 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000560 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000629 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001560 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000805 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000817 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000771 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000918 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000571 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000508 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 8670
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 34
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001459 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000977 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001322 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000675 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000636 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000658 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000658 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000768 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000906 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000660 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000737 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001097 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000659 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000831 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000532 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000565 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 8415
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 33
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001002 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000596 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000666 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000732 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000724 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] Total Bins 8160
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 32
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000755 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Total Bins 7905

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000610 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000778 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000857 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000892 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905[LightGBM] [Info] Total Bins 7905

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000747 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000721 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001196 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7905
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 31
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000926 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000984 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000808 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000761 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000652 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001025 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000663 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30

[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000512 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000573 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001271 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001053 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000645 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000646 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 7395

[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000906 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000648 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000791 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000724 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000665 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000724 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7395
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684[LightGBM] [Info] Total Bins 7395

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 29
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000913 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000945 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000791 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000759 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000680 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000859 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000582 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000620 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000662 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000990 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000666 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000580 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Total Bins 7140
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 28
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001012 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000970 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000949 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000905 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001103 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001458 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Total Bins 6885
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 27
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000618 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000646 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001000 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000666 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000742 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001899 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000704 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000718 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6630
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 26
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000781 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000598 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000562 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Total Bins 6375

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001487 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000789 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000694 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000934 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000578 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000625 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6375
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 25
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000955 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24

[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000653 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000611 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000621 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Total Bins 6120

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000610 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 6120

[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000612 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000716 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000601 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6120
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000732 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000778 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000710 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000541 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Total Bins 5865
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000747 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000674 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000711 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000682 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000663 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000805 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001044 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000959 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 5610
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 22
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000748 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000638 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000744 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000601 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000979 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000661 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000592 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000622 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000555 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000599 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000499 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] Total Bins 5355
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000621 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000603 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000671 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000980 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000462 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000799 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000865 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000817 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 5100
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000643 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000732 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000600 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4845
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000758 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000965 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000712 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000591 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000958 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000599 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000586 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000577 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000635 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Total Bins 4590
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000562 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000512 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001147 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000620 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000253 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4335
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000768 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000524 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000484 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000619 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Total Bins 3825[LightGBM] [Info] Total Bins 3825

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000799 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000731 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000832 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3570
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000875 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000535 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000532 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000658 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3315
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000475 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000533 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3060
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000589 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000576 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000770 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001117 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000546 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000578 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Total Bins 2805
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2550
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000655 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2295
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000567 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8

[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526

[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2040
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001317 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001641 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000535 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1785
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Total Bins 1530

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000611 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000698 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1275[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 1275
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684[LightGBM] [Info] Start training from score 0.001684

[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000706 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1020
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372[LightGBM] [Info] Number of positive: 2378, number of negative: 2372

[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765[LightGBM] [Info] Total Bins 765

[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3

[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000482 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3
[LightGBM] [Info] Total Bins 765
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 3

[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000774 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000731 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 510
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.
You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.
You can set `force_col_wise=true` to remove the overhead.

[LightGBM] [Info] Total Bins 510[LightGBM] [Info] Total Bins 510

[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526[LightGBM] [Info] Start training from score 0.002526

[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2378, number of negative: 2372
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500632 -&gt; initscore=0.002526
[LightGBM] [Info] Start training from score 0.002526
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
[LightGBM] [Info] Number of positive: 2377, number of negative: 2373
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 255
[LightGBM] [Info] Number of data points in the train set: 4750, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -&gt; initscore=0.001684
[LightGBM] [Info] Start training from score 0.001684
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>The plot above presents the averaged CV Validation AUC of model performance for each round of the RFE process in both ShapRFECV and RFECV. The optimal number of features is 16 (based on the highest validation metric mean) for the former, and 15 for the latter.</p>
<p>Now we will compare the performance of the model trained on:</p>
<ul>
<li>All 50 available features (baseline),</li>
<li>15 features selected by RFECV (final),</li>
<li>16 features selected by ShapRFECV (final),</li>
<li>15 feature selected by ShapRFECV (baseline).</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [5]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-4">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="n">n_features_shap</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shap_elimination</span><span class="o">.</span><span class="n">get_reduced_features_set</span><span class="p">(</span><span class="s2">"best"</span><span class="p">))</span>  <span class="c1"># 16</span>
<span class="n">n_features_rfecv</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rfe</span><span class="o">.</span><span class="n">n_features_</span><span class="p">)</span>  <span class="c1"># 15</span>

<span class="c1"># Calculate the AUC using all features.</span>
<span class="n">test_auc_full</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">val_auc_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="c1"># Optimal set for RFECV</span>
<span class="n">rfe_features_set</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">]</span>
<span class="n">test_auc_rfe</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">rfe_features_set</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">rfe_features_set</span><span class="p">],</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">val_auc_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">"mean_test_score"</span><span class="p">][</span><span class="n">n_features_rfecv</span><span class="p">]</span>

<span class="c1"># Optimal set for SHAP</span>
<span class="n">shap_feature_set</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">shap_elimination</span><span class="o">.</span><span class="n">get_reduced_features_set</span><span class="p">(</span><span class="n">n_features_shap</span><span class="p">)]</span>
<span class="n">test_auc_shap</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">shap_feature_set</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">shap_feature_set</span><span class="p">],</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">val_auc_shap</span> <span class="o">=</span> <span class="n">shap_report</span><span class="p">[</span><span class="n">shap_report</span><span class="o">.</span><span class="n">num_features</span> <span class="o">==</span> <span class="n">n_features_shap</span><span class="p">][</span><span class="s2">"val_metric_mean"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Same nr of features as RFECV</span>
<span class="n">shap_feature_set_size_rfe</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">shap_elimination</span><span class="o">.</span><span class="n">get_reduced_features_set</span><span class="p">(</span><span class="n">n_features_rfecv</span><span class="p">)]</span>
<span class="n">test_auc_shap_size_rfe</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">shap_feature_set_size_rfe</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span>
    <span class="n">X_test</span><span class="p">[</span><span class="n">shap_feature_set_size_rfe</span><span class="p">],</span> <span class="n">y_test</span>
<span class="p">)</span>
<span class="n">val_auc_shap_size_rfe</span> <span class="o">=</span> <span class="n">shap_report</span><span class="p">[</span><span class="n">shap_report</span><span class="o">.</span><span class="n">num_features</span> <span class="o">==</span> <span class="n">n_features_rfecv</span><span class="p">][</span><span class="s2">"val_metric_mean"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Plot Test and Validation Performance</span>
<span class="n">variants</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">"All 50 features"</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">"RFECV </span><span class="si">{</span><span class="n">n_features_rfecv</span><span class="si">}</span><span class="s2"> features"</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">"ShapRFECV </span><span class="si">{</span><span class="n">n_features_shap</span><span class="si">}</span><span class="s2"> features"</span><span class="p">,</span>
    <span class="sa">f</span><span class="s2">"ShapRFECV </span><span class="si">{</span><span class="n">n_features_rfecv</span><span class="si">}</span><span class="s2"> features"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_auc_full</span><span class="p">,</span> <span class="n">test_auc_rfe</span><span class="p">,</span> <span class="n">test_auc_shap</span><span class="p">,</span> <span class="n">test_auc_shap_size_rfe</span><span class="p">]</span>
<span class="n">results_val</span> <span class="o">=</span> <span class="p">[</span><span class="n">val_auc_full</span><span class="p">,</span> <span class="n">val_auc_rfe</span><span class="p">,</span> <span class="n">val_auc_shap</span><span class="p">,</span> <span class="n">val_auc_shap_size_rfe</span><span class="p">]</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">"CV Validation AUC"</span><span class="p">:</span> <span class="n">results_val</span><span class="p">,</span> <span class="s2">"Test AUC"</span><span class="p">:</span> <span class="n">results_test</span><span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="n">variants</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span> <span class="n">rot</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Comparison of RFECV and ShapRFECV"</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Model Performance"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-4">n_features_shap = len(shap_elimination.get_reduced_features_set("best"))  # 16
n_features_rfecv = int(rfe.n_features_)  # 15

# Calculate the AUC using all features.
test_auc_full = model.fit(X_train, y_train).score(X_test, y_test)
val_auc_full = np.mean(cross_val_score(model, X_train, y_train, cv=10))

# Optimal set for RFECV
rfe_features_set = X_train.columns[rfe.support_]
test_auc_rfe = model.fit(X_train[rfe_features_set], y_train).score(X_test[rfe_features_set], y_test)
val_auc_rfe = rfe.cv_results_["mean_test_score"][n_features_rfecv]

# Optimal set for SHAP
shap_feature_set = X_train.columns[shap_elimination.get_reduced_features_set(n_features_shap)]
test_auc_shap = model.fit(X_train[shap_feature_set], y_train).score(X_test[shap_feature_set], y_test)
val_auc_shap = shap_report[shap_report.num_features == n_features_shap]["val_metric_mean"].values[0]

# Same nr of features as RFECV
shap_feature_set_size_rfe = X_train.columns[shap_elimination.get_reduced_features_set(n_features_rfecv)]
test_auc_shap_size_rfe = model.fit(X_train[shap_feature_set_size_rfe], y_train).score(
    X_test[shap_feature_set_size_rfe], y_test
)
val_auc_shap_size_rfe = shap_report[shap_report.num_features == n_features_rfecv]["val_metric_mean"].values[0]

# Plot Test and Validation Performance
variants = (
    "All 50 features",
    f"RFECV {n_features_rfecv} features",
    f"ShapRFECV {n_features_shap} features",
    f"ShapRFECV {n_features_rfecv} features",
)
results_test = [test_auc_full, test_auc_rfe, test_auc_shap, test_auc_shap_size_rfe]
results_val = [val_auc_full, val_auc_rfe, val_auc_shap, val_auc_shap_size_rfe]

ax = pd.DataFrame({"CV Validation AUC": results_val, "Test AUC": results_test}, index=variants).plot.bar(
    ylim=(0.5, 0.6), rot=10, title="Comparison of RFECV and ShapRFECV", figsize=(10, 5)
)
plt.axhline(y=0.5)
ax.set_ylabel("Model Performance")
plt.show()</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000759 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2253, number of negative: 2247
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500667 -&gt; initscore=0.002667
[LightGBM] [Info] Start training from score 0.002667
[LightGBM] [Info] Number of positive: 2253, number of negative: 2247
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500667 -&gt; initscore=0.002667
[LightGBM] [Info] Start training from score 0.002667
[LightGBM] [Info] Number of positive: 2253, number of negative: 2247
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000675 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500667 -&gt; initscore=0.002667
[LightGBM] [Info] Start training from score 0.002667
[LightGBM] [Info] Number of positive: 2253, number of negative: 2247
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000653 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500667 -&gt; initscore=0.002667
[LightGBM] [Info] Start training from score 0.002667
[LightGBM] [Info] Number of positive: 2253, number of negative: 2247
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000710 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500667 -&gt; initscore=0.002667
[LightGBM] [Info] Start training from score 0.002667
[LightGBM] [Info] Number of positive: 2253, number of negative: 2247
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500667 -&gt; initscore=0.002667
[LightGBM] [Info] Start training from score 0.002667
[LightGBM] [Info] Number of positive: 2253, number of negative: 2247
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500667 -&gt; initscore=0.002667
[LightGBM] [Info] Start training from score 0.002667
[LightGBM] [Info] Number of positive: 2252, number of negative: 2248
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000648 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500444 -&gt; initscore=0.001778
[LightGBM] [Info] Start training from score 0.001778
[LightGBM] [Info] Number of positive: 2252, number of negative: 2248
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000726 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500444 -&gt; initscore=0.001778
[LightGBM] [Info] Start training from score 0.001778
[LightGBM] [Info] Number of positive: 2252, number of negative: 2248
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 12750
[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 50
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500444 -&gt; initscore=0.001778
[LightGBM] [Info] Start training from score 0.001778
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4080
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
[LightGBM] [Info] Number of positive: 2503, number of negative: 2497
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3825
[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -&gt; initscore=0.002400
[LightGBM] [Info] Start training from score 0.002400
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>As shown in the plot, ShapRFECV provides superior results for both: CV Validation and Test AUC, compared to RFECV and the baseline model with all the available features. Not only the introduced method allows to eliminate features without the loss in performance, but also it may increase the performance of the model.</p>
<p>When it comes to time required to perform the feature selection in the experiment above, RFECV takes 6.11 s ± 33.7 ms, while ShapRFECV takes 10.1 s ± 72.8 ms, which shows that the latter is more computation expensive, due to SHAP values calculation.</p>
</div>
</div>
</div>
</div>
</div> <!-- jp-Notebook -->
</div> <!-- jupyter-wrapper -->

        <style>
        ['pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.highlight-ipynb .hll { background-color: var(--jp-cell-editor-active-background) }\n.highlight-ipynb { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }\n.highlight-ipynb .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */\n.highlight-ipynb .err { color: var(--jp-mirror-editor-error-color) } /* Error */\n.highlight-ipynb .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */\n.highlight-ipynb .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */\n.highlight-ipynb .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */\n.highlight-ipynb .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */\n.highlight-ipynb .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */\n.highlight-ipynb .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */\n.highlight-ipynb .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */\n.highlight-ipynb .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */\n.highlight-ipynb .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */\n.highlight-ipynb .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */\n.highlight-ipynb .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */\n.highlight-ipynb .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */\n.highlight-ipynb .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */\n.highlight-ipynb .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */\n.highlight-ipynb .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */\n.highlight-ipynb .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */\n.highlight-ipynb .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */\n.highlight-ipynb .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */\n.highlight-ipynb .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */\n.highlight-ipynb .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */\n.highlight-ipynb .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */\n.highlight-ipynb .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */\n.highlight-ipynb .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */\n.highlight-ipynb .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */\n.highlight-ipynb .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */\n.highlight-ipynb .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */\n.highlight-ipynb .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */\n.highlight-ipynb .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */\n.highlight-ipynb .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */\n.highlight-ipynb .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */\n.highlight-ipynb .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */\n.highlight-ipynb .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */\n.highlight-ipynb .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */\n.highlight-ipynb .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */\n.highlight-ipynb .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */\n.highlight-ipynb .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */\n.highlight-ipynb .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */\n.highlight-ipynb .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */\n.highlight-ipynb .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */']
        </style>
        












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; ING Bank N.V.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  </body>
</html>