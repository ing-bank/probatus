
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Validation of regressors and classifiers and data used to develop them">
      
      
        <meta name="author" content="ING Bank N. V.">
      
      
        <link rel="canonical" href="https://ing-bank.github.io/probatus/api/model_interpret.html">
      
      
        <link rel="prev" href="feature_elimination.html">
      
      
        <link rel="next" href="sample_similarity.html">
      
      
      <link rel="icon" href="../img/Probatus_P_white.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.29">
    
    
      
        <title>Model Interpretation using SHAP - Probatus</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.76a95c52.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model-interpretation-using-shap" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="Probatus" class="md-header__button md-logo" aria-label="Probatus" data-md-component="logo">
      
  <img src="../img/Probatus_P_white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Probatus
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Model Interpretation using SHAP
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ing-bank/probatus/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../index.html" class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="feature_elimination.html" class="md-tabs__link">
          
  
  Api

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../discussion/nb_rfecv_vs_shaprfecv.html" class="md-tabs__link">
          
  
  Discussion

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../howto/grouped_data.html" class="md-tabs__link">
          
  
  Howto

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/nb_automatic_best_num_features.html" class="md-tabs__link">
          
  
  Tutorials

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Probatus" class="md-nav__button md-logo" aria-label="Probatus" data-md-component="logo">
      
  <img src="../img/Probatus_P_white.png" alt="logo">

    </a>
    Probatus
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ing-bank/probatus/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Api
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Api
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="feature_elimination.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Features Elimination
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Model Interpretation using SHAP
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="model_interpret.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Model Interpretation using SHAP
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret" class="md-nav__link">
    <span class="md-ellipsis">
      model_interpret
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter" class="md-nav__link">
    <span class="md-ellipsis">
      ShapModelInterpreter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ShapModelInterpreter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.compute" class="md-nav__link">
    <span class="md-ellipsis">
      compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.fit_compute" class="md-nav__link">
    <span class="md-ellipsis">
      fit_compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence" class="md-nav__link">
    <span class="md-ellipsis">
      shap_dependence
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter" class="md-nav__link">
    <span class="md-ellipsis">
      DependencePlotter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DependencePlotter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.__repr__" class="md-nav__link">
    <span class="md-ellipsis">
      __repr__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.compute" class="md-nav__link">
    <span class="md-ellipsis">
      compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.fit_compute" class="md-nav__link">
    <span class="md-ellipsis">
      fit_compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="sample_similarity.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sample Similarity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="utils.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utility Functions
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Discussion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Discussion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../discussion/nb_rfecv_vs_shaprfecv.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ShapRFECV vs sklearn RFECV
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Howto
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Howto
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../howto/grouped_data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to work with grouped data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../howto/reproducibility.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to ensure reproducibility of the results
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_automatic_best_num_features.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Feature selection techniques
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_custom_scoring.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom Scoring Metrics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_sample_similarity.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sample Similarity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_dependence.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap dependence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_feature_elimination.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ShapRFECV - Recursive Feature Elimination using SHAP importance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_model_interpreter.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tree Model Interpretation using SHAP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_variance_penalty_and_results_comparison.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap variance penalty
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret" class="md-nav__link">
    <span class="md-ellipsis">
      model_interpret
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter" class="md-nav__link">
    <span class="md-ellipsis">
      ShapModelInterpreter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ShapModelInterpreter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.compute" class="md-nav__link">
    <span class="md-ellipsis">
      compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.fit_compute" class="md-nav__link">
    <span class="md-ellipsis">
      fit_compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.model_interpret.ShapModelInterpreter.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence" class="md-nav__link">
    <span class="md-ellipsis">
      shap_dependence
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter" class="md-nav__link">
    <span class="md-ellipsis">
      DependencePlotter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DependencePlotter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.__repr__" class="md-nav__link">
    <span class="md-ellipsis">
      __repr__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.compute" class="md-nav__link">
    <span class="md-ellipsis">
      compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.fit_compute" class="md-nav__link">
    <span class="md-ellipsis">
      fit_compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.interpret.shap_dependence.DependencePlotter.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="model-interpretation-using-shap">Model Interpretation using SHAP</h1>
<p>The aim of this module is to provide tools for model interpretation using the <a href="https://shap.readthedocs.io/en/latest/">SHAP</a> library.
The class below is a convenience wrapper that implements multiple plots for tree-based &amp; linear models.</p>


<div class="doc doc-object doc-module">



<a id="probatus.interpret.model_interpret"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="probatus.interpret.model_interpret.ShapModelInterpreter" class="doc doc-heading">
            <code>ShapModelInterpreter</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="probatus.utils.BaseFitComputePlotClass">BaseFitComputePlotClass</span></code></p>


      <p>This class is a wrapper that allows to easily analyse a model's features.</p>
<p>It allows us to plot SHAP feature importance,
    SHAP summary plot and SHAP dependence plots.</p>
<p>Example:</p>
<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from probatus.interpret import ShapModelInterpreter
import numpy as np
import pandas as pd

feature_names = ['f1', 'f2', 'f3', 'f4']

# Prepare two samples
X, y = make_classification(n_samples=5000, n_features=4, random_state=0)
X = pd.DataFrame(X, columns=feature_names)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Prepare and fit model. Remember about class_weight=&quot;balanced&quot; or an equivalent.
model = RandomForestClassifier(class_weight='balanced', n_estimators = 100, max_depth=2, random_state=0)
model.fit(X_train, y_train)

# Train ShapModelInterpreter
shap_interpreter = ShapModelInterpreter(model)
feature_importance = shap_interpreter.fit_compute(X_train, X_test, y_train, y_test)

# Make plots
ax1 = shap_interpreter.plot('importance')
ax2 = shap_interpreter.plot('summary')
ax3 = shap_interpreter.plot('dependence', target_columns=['f1', 'f2'])
ax4 = shap_interpreter.plot('sample', samples_index=[X_test.index.tolist()[0]])
</code></pre>
<p><img src="../img/model_interpret_importance.png" width="320" />
<img src="../img/model_interpret_summary.png" width="320" />
<img src="../img/model_interpret_dep.png" width="320" />
<img src="../img/model_interpret_sample.png" width="320" /></p>

              <details class="quote">
                <summary>Source code in <code>probatus/interpret/model_interpret.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ShapModelInterpreter</span><span class="p">(</span><span class="n">BaseFitComputePlotClass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class is a wrapper that allows to easily analyse a model&#39;s features.</span>

<span class="sd">    It allows us to plot SHAP feature importance,</span>
<span class="sd">        SHAP summary plot and SHAP dependence plots.</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">    from sklearn.datasets import make_classification</span>
<span class="sd">    from sklearn.ensemble import RandomForestClassifier</span>
<span class="sd">    from sklearn.model_selection import train_test_split</span>
<span class="sd">    from probatus.interpret import ShapModelInterpreter</span>
<span class="sd">    import numpy as np</span>
<span class="sd">    import pandas as pd</span>

<span class="sd">    feature_names = [&#39;f1&#39;, &#39;f2&#39;, &#39;f3&#39;, &#39;f4&#39;]</span>

<span class="sd">    # Prepare two samples</span>
<span class="sd">    X, y = make_classification(n_samples=5000, n_features=4, random_state=0)</span>
<span class="sd">    X = pd.DataFrame(X, columns=feature_names)</span>
<span class="sd">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span>

<span class="sd">    # Prepare and fit model. Remember about class_weight=&quot;balanced&quot; or an equivalent.</span>
<span class="sd">    model = RandomForestClassifier(class_weight=&#39;balanced&#39;, n_estimators = 100, max_depth=2, random_state=0)</span>
<span class="sd">    model.fit(X_train, y_train)</span>

<span class="sd">    # Train ShapModelInterpreter</span>
<span class="sd">    shap_interpreter = ShapModelInterpreter(model)</span>
<span class="sd">    feature_importance = shap_interpreter.fit_compute(X_train, X_test, y_train, y_test)</span>

<span class="sd">    # Make plots</span>
<span class="sd">    ax1 = shap_interpreter.plot(&#39;importance&#39;)</span>
<span class="sd">    ax2 = shap_interpreter.plot(&#39;summary&#39;)</span>
<span class="sd">    ax3 = shap_interpreter.plot(&#39;dependence&#39;, target_columns=[&#39;f1&#39;, &#39;f2&#39;])</span>
<span class="sd">    ax4 = shap_interpreter.plot(&#39;sample&#39;, samples_index=[X_test.index.tolist()[0]])</span>
<span class="sd">    ```</span>

<span class="sd">    &lt;img src=&quot;../img/model_interpret_importance.png&quot; width=&quot;320&quot; /&gt;</span>
<span class="sd">    &lt;img src=&quot;../img/model_interpret_summary.png&quot; width=&quot;320&quot; /&gt;</span>
<span class="sd">    &lt;img src=&quot;../img/model_interpret_dep.png&quot; width=&quot;320&quot; /&gt;</span>
<span class="sd">    &lt;img src=&quot;../img/model_interpret_sample.png&quot; width=&quot;320&quot; /&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the class.</span>

<span class="sd">        Args:</span>
<span class="sd">            model (classifier or regressor):</span>
<span class="sd">                Model fitted on X_train.</span>

<span class="sd">            scoring (string or probatus.utils.Scorer, optional):</span>
<span class="sd">                Metric for which the model performance is calculated. It can be either a metric name  aligned with</span>
<span class="sd">                predefined classification scorers names in sklearn</span>
<span class="sd">                ([link](https://scikit-learn.org/stable/modules/model_evaluation.html)).</span>
<span class="sd">                Another option is using probatus.utils.Scorer to define a custom metric.</span>

<span class="sd">            verbose (int, optional):</span>
<span class="sd">                Controls verbosity of the output:</span>

<span class="sd">                - 0 - neither prints nor warnings are shown</span>
<span class="sd">                - 1 - only most important warnings</span>
<span class="sd">                - 2 - shows all prints and all warnings.</span>

<span class="sd">            random_state (int, optional):</span>
<span class="sd">                Random state set for the nr of samples. If it is None, the results will not be reproducible. For</span>
<span class="sd">                reproducible results set it to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">get_single_scorer</span><span class="p">(</span><span class="n">scoring</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the object and calculates the shap values for the provided datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_train (pd.DataFrame):</span>
<span class="sd">                Dataframe containing training data.</span>

<span class="sd">            X_test (pd.DataFrame):</span>
<span class="sd">                Dataframe containing test data.</span>

<span class="sd">            y_train (pd.Series):</span>
<span class="sd">                Series of labels for train data.</span>

<span class="sd">            y_test (pd.Series):</span>
<span class="sd">                Series of labels for test data.</span>

<span class="sd">            column_names (None, or list of str, optional):</span>
<span class="sd">                List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</span>

<span class="sd">            class_names (None, or list of str, optional):</span>
<span class="sd">                List of class names e.g. [&#39;neg&#39;, &#39;pos&#39;]. If none, the default [&#39;Negative Class&#39;, &#39;Positive Class&#39;] are</span>
<span class="sd">                used.</span>

<span class="sd">            **shap_kwargs:</span>
<span class="sd">                keyword arguments passed to</span>
<span class="sd">                [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">                It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">                The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">                `check_additivity=False` disables the additivity check inside SHAP.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">preprocess_labels</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_name</span><span class="o">=</span><span class="s2">&quot;y_train&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">preprocess_labels</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_name</span><span class="o">=</span><span class="s2">&quot;y_test&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="c1"># Set class names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">class_names</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Negative Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Positive Class&quot;</span><span class="p">]</span>

        <span class="c1"># Calculate Metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Train </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_score</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Test </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_score</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_train</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">expected_value_train</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tdp_train</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prep_shap_related_variables</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span>
            <span class="n">column_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">expected_value_test</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tdp_test</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prep_shap_related_variables</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">,</span>
            <span class="n">column_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_prep_shap_related_variables</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">approximate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The function prepares the variables related to shap that are used to interpret the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (np.array, int, DependencePlotter):</span>
<span class="sd">                Shap values, expected value of the explainer, and fitted TreeDependencePlotter for a given dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">shap_values</span><span class="p">,</span> <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap_calc</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">approximate</span><span class="o">=</span><span class="n">approximate</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">return_explainer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">expected_value</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span>

        <span class="c1"># For sklearn models the expected values consists of two elements (negative_class and positive_class)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expected_value</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expected_value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">expected_value</span> <span class="o">=</span> <span class="n">expected_value</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Initialize tree dependence plotter</span>
        <span class="n">tdp</span> <span class="o">=</span> <span class="n">DependencePlotter</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
            <span class="n">precalc_shap</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">shap_values</span><span class="p">,</span> <span class="n">expected_value</span><span class="p">,</span> <span class="n">tdp</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the DataFrame that presents the importance of each feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            return_scores (bool, optional):</span>
<span class="sd">                Flag indicating whether the method should return the train and test score of the model, together with</span>
<span class="sd">                the model interpretation report. If true, the output of this method is a tuple of DataFrame, float,</span>
<span class="sd">                float.</span>

<span class="sd">            shap_variance_penalty_factor (int or float, optional):</span>
<span class="sd">                Apply aggregation penalty when computing average of shap values for a given feature.</span>
<span class="sd">                Results in a preference for features that have smaller standard deviation of shap</span>
<span class="sd">                values (more coherent shap importance). Recommend value 0.5 - 1.0.</span>
<span class="sd">                Formula: penalized_shap_mean = (mean_shap - (std_shap * shap_variance_penalty_factor))</span>

<span class="sd">        Returns:</span>
<span class="sd">            (pd.DataFrame or tuple(pd.DataFrame, float, float)):</span>
<span class="sd">                Dataframe with SHAP feature importance, or tuple containing the dataframe, train and test scores of the</span>
<span class="sd">                model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>

        <span class="c1"># Compute SHAP importance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">importance_df_train</span> <span class="o">=</span> <span class="n">calculate_shap_importance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_train</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">output_columns_suffix</span><span class="o">=</span><span class="s2">&quot;_train&quot;</span><span class="p">,</span>
            <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="n">shap_variance_penalty_factor</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">importance_df_test</span> <span class="o">=</span> <span class="n">calculate_shap_importance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">output_columns_suffix</span><span class="o">=</span><span class="s2">&quot;_test&quot;</span><span class="p">,</span>
            <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="n">shap_variance_penalty_factor</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Concatenate the train and test, sort by test set importance and reorder the columns</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">importance_df_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">importance_df_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
            <span class="s2">&quot;mean_abs_shap_value_test&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)[</span>
            <span class="p">[</span>
                <span class="s2">&quot;mean_abs_shap_value_test&quot;</span><span class="p">,</span>
                <span class="s2">&quot;mean_abs_shap_value_train&quot;</span><span class="p">,</span>
                <span class="s2">&quot;mean_shap_value_test&quot;</span><span class="p">,</span>
                <span class="s2">&quot;mean_shap_value_train&quot;</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">return_scores</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">importance_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">importance_df</span>

    <span class="k">def</span> <span class="nf">fit_compute</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the object and calculates the shap values for the provided datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_train (pd.DataFrame):</span>
<span class="sd">                Dataframe containing training data.</span>

<span class="sd">            X_test (pd.DataFrame):</span>
<span class="sd">                Dataframe containing test data.</span>

<span class="sd">            y_train (pd.Series):</span>
<span class="sd">                Series of labels for train data.</span>

<span class="sd">            y_test (pd.Series):</span>
<span class="sd">                Series of labels for test data.</span>

<span class="sd">            column_names (None, or list of str, optional):</span>
<span class="sd">                List of feature names for the dataset.</span>
<span class="sd">                If None, then column names from the X_train dataframe are used.</span>

<span class="sd">            class_names (None, or list of str, optional):</span>
<span class="sd">                List of class names e.g. [&#39;neg&#39;, &#39;pos&#39;].</span>
<span class="sd">                If none, the default [&#39;Negative Class&#39;, &#39;Positive Class&#39;] are</span>
<span class="sd">                used.</span>

<span class="sd">            return_scores (bool, optional):</span>
<span class="sd">                Flag indicating whether the method should return</span>
<span class="sd">                the train and test score of the model,</span>
<span class="sd">                together with the model interpretation report. If true,</span>
<span class="sd">                the output of this method is a tuple of DataFrame, float,</span>
<span class="sd">                float.</span>

<span class="sd">            shap_variance_penalty_factor (int or float, optional):</span>
<span class="sd">                Apply aggregation penalty when computing average of shap values for a given feature.</span>
<span class="sd">                Results in a preference for features that have smaller standard deviation of shap</span>
<span class="sd">                values (more coherent shap importance). Recommend value 0.5 - 1.0.</span>
<span class="sd">                Formula: penalized_shap_mean = (mean_shap - (std_shap * shap_variance_penalty_factor))</span>

<span class="sd">            **shap_kwargs:</span>
<span class="sd">                keyword arguments passed to</span>
<span class="sd">                [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">                It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">                The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">                `check_additivity=False` disables the additivity check inside SHAP.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (pd.DataFrame or tuple(pd.DataFrame, float, float)):</span>
<span class="sd">                Dataframe with SHAP feature importance, or tuple containing the dataframe, train and test scores of the</span>
<span class="sd">                model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
            <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
            <span class="n">y_train</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
            <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
            <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
            <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">return_scores</span><span class="o">=</span><span class="n">return_scores</span><span class="p">,</span> <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="n">shap_variance_penalty_factor</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plot_type</span><span class="p">,</span> <span class="n">target_set</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">target_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">samples_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the appropriate SHAP plot.</span>

<span class="sd">        Args:</span>
<span class="sd">            plot_type (str):</span>
<span class="sd">                One of the following:</span>

<span class="sd">                - `&#39;importance&#39;`: Feature importance plot, SHAP bar summary plot</span>
<span class="sd">                - `&#39;summary&#39;`: SHAP Summary plot</span>
<span class="sd">                - `&#39;dependence&#39;`: Dependence plot for each feature</span>
<span class="sd">                - `&#39;sample&#39;`: Explanation of a given sample in the test data</span>

<span class="sd">            target_set (str, optional):</span>
<span class="sd">                The set for which the plot should be generated, either `train` or `test` set. We recommend using test</span>
<span class="sd">                set, because it is not biased by model training. The train set plots are mainly used to compare with the</span>
<span class="sd">                test set plots, whether there are significant differences, which indicate shift in data distribution.</span>

<span class="sd">            target_columns (None, str or list of str, optional):</span>
<span class="sd">                List of features names, for which the plots should be generated. If None, all features will be plotted.</span>

<span class="sd">            samples_index (None, int, list or pd.Index, optional):</span>
<span class="sd">                Index of samples to be explained if the `plot_type=sample`.</span>

<span class="sd">            show (bool, optional):</span>
<span class="sd">                If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,</span>
<span class="sd">                when you want to edit the returned axis, before showing it.</span>

<span class="sd">            **plot_kwargs:</span>
<span class="sd">                Keyword arguments passed to the plot method. For &#39;importance&#39; and &#39;summary&#39; plot_type, the kwargs are</span>
<span class="sd">                passed to shap.summary_plot, for &#39;dependence&#39; plot_type, they are passed to</span>
<span class="sd">                probatus.interpret.DependencePlotter.plot method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (matplotlib.axes or list(matplotlib.axes)):</span>
<span class="sd">                An Axes with the plot, or list of axes when multiple plots are returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Choose correct columns</span>
        <span class="k">if</span> <span class="n">target_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">target_columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span>

        <span class="n">target_columns</span> <span class="o">=</span> <span class="n">assure_list_of_strings</span><span class="p">(</span><span class="n">target_columns</span><span class="p">,</span> <span class="s2">&quot;target_columns&quot;</span><span class="p">)</span>
        <span class="n">target_columns_indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">target_column</span><span class="p">)</span> <span class="k">for</span> <span class="n">target_column</span> <span class="ow">in</span> <span class="n">target_columns</span><span class="p">]</span>

        <span class="c1"># Choose the correct dataset</span>
        <span class="k">if</span> <span class="n">target_set</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
            <span class="n">target_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span>
            <span class="n">target_shap_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span>
            <span class="n">target_tdp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tdp_test</span>
            <span class="n">target_expected_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected_value_test</span>
        <span class="k">elif</span> <span class="n">target_set</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
            <span class="n">target_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span>
            <span class="n">target_shap_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_train</span>
            <span class="n">target_tdp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tdp_train</span>
            <span class="n">target_expected_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected_value_train</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The target_set parameter can be either &quot;train&quot; or &quot;test&quot;.&#39;</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">plot_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">]:</span>
            <span class="n">target_X</span> <span class="o">=</span> <span class="n">target_X</span><span class="p">[</span><span class="n">target_columns</span><span class="p">]</span>
            <span class="n">target_shap_values</span> <span class="o">=</span> <span class="n">target_shap_values</span><span class="p">[:,</span> <span class="n">target_columns_indices</span><span class="p">]</span>
            <span class="c1"># Set summary plot settings</span>
            <span class="k">if</span> <span class="n">plot_type</span> <span class="o">==</span> <span class="s2">&quot;importance&quot;</span><span class="p">:</span>
                <span class="n">plot_type</span> <span class="o">=</span> <span class="s2">&quot;bar&quot;</span>
                <span class="n">plot_title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SHAP Feature Importance for </span><span class="si">{</span><span class="n">target_set</span><span class="si">}</span><span class="s2"> set&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">plot_type</span> <span class="o">=</span> <span class="s2">&quot;dot&quot;</span>
                <span class="n">plot_title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SHAP Summary plot for </span><span class="si">{</span><span class="n">target_set</span><span class="si">}</span><span class="s2"> set&quot;</span>

            <span class="n">summary_plot</span><span class="p">(</span>
                <span class="n">target_shap_values</span><span class="p">,</span>
                <span class="n">target_X</span><span class="p">,</span>
                <span class="n">plot_type</span><span class="o">=</span><span class="n">plot_type</span><span class="p">,</span>
                <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
                <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">plot_title</span><span class="p">)</span>

            <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span><span class="p">,</span>
                <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">),</span>
                <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
                <span class="n">xycoords</span><span class="o">=</span><span class="s2">&quot;axes fraction&quot;</span><span class="p">,</span>
                <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
                <span class="n">va</span><span class="o">=</span><span class="s2">&quot;top&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">plot_type</span> <span class="o">==</span> <span class="s2">&quot;dependence&quot;</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">target_columns</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_tdp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">))</span>

        <span class="k">elif</span> <span class="n">plot_type</span> <span class="o">==</span> <span class="s2">&quot;sample&quot;</span><span class="p">:</span>
            <span class="c1"># Ensure the correct samples_index type</span>
            <span class="k">if</span> <span class="n">samples_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For sample plot, you need to specify the samples_index be plotted plot&quot;</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples_index</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples_index</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">samples_index</span> <span class="o">=</span> <span class="p">[</span><span class="n">samples_index</span><span class="p">]</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">samples_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples_index</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;sample_index must be one of the following: int, str, list or pd.Index&quot;</span><span class="p">))</span>

            <span class="n">ax</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">sample_index</span> <span class="ow">in</span> <span class="n">samples_index</span><span class="p">:</span>
                <span class="n">sample_loc</span> <span class="o">=</span> <span class="n">target_X</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="n">sample_index</span><span class="p">)</span>

                <span class="n">waterfall_legacy</span><span class="p">(</span>
                    <span class="n">target_expected_value</span><span class="p">,</span>
                    <span class="n">target_shap_values</span><span class="p">[</span><span class="n">sample_loc</span><span class="p">,</span> <span class="p">:],</span>
                    <span class="n">target_X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">sample_index</span><span class="p">],</span>
                    <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">plot_title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SHAP Sample Explanation of </span><span class="si">{</span><span class="n">target_set</span><span class="si">}</span><span class="s2"> sample for index=</span><span class="si">{</span><span class="n">sample_index</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">current_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
                <span class="n">current_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">plot_title</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_ax</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Wrong plot type, select from &#39;importance&#39;, &#39;summary&#39;, or &#39;dependence&#39;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.model_interpret.ShapModelInterpreter.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Initializes the class.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
                  <code>classifier or regressor</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model fitted on X_train.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scoring</code></td>
            <td>
                  <code>string or <a class="autorefs autorefs-internal" title="probatus.utils.Scorer" href="utils.html#probatus.utils.scoring.Scorer">Scorer</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Metric for which the model performance is calculated. It can be either a metric name  aligned with
predefined classification scorers names in sklearn
(<a href="https://scikit-learn.org/stable/modules/model_evaluation.html">link</a>).
Another option is using probatus.utils.Scorer to define a custom metric.</p>
              </div>
            </td>
            <td>
                  <code>&#39;roc_auc&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>verbose</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Controls verbosity of the output:</p>
<ul>
<li>0 - neither prints nor warnings are shown</li>
<li>1 - only most important warnings</li>
<li>2 - shows all prints and all warnings.</li>
</ul>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>random_state</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random state set for the nr of samples. If it is None, the results will not be reproducible. For
reproducible results set it to an integer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/model_interpret.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the class.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (classifier or regressor):</span>
<span class="sd">            Model fitted on X_train.</span>

<span class="sd">        scoring (string or probatus.utils.Scorer, optional):</span>
<span class="sd">            Metric for which the model performance is calculated. It can be either a metric name  aligned with</span>
<span class="sd">            predefined classification scorers names in sklearn</span>
<span class="sd">            ([link](https://scikit-learn.org/stable/modules/model_evaluation.html)).</span>
<span class="sd">            Another option is using probatus.utils.Scorer to define a custom metric.</span>

<span class="sd">        verbose (int, optional):</span>
<span class="sd">            Controls verbosity of the output:</span>

<span class="sd">            - 0 - neither prints nor warnings are shown</span>
<span class="sd">            - 1 - only most important warnings</span>
<span class="sd">            - 2 - shows all prints and all warnings.</span>

<span class="sd">        random_state (int, optional):</span>
<span class="sd">            Random state set for the nr of samples. If it is None, the results will not be reproducible. For</span>
<span class="sd">            reproducible results set it to an integer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">get_single_scorer</span><span class="p">(</span><span class="n">scoring</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.model_interpret.ShapModelInterpreter.compute" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Computes the DataFrame that presents the importance of each feature.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>return_scores</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag indicating whether the method should return the train and test score of the model, together with
the model interpretation report. If true, the output of this method is a tuple of DataFrame, float,
float.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>shap_variance_penalty_factor</code></td>
            <td>
                  <code>int or float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Apply aggregation penalty when computing average of shap values for a given feature.
Results in a preference for features that have smaller standard deviation of shap
values (more coherent shap importance). Recommend value 0.5 - 1.0.
Formula: penalized_shap_mean = (mean_shap - (std_shap * shap_variance_penalty_factor))</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span> or tuple(<span title="pandas.DataFrame">DataFrame</span>, float, float)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataframe with SHAP feature importance, or tuple containing the dataframe, train and test scores of the
model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/model_interpret.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the DataFrame that presents the importance of each feature.</span>

<span class="sd">    Args:</span>
<span class="sd">        return_scores (bool, optional):</span>
<span class="sd">            Flag indicating whether the method should return the train and test score of the model, together with</span>
<span class="sd">            the model interpretation report. If true, the output of this method is a tuple of DataFrame, float,</span>
<span class="sd">            float.</span>

<span class="sd">        shap_variance_penalty_factor (int or float, optional):</span>
<span class="sd">            Apply aggregation penalty when computing average of shap values for a given feature.</span>
<span class="sd">            Results in a preference for features that have smaller standard deviation of shap</span>
<span class="sd">            values (more coherent shap importance). Recommend value 0.5 - 1.0.</span>
<span class="sd">            Formula: penalized_shap_mean = (mean_shap - (std_shap * shap_variance_penalty_factor))</span>

<span class="sd">    Returns:</span>
<span class="sd">        (pd.DataFrame or tuple(pd.DataFrame, float, float)):</span>
<span class="sd">            Dataframe with SHAP feature importance, or tuple containing the dataframe, train and test scores of the</span>
<span class="sd">            model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>

    <span class="c1"># Compute SHAP importance</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">importance_df_train</span> <span class="o">=</span> <span class="n">calculate_shap_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_train</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
        <span class="n">output_columns_suffix</span><span class="o">=</span><span class="s2">&quot;_train&quot;</span><span class="p">,</span>
        <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="n">shap_variance_penalty_factor</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">importance_df_test</span> <span class="o">=</span> <span class="n">calculate_shap_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
        <span class="n">output_columns_suffix</span><span class="o">=</span><span class="s2">&quot;_test&quot;</span><span class="p">,</span>
        <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="n">shap_variance_penalty_factor</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Concatenate the train and test, sort by test set importance and reorder the columns</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">importance_df_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">importance_df_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
        <span class="s2">&quot;mean_abs_shap_value_test&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)[</span>
        <span class="p">[</span>
            <span class="s2">&quot;mean_abs_shap_value_test&quot;</span><span class="p">,</span>
            <span class="s2">&quot;mean_abs_shap_value_train&quot;</span><span class="p">,</span>
            <span class="s2">&quot;mean_shap_value_test&quot;</span><span class="p">,</span>
            <span class="s2">&quot;mean_shap_value_train&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">]</span>

    <span class="k">if</span> <span class="n">return_scores</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">importance_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">importance_df</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.model_interpret.ShapModelInterpreter.fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Fits the object and calculates the shap values for the provided datasets.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X_train</code></td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataframe containing training data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X_test</code></td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataframe containing test data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_train</code></td>
            <td>
                  <code><span title="pandas.Series">Series</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Series of labels for train data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_test</code></td>
            <td>
                  <code><span title="pandas.Series">Series</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Series of labels for test data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>column_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names e.g. ['neg', 'pos']. If none, the default ['Negative Class', 'Positive Class'] are
used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**shap_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>keyword arguments passed to
<a href="https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer">shap.Explainer</a>.
It also enables <code>approximate</code> and <code>check_additivity</code> parameters, passed while calculating SHAP values.
The <code>approximate=True</code> causes less accurate, but faster SHAP values calculation, while
<code>check_additivity=False</code> disables the additivity check inside SHAP.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/model_interpret.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fits the object and calculates the shap values for the provided datasets.</span>

<span class="sd">    Args:</span>
<span class="sd">        X_train (pd.DataFrame):</span>
<span class="sd">            Dataframe containing training data.</span>

<span class="sd">        X_test (pd.DataFrame):</span>
<span class="sd">            Dataframe containing test data.</span>

<span class="sd">        y_train (pd.Series):</span>
<span class="sd">            Series of labels for train data.</span>

<span class="sd">        y_test (pd.Series):</span>
<span class="sd">            Series of labels for test data.</span>

<span class="sd">        column_names (None, or list of str, optional):</span>
<span class="sd">            List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</span>

<span class="sd">        class_names (None, or list of str, optional):</span>
<span class="sd">            List of class names e.g. [&#39;neg&#39;, &#39;pos&#39;]. If none, the default [&#39;Negative Class&#39;, &#39;Positive Class&#39;] are</span>
<span class="sd">            used.</span>

<span class="sd">        **shap_kwargs:</span>
<span class="sd">            keyword arguments passed to</span>
<span class="sd">            [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">            It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">            The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">            `check_additivity=False` disables the additivity check inside SHAP.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">preprocess_labels</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_name</span><span class="o">=</span><span class="s2">&quot;y_train&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">preprocess_labels</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_name</span><span class="o">=</span><span class="s2">&quot;y_test&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

    <span class="c1"># Set class names</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">class_names</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Negative Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Positive Class&quot;</span><span class="p">]</span>

    <span class="c1"># Calculate Metrics</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Train </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_score</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Test </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_score</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
    <span class="p">)</span>

    <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_train</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expected_value_train</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tdp_train</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prep_shap_related_variables</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span>
        <span class="n">column_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
        <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expected_value_test</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tdp_test</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prep_shap_related_variables</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">,</span>
        <span class="n">column_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
        <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.model_interpret.ShapModelInterpreter.fit_compute" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fit_compute</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Fits the object and calculates the shap values for the provided datasets.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X_train</code></td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataframe containing training data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X_test</code></td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataframe containing test data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_train</code></td>
            <td>
                  <code><span title="pandas.Series">Series</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Series of labels for train data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_test</code></td>
            <td>
                  <code><span title="pandas.Series">Series</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Series of labels for test data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>column_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of feature names for the dataset.
If None, then column names from the X_train dataframe are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names e.g. ['neg', 'pos'].
If none, the default ['Negative Class', 'Positive Class'] are
used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>return_scores</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag indicating whether the method should return
the train and test score of the model,
together with the model interpretation report. If true,
the output of this method is a tuple of DataFrame, float,
float.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>shap_variance_penalty_factor</code></td>
            <td>
                  <code>int or float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Apply aggregation penalty when computing average of shap values for a given feature.
Results in a preference for features that have smaller standard deviation of shap
values (more coherent shap importance). Recommend value 0.5 - 1.0.
Formula: penalized_shap_mean = (mean_shap - (std_shap * shap_variance_penalty_factor))</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**shap_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>keyword arguments passed to
<a href="https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer">shap.Explainer</a>.
It also enables <code>approximate</code> and <code>check_additivity</code> parameters, passed while calculating SHAP values.
The <code>approximate=True</code> causes less accurate, but faster SHAP values calculation, while
<code>check_additivity=False</code> disables the additivity check inside SHAP.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span> or tuple(<span title="pandas.DataFrame">DataFrame</span>, float, float)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataframe with SHAP feature importance, or tuple containing the dataframe, train and test scores of the
model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/model_interpret.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit_compute</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fits the object and calculates the shap values for the provided datasets.</span>

<span class="sd">    Args:</span>
<span class="sd">        X_train (pd.DataFrame):</span>
<span class="sd">            Dataframe containing training data.</span>

<span class="sd">        X_test (pd.DataFrame):</span>
<span class="sd">            Dataframe containing test data.</span>

<span class="sd">        y_train (pd.Series):</span>
<span class="sd">            Series of labels for train data.</span>

<span class="sd">        y_test (pd.Series):</span>
<span class="sd">            Series of labels for test data.</span>

<span class="sd">        column_names (None, or list of str, optional):</span>
<span class="sd">            List of feature names for the dataset.</span>
<span class="sd">            If None, then column names from the X_train dataframe are used.</span>

<span class="sd">        class_names (None, or list of str, optional):</span>
<span class="sd">            List of class names e.g. [&#39;neg&#39;, &#39;pos&#39;].</span>
<span class="sd">            If none, the default [&#39;Negative Class&#39;, &#39;Positive Class&#39;] are</span>
<span class="sd">            used.</span>

<span class="sd">        return_scores (bool, optional):</span>
<span class="sd">            Flag indicating whether the method should return</span>
<span class="sd">            the train and test score of the model,</span>
<span class="sd">            together with the model interpretation report. If true,</span>
<span class="sd">            the output of this method is a tuple of DataFrame, float,</span>
<span class="sd">            float.</span>

<span class="sd">        shap_variance_penalty_factor (int or float, optional):</span>
<span class="sd">            Apply aggregation penalty when computing average of shap values for a given feature.</span>
<span class="sd">            Results in a preference for features that have smaller standard deviation of shap</span>
<span class="sd">            values (more coherent shap importance). Recommend value 0.5 - 1.0.</span>
<span class="sd">            Formula: penalized_shap_mean = (mean_shap - (std_shap * shap_variance_penalty_factor))</span>

<span class="sd">        **shap_kwargs:</span>
<span class="sd">            keyword arguments passed to</span>
<span class="sd">            [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">            It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">            The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">            `check_additivity=False` disables the additivity check inside SHAP.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (pd.DataFrame or tuple(pd.DataFrame, float, float)):</span>
<span class="sd">            Dataframe with SHAP feature importance, or tuple containing the dataframe, train and test scores of the</span>
<span class="sd">            model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
        <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span>
        <span class="n">y_train</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
        <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
        <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
        <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">return_scores</span><span class="o">=</span><span class="n">return_scores</span><span class="p">,</span> <span class="n">shap_variance_penalty_factor</span><span class="o">=</span><span class="n">shap_variance_penalty_factor</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.model_interpret.ShapModelInterpreter.plot" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot</span><span class="p">(</span><span class="n">plot_type</span><span class="p">,</span> <span class="n">target_set</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">target_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">samples_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Plots the appropriate SHAP plot.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>plot_type</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One of the following:</p>
<ul>
<li><code>'importance'</code>: Feature importance plot, SHAP bar summary plot</li>
<li><code>'summary'</code>: SHAP Summary plot</li>
<li><code>'dependence'</code>: Dependence plot for each feature</li>
<li><code>'sample'</code>: Explanation of a given sample in the test data</li>
</ul>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>target_set</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The set for which the plot should be generated, either <code>train</code> or <code>test</code> set. We recommend using test
set, because it is not biased by model training. The train set plots are mainly used to compare with the
test set plots, whether there are significant differences, which indicate shift in data distribution.</p>
              </div>
            </td>
            <td>
                  <code>&#39;test&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>target_columns</code></td>
            <td>
                  <code>None, str or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of features names, for which the plots should be generated. If None, all features will be plotted.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>samples_index</code></td>
            <td>
                  <code>(None, int, list or <span title="pandas.Index">Index</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Index of samples to be explained if the <code>plot_type=sample</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>show</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,
when you want to edit the returned axis, before showing it.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**plot_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments passed to the plot method. For 'importance' and 'summary' plot_type, the kwargs are
passed to shap.summary_plot, for 'dependence' plot_type, they are passed to
probatus.interpret.DependencePlotter.plot method.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="matplotlib.axes">axes</span> or list(<span title="matplotlib.axes">axes</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An Axes with the plot, or list of axes when multiple plots are returned.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/model_interpret.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plot_type</span><span class="p">,</span> <span class="n">target_set</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">target_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">samples_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots the appropriate SHAP plot.</span>

<span class="sd">    Args:</span>
<span class="sd">        plot_type (str):</span>
<span class="sd">            One of the following:</span>

<span class="sd">            - `&#39;importance&#39;`: Feature importance plot, SHAP bar summary plot</span>
<span class="sd">            - `&#39;summary&#39;`: SHAP Summary plot</span>
<span class="sd">            - `&#39;dependence&#39;`: Dependence plot for each feature</span>
<span class="sd">            - `&#39;sample&#39;`: Explanation of a given sample in the test data</span>

<span class="sd">        target_set (str, optional):</span>
<span class="sd">            The set for which the plot should be generated, either `train` or `test` set. We recommend using test</span>
<span class="sd">            set, because it is not biased by model training. The train set plots are mainly used to compare with the</span>
<span class="sd">            test set plots, whether there are significant differences, which indicate shift in data distribution.</span>

<span class="sd">        target_columns (None, str or list of str, optional):</span>
<span class="sd">            List of features names, for which the plots should be generated. If None, all features will be plotted.</span>

<span class="sd">        samples_index (None, int, list or pd.Index, optional):</span>
<span class="sd">            Index of samples to be explained if the `plot_type=sample`.</span>

<span class="sd">        show (bool, optional):</span>
<span class="sd">            If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,</span>
<span class="sd">            when you want to edit the returned axis, before showing it.</span>

<span class="sd">        **plot_kwargs:</span>
<span class="sd">            Keyword arguments passed to the plot method. For &#39;importance&#39; and &#39;summary&#39; plot_type, the kwargs are</span>
<span class="sd">            passed to shap.summary_plot, for &#39;dependence&#39; plot_type, they are passed to</span>
<span class="sd">            probatus.interpret.DependencePlotter.plot method.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (matplotlib.axes or list(matplotlib.axes)):</span>
<span class="sd">            An Axes with the plot, or list of axes when multiple plots are returned.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Choose correct columns</span>
    <span class="k">if</span> <span class="n">target_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">target_columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span>

    <span class="n">target_columns</span> <span class="o">=</span> <span class="n">assure_list_of_strings</span><span class="p">(</span><span class="n">target_columns</span><span class="p">,</span> <span class="s2">&quot;target_columns&quot;</span><span class="p">)</span>
    <span class="n">target_columns_indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">target_column</span><span class="p">)</span> <span class="k">for</span> <span class="n">target_column</span> <span class="ow">in</span> <span class="n">target_columns</span><span class="p">]</span>

    <span class="c1"># Choose the correct dataset</span>
    <span class="k">if</span> <span class="n">target_set</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
        <span class="n">target_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span>
        <span class="n">target_shap_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span>
        <span class="n">target_tdp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tdp_test</span>
        <span class="n">target_expected_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected_value_test</span>
    <span class="k">elif</span> <span class="n">target_set</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
        <span class="n">target_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span>
        <span class="n">target_shap_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_train</span>
        <span class="n">target_tdp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tdp_train</span>
        <span class="n">target_expected_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected_value_train</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The target_set parameter can be either &quot;train&quot; or &quot;test&quot;.&#39;</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">plot_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">]:</span>
        <span class="n">target_X</span> <span class="o">=</span> <span class="n">target_X</span><span class="p">[</span><span class="n">target_columns</span><span class="p">]</span>
        <span class="n">target_shap_values</span> <span class="o">=</span> <span class="n">target_shap_values</span><span class="p">[:,</span> <span class="n">target_columns_indices</span><span class="p">]</span>
        <span class="c1"># Set summary plot settings</span>
        <span class="k">if</span> <span class="n">plot_type</span> <span class="o">==</span> <span class="s2">&quot;importance&quot;</span><span class="p">:</span>
            <span class="n">plot_type</span> <span class="o">=</span> <span class="s2">&quot;bar&quot;</span>
            <span class="n">plot_title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SHAP Feature Importance for </span><span class="si">{</span><span class="n">target_set</span><span class="si">}</span><span class="s2"> set&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plot_type</span> <span class="o">=</span> <span class="s2">&quot;dot&quot;</span>
            <span class="n">plot_title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SHAP Summary plot for </span><span class="si">{</span><span class="n">target_set</span><span class="si">}</span><span class="s2"> set&quot;</span>

        <span class="n">summary_plot</span><span class="p">(</span>
            <span class="n">target_shap_values</span><span class="p">,</span>
            <span class="n">target_X</span><span class="p">,</span>
            <span class="n">plot_type</span><span class="o">=</span><span class="n">plot_type</span><span class="p">,</span>
            <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
            <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">plot_title</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span><span class="p">,</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">),</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
            <span class="n">xycoords</span><span class="o">=</span><span class="s2">&quot;axes fraction&quot;</span><span class="p">,</span>
            <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
            <span class="n">va</span><span class="o">=</span><span class="s2">&quot;top&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">plot_type</span> <span class="o">==</span> <span class="s2">&quot;dependence&quot;</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">target_columns</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_tdp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">))</span>

    <span class="k">elif</span> <span class="n">plot_type</span> <span class="o">==</span> <span class="s2">&quot;sample&quot;</span><span class="p">:</span>
        <span class="c1"># Ensure the correct samples_index type</span>
        <span class="k">if</span> <span class="n">samples_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For sample plot, you need to specify the samples_index be plotted plot&quot;</span><span class="p">))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples_index</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples_index</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">samples_index</span> <span class="o">=</span> <span class="p">[</span><span class="n">samples_index</span><span class="p">]</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">samples_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">samples_index</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;sample_index must be one of the following: int, str, list or pd.Index&quot;</span><span class="p">))</span>

        <span class="n">ax</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">sample_index</span> <span class="ow">in</span> <span class="n">samples_index</span><span class="p">:</span>
            <span class="n">sample_loc</span> <span class="o">=</span> <span class="n">target_X</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_loc</span><span class="p">(</span><span class="n">sample_index</span><span class="p">)</span>

            <span class="n">waterfall_legacy</span><span class="p">(</span>
                <span class="n">target_expected_value</span><span class="p">,</span>
                <span class="n">target_shap_values</span><span class="p">[</span><span class="n">sample_loc</span><span class="p">,</span> <span class="p">:],</span>
                <span class="n">target_X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">sample_index</span><span class="p">],</span>
                <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">plot_title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SHAP Sample Explanation of </span><span class="si">{</span><span class="n">target_set</span><span class="si">}</span><span class="s2"> sample for index=</span><span class="si">{</span><span class="n">sample_index</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">current_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
            <span class="n">current_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">plot_title</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_ax</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Wrong plot type, select from &#39;importance&#39;, &#39;summary&#39;, or &#39;dependence&#39;&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<a id="probatus.interpret.shap_dependence"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="probatus.interpret.shap_dependence.DependencePlotter" class="doc doc-heading">
            <code>DependencePlotter</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="probatus.utils.BaseFitComputePlotClass">BaseFitComputePlotClass</span></code></p>


      <p>Plotter used to plot SHAP dependence plot together with the target rates.</p>
<p>Currently it supports tree-based and linear models.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>classifier for which interpretation is done.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
      <p>Example:</p>
<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from probatus.interpret import DependencePlotter

X, y = make_classification(n_samples=15, n_features=3, n_informative=3, n_redundant=0, random_state=42)
model = RandomForestClassifier().fit(X, y)
bdp = DependencePlotter(model)
shap_values = bdp.fit_compute(X, y)

bdp.plot(feature=2)
</code></pre>
<p><img src="../img/model_interpret_dep.png"/></p>

              <details class="quote">
                <summary>Source code in <code>probatus/interpret/shap_dependence.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DependencePlotter</span><span class="p">(</span><span class="n">BaseFitComputePlotClass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plotter used to plot SHAP dependence plot together with the target rates.</span>

<span class="sd">    Currently it supports tree-based and linear models.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: classifier for which interpretation is done.</span>

<span class="sd">    Example:</span>
<span class="sd">    ```python</span>
<span class="sd">    from sklearn.datasets import make_classification</span>
<span class="sd">    from sklearn.ensemble import RandomForestClassifier</span>
<span class="sd">    from probatus.interpret import DependencePlotter</span>

<span class="sd">    X, y = make_classification(n_samples=15, n_features=3, n_informative=3, n_redundant=0, random_state=42)</span>
<span class="sd">    model = RandomForestClassifier().fit(X, y)</span>
<span class="sd">    bdp = DependencePlotter(model)</span>
<span class="sd">    shap_values = bdp.fit_compute(X, y)</span>

<span class="sd">    bdp.plot(feature=2)</span>
<span class="sd">    ```</span>

<span class="sd">    &lt;img src=&quot;../img/model_interpret_dep.png&quot;/&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the class.</span>

<span class="sd">        Args:</span>
<span class="sd">            model (model object):</span>
<span class="sd">                regression or classification model or pipeline.</span>

<span class="sd">            verbose (int, optional):</span>
<span class="sd">                Controls verbosity of the output:</span>

<span class="sd">                - 0 - neither prints nor warnings are shown</span>
<span class="sd">                - 1 - only most important warnings</span>
<span class="sd">                - 2 - shows all prints and all warnings.</span>

<span class="sd">            random_state (int, optional):</span>
<span class="sd">                Random state set for the nr of samples. If it is None, the results will not be reproducible. For</span>
<span class="sd">                reproducible results set it to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Represent string method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Shap dependence plotter for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precalc_shap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the plotter to the model and data by computing the shap values.</span>

<span class="sd">        If the shap_values are passed, they do not need to be computed.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (pd.DataFrame): input variables.</span>

<span class="sd">            y (pd.Series): target variable.</span>

<span class="sd">            column_names (None, or list of str, optional):</span>
<span class="sd">                List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</span>

<span class="sd">            class_names (None, or list of str, optional):</span>
<span class="sd">                List of class names e.g. [&#39;neg&#39;, &#39;pos&#39;]. If none, the default [&#39;Negative Class&#39;, &#39;Positive Class&#39;] are</span>
<span class="sd">                used.</span>

<span class="sd">            precalc_shap (Optional, None or np.array):</span>
<span class="sd">                Precalculated shap values, If provided they don&#39;t need to be computed.</span>

<span class="sd">            **shap_kwargs:</span>
<span class="sd">                keyword arguments passed to</span>
<span class="sd">                [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">                It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">                The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">                `check_additivity=False` disables the additivity check inside SHAP.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">preprocess_labels</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="c1"># Set class names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">class_names</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Negative Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Positive Class&quot;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">shap_vals_df</span> <span class="o">=</span> <span class="n">shap_to_df</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="n">precalc_shap</span><span class="o">=</span><span class="n">precalc_shap</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the report returned to the user, namely the SHAP values generated on the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (pd.DataFrame):</span>
<span class="sd">                SHAP Values for X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_vals_df</span>

    <span class="k">def</span> <span class="nf">fit_compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precalc_shap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the plotter to the model and data by computing the shap values.</span>

<span class="sd">        If the shap_values are passed, they do not need to be computed</span>

<span class="sd">        Args:</span>
<span class="sd">            X (pd.DataFrame):</span>
<span class="sd">                Provided dataset.</span>

<span class="sd">            y (pd.Series):</span>
<span class="sd">                Labels for X.</span>

<span class="sd">            column_names (None, or list of str, optional):</span>
<span class="sd">                List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</span>

<span class="sd">            class_names (None, or list of str, optional):</span>
<span class="sd">                List of class names e.g. [&#39;neg&#39;, &#39;pos&#39;]. If none, the default [&#39;Negative Class&#39;, &#39;Positive Class&#39;] are</span>
<span class="sd">                used.</span>

<span class="sd">            precalc_shap (Optional, None or np.array):</span>
<span class="sd">                Precalculated shap values, If provided they don&#39;t need to be computed.</span>

<span class="sd">            **shap_kwargs:</span>
<span class="sd">                keyword arguments passed to</span>
<span class="sd">                [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">                It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">                The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">                `check_additivity=False` disables the additivity check inside SHAP.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (pd.DataFrame):</span>
<span class="sd">                SHAP Values for X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span> <span class="n">precalc_shap</span><span class="o">=</span><span class="n">precalc_shap</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feature</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">min_q</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">max_q</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the shap values for data points for a given feature, as well as the target rate and values distribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            feature (str or int):</span>
<span class="sd">                Feature name of the feature to be analyzed.</span>

<span class="sd">            figsize ((float, float), optional):</span>
<span class="sd">                Tuple specifying size (width, height) of resulting figure in inches.</span>

<span class="sd">            bins (int or list[float]):</span>
<span class="sd">                Number of bins or boundaries of bins (supplied in list) for target-rate plot.</span>

<span class="sd">            show (bool, optional):</span>
<span class="sd">                If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,</span>
<span class="sd">                when you want to edit the returned axis, before showing it.</span>

<span class="sd">            min_q (float, optional):</span>
<span class="sd">                Optional minimum quantile from which to consider values, used for plotting under outliers.</span>

<span class="sd">            max_q (float, optional):</span>
<span class="sd">                Optional maximum quantile until which data points are considered, used for plotting under outliers.</span>

<span class="sd">            alpha (float, optional):</span>
<span class="sd">                Optional alpha blending value, between 0 (transparent) and 1 (opaque).</span>

<span class="sd">        Returns</span>
<span class="sd">            (list(matplotlib.axes)):</span>
<span class="sd">                List of axes that include the plots.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">min_q</span> <span class="o">&gt;=</span> <span class="n">max_q</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;min_q must be smaller than max_q&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Feature not recognized&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;alpha must be a float value between 0 and 1&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">min_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">min_q</span><span class="p">,</span> <span class="n">max_q</span><span class="p">,</span> <span class="n">alpha</span>

        <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">rowspan</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">ax2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dependence_plot</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_rate_plot</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>

        <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">ax1</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_dependence_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots shap values for data points with respect to specified feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            feature (str or int):</span>
<span class="sd">                Feature for which dependence plot is to be created.</span>

<span class="sd">            ax (matplotlib.pyplot.axes, optional):</span>
<span class="sd">                Optional axis on which to draw plot.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (matplotlib.pyplot.axes):</span>
<span class="sd">                Axes on which plot is drawn.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">shap_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_X_y_shap_with_q_cut</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">shap_val</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightblue&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">shap_val</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;darkred&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Shap value&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dependence plot for </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> feature&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">ax</span>

    <span class="k">def</span> <span class="nf">_target_rate_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the distributions of the specific features, as well as the target rate as function of the feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            feature (str or int):</span>
<span class="sd">                Feature for which to create target rate plot.</span>

<span class="sd">            bins (int or list[float]), optional:</span>
<span class="sd">                Number of bins or boundaries of desired bins in list.</span>

<span class="sd">            ax (matplotlib.pyplot.axes, optional):</span>
<span class="sd">                Optional axis on which to draw plot.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (list[float], matplotlib.pyplot.axes, float):</span>
<span class="sd">                Tuple of boundaries of bins used, axis on which plot is drawn, total ratio of target (positive over</span>
<span class="sd">                negative).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">shap_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_X_y_shap_with_q_cut</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">)</span>

        <span class="c1"># Create bins if not explicitly supplied</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">simple_binner</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s2">&quot;ordinal&quot;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="n">simple_binner</span><span class="o">.</span><span class="n">bin_edges_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="c1"># Determine bin for datapoints</span>
        <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>
        <span class="c1"># Create dataframe with binned data</span>
        <span class="n">dfs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">feature</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;bin_index&quot;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">index</span><span class="p">)})</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span>
            <span class="s2">&quot;bin_index&quot;</span><span class="p">,</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># Extract target ratio and mean feature value</span>
        <span class="n">target_ratio</span> <span class="o">=</span> <span class="n">dfs</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">x_vals</span> <span class="o">=</span> <span class="n">dfs</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Transform the first and last bin to work with plt.hist method</span>
        <span class="k">if</span> <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

        <span class="c1"># Plot target rate</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Counts&quot;</span><span class="p">)</span>
        <span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">target_ratio</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Target rate&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> feature values&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">bins</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">target_ratio</span>

    <span class="k">def</span> <span class="nf">_get_X_y_shap_with_q_cut</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extracts all X, y pairs and shap values that fall within defined quantiles of the feature.</span>

<span class="sd">        Args:</span>
<span class="sd">            feature (str): feature to return values for</span>

<span class="sd">        Returns:</span>
<span class="sd">            x (pd.Series): selected datapoints</span>
<span class="sd">            y (pd.Series): target values of selected datapoints</span>
<span class="sd">            shap_val (pd.Series): shap values of selected datapoints</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Feature not found in data&quot;</span><span class="p">)</span>

        <span class="c1"># Prepare arrays</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>
        <span class="n">shap_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_vals_df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>

        <span class="c1"># Determine quantile ranges</span>
        <span class="n">x_min</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_q</span><span class="p">)</span>
        <span class="n">x_max</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_q</span><span class="p">)</span>

        <span class="c1"># Create filter</span>
        <span class="nb">filter</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="n">x_max</span><span class="p">)</span>

        <span class="c1"># Filter and return terms</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="nb">filter</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="nb">filter</span><span class="p">],</span> <span class="n">shap_val</span><span class="p">[</span><span class="nb">filter</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.shap_dependence.DependencePlotter.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Initializes the class.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
                  <code>model object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>regression or classification model or pipeline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>verbose</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Controls verbosity of the output:</p>
<ul>
<li>0 - neither prints nor warnings are shown</li>
<li>1 - only most important warnings</li>
<li>2 - shows all prints and all warnings.</li>
</ul>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>random_state</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random state set for the nr of samples. If it is None, the results will not be reproducible. For
reproducible results set it to an integer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/shap_dependence.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the class.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (model object):</span>
<span class="sd">            regression or classification model or pipeline.</span>

<span class="sd">        verbose (int, optional):</span>
<span class="sd">            Controls verbosity of the output:</span>

<span class="sd">            - 0 - neither prints nor warnings are shown</span>
<span class="sd">            - 1 - only most important warnings</span>
<span class="sd">            - 2 - shows all prints and all warnings.</span>

<span class="sd">        random_state (int, optional):</span>
<span class="sd">            Random state set for the nr of samples. If it is None, the results will not be reproducible. For</span>
<span class="sd">            reproducible results set it to an integer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.shap_dependence.DependencePlotter.__repr__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__repr__</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Represent string method.</p>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/shap_dependence.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represent string method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Shap dependence plotter for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.shap_dependence.DependencePlotter.compute" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Computes the report returned to the user, namely the SHAP values generated on the dataset.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>SHAP Values for X.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/shap_dependence.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the report returned to the user, namely the SHAP values generated on the dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (pd.DataFrame):</span>
<span class="sd">            SHAP Values for X.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_vals_df</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.shap_dependence.DependencePlotter.fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precalc_shap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Fits the plotter to the model and data by computing the shap values.</p>
<p>If the shap_values are passed, they do not need to be computed.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>input variables.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
                  <code><span title="pandas.Series">Series</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>target variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>column_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names e.g. ['neg', 'pos']. If none, the default ['Negative Class', 'Positive Class'] are
used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>precalc_shap</code></td>
            <td>
                  <code>(Optional, None or <span title="numpy.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Precalculated shap values, If provided they don't need to be computed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**shap_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>keyword arguments passed to
<a href="https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer">shap.Explainer</a>.
It also enables <code>approximate</code> and <code>check_additivity</code> parameters, passed while calculating SHAP values.
The <code>approximate=True</code> causes less accurate, but faster SHAP values calculation, while
<code>check_additivity=False</code> disables the additivity check inside SHAP.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/shap_dependence.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precalc_shap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fits the plotter to the model and data by computing the shap values.</span>

<span class="sd">    If the shap_values are passed, they do not need to be computed.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (pd.DataFrame): input variables.</span>

<span class="sd">        y (pd.Series): target variable.</span>

<span class="sd">        column_names (None, or list of str, optional):</span>
<span class="sd">            List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</span>

<span class="sd">        class_names (None, or list of str, optional):</span>
<span class="sd">            List of class names e.g. [&#39;neg&#39;, &#39;pos&#39;]. If none, the default [&#39;Negative Class&#39;, &#39;Positive Class&#39;] are</span>
<span class="sd">            used.</span>

<span class="sd">        precalc_shap (Optional, None or np.array):</span>
<span class="sd">            Precalculated shap values, If provided they don&#39;t need to be computed.</span>

<span class="sd">        **shap_kwargs:</span>
<span class="sd">            keyword arguments passed to</span>
<span class="sd">            [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">            It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">            The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">            `check_additivity=False` disables the additivity check inside SHAP.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">preprocess_labels</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

    <span class="c1"># Set class names</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">class_names</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Negative Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Positive Class&quot;</span><span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">shap_vals_df</span> <span class="o">=</span> <span class="n">shap_to_df</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
        <span class="n">precalc_shap</span><span class="o">=</span><span class="n">precalc_shap</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
        <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.shap_dependence.DependencePlotter.fit_compute" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fit_compute</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precalc_shap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Fits the plotter to the model and data by computing the shap values.</p>
<p>If the shap_values are passed, they do not need to be computed</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Provided dataset.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y</code></td>
            <td>
                  <code><span title="pandas.Series">Series</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Labels for X.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>column_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names e.g. ['neg', 'pos']. If none, the default ['Negative Class', 'Positive Class'] are
used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>precalc_shap</code></td>
            <td>
                  <code>(Optional, None or <span title="numpy.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Precalculated shap values, If provided they don't need to be computed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**shap_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>keyword arguments passed to
<a href="https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer">shap.Explainer</a>.
It also enables <code>approximate</code> and <code>check_additivity</code> parameters, passed while calculating SHAP values.
The <code>approximate=True</code> causes less accurate, but faster SHAP values calculation, while
<code>check_additivity=False</code> disables the additivity check inside SHAP.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>SHAP Values for X.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/shap_dependence.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit_compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precalc_shap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fits the plotter to the model and data by computing the shap values.</span>

<span class="sd">    If the shap_values are passed, they do not need to be computed</span>

<span class="sd">    Args:</span>
<span class="sd">        X (pd.DataFrame):</span>
<span class="sd">            Provided dataset.</span>

<span class="sd">        y (pd.Series):</span>
<span class="sd">            Labels for X.</span>

<span class="sd">        column_names (None, or list of str, optional):</span>
<span class="sd">            List of feature names for the dataset. If None, then column names from the X_train dataframe are used.</span>

<span class="sd">        class_names (None, or list of str, optional):</span>
<span class="sd">            List of class names e.g. [&#39;neg&#39;, &#39;pos&#39;]. If none, the default [&#39;Negative Class&#39;, &#39;Positive Class&#39;] are</span>
<span class="sd">            used.</span>

<span class="sd">        precalc_shap (Optional, None or np.array):</span>
<span class="sd">            Precalculated shap values, If provided they don&#39;t need to be computed.</span>

<span class="sd">        **shap_kwargs:</span>
<span class="sd">            keyword arguments passed to</span>
<span class="sd">            [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">            It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">            The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">            `check_additivity=False` disables the additivity check inside SHAP.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (pd.DataFrame):</span>
<span class="sd">            SHAP Values for X.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span> <span class="n">precalc_shap</span><span class="o">=</span><span class="n">precalc_shap</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.interpret.shap_dependence.DependencePlotter.plot" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">min_q</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_q</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Plots the shap values for data points for a given feature, as well as the target rate and values distribution.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>feature</code></td>
            <td>
                  <code>str or int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Feature name of the feature to be analyzed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>figsize</code></td>
            <td>
                  <code>float, float)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple specifying size (width, height) of resulting figure in inches.</p>
              </div>
            </td>
            <td>
                  <code>(15, 10)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bins</code></td>
            <td>
                  <code>int or list[float]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of bins or boundaries of bins (supplied in list) for target-rate plot.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>show</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,
when you want to edit the returned axis, before showing it.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>min_q</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional minimum quantile from which to consider values, used for plotting under outliers.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>max_q</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional maximum quantile until which data points are considered, used for plotting under outliers.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>alpha</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional alpha blending value, between 0 (transparent) and 1 (opaque).</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
      </tbody>
    </table>
      <p>Returns
    (list(matplotlib.axes)):
        List of axes that include the plots.</p>

            <details class="quote">
              <summary>Source code in <code>probatus/interpret/shap_dependence.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">feature</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">min_q</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">max_q</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots the shap values for data points for a given feature, as well as the target rate and values distribution.</span>

<span class="sd">    Args:</span>
<span class="sd">        feature (str or int):</span>
<span class="sd">            Feature name of the feature to be analyzed.</span>

<span class="sd">        figsize ((float, float), optional):</span>
<span class="sd">            Tuple specifying size (width, height) of resulting figure in inches.</span>

<span class="sd">        bins (int or list[float]):</span>
<span class="sd">            Number of bins or boundaries of bins (supplied in list) for target-rate plot.</span>

<span class="sd">        show (bool, optional):</span>
<span class="sd">            If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,</span>
<span class="sd">            when you want to edit the returned axis, before showing it.</span>

<span class="sd">        min_q (float, optional):</span>
<span class="sd">            Optional minimum quantile from which to consider values, used for plotting under outliers.</span>

<span class="sd">        max_q (float, optional):</span>
<span class="sd">            Optional maximum quantile until which data points are considered, used for plotting under outliers.</span>

<span class="sd">        alpha (float, optional):</span>
<span class="sd">            Optional alpha blending value, between 0 (transparent) and 1 (opaque).</span>

<span class="sd">    Returns</span>
<span class="sd">        (list(matplotlib.axes)):</span>
<span class="sd">            List of axes that include the plots.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">min_q</span> <span class="o">&gt;=</span> <span class="n">max_q</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;min_q must be smaller than max_q&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Feature not recognized&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;alpha must be a float value between 0 and 1&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">min_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">min_q</span><span class="p">,</span> <span class="n">max_q</span><span class="p">,</span> <span class="n">alpha</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">rowspan</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_dependence_plot</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_target_rate_plot</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">ax1</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; ING Bank N.V.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  </body>
</html>