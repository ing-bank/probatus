
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Validation of regressors and classifiers and data used to develop them">
      
      
        <meta name="author" content="ING Bank N. V.">
      
      
        <link rel="canonical" href="https://ing-bank.github.io/probatus/api/sample_similarity.html">
      
      
        <link rel="prev" href="model_interpret.html">
      
      
        <link rel="next" href="utils.html">
      
      
      <link rel="icon" href="../img/Probatus_P_white.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.29">
    
    
      
        <title>Sample Similarity - Probatus</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.76a95c52.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-orange" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#sample-similarity" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="Probatus" class="md-header__button md-logo" aria-label="Probatus" data-md-component="logo">
      
  <img src="../img/Probatus_P_white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Probatus
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Sample Similarity
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ing-bank/probatus/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../index.html" class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="feature_elimination.html" class="md-tabs__link">
          
  
  Api

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../discussion/nb_rfecv_vs_shaprfecv.html" class="md-tabs__link">
          
  
  Discussion

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../howto/grouped_data.html" class="md-tabs__link">
          
  
  Howto

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/nb_automatic_best_num_features.html" class="md-tabs__link">
          
  
  Tutorials

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Probatus" class="md-nav__button md-logo" aria-label="Probatus" data-md-component="logo">
      
  <img src="../img/Probatus_P_white.png" alt="logo">

    </a>
    Probatus
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ing-bank/probatus/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Api
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Api
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="feature_elimination.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Features Elimination
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="model_interpret.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Interpretation using SHAP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Sample Similarity
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="sample_similarity.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Sample Similarity
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model" class="md-nav__link">
    <span class="md-ellipsis">
      resemblance_model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel" class="md-nav__link">
    <span class="md-ellipsis">
      BaseResemblanceModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BaseResemblanceModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.compute" class="md-nav__link">
    <span class="md-ellipsis">
      compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.fit_compute" class="md-nav__link">
    <span class="md-ellipsis">
      fit_compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.get_data_splits" class="md-nav__link">
    <span class="md-ellipsis">
      get_data_splits
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance" class="md-nav__link">
    <span class="md-ellipsis">
      PermutationImportanceResemblance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PermutationImportanceResemblance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance" class="md-nav__link">
    <span class="md-ellipsis">
      SHAPImportanceResemblance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SHAPImportanceResemblance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.get_shap_values" class="md-nav__link">
    <span class="md-ellipsis">
      get_shap_values
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="utils.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utility Functions
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Discussion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Discussion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../discussion/nb_rfecv_vs_shaprfecv.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ShapRFECV vs sklearn RFECV
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Howto
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Howto
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../howto/grouped_data.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to work with grouped data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../howto/reproducibility.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to ensure reproducibility of the results
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_automatic_best_num_features.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Feature selection techniques
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_custom_scoring.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom Scoring Metrics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_sample_similarity.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sample Similarity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_dependence.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap dependence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_feature_elimination.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ShapRFECV - Recursive Feature Elimination using SHAP importance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_model_interpreter.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tree Model Interpretation using SHAP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/nb_shap_variance_penalty_and_results_comparison.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap variance penalty
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model" class="md-nav__link">
    <span class="md-ellipsis">
      resemblance_model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel" class="md-nav__link">
    <span class="md-ellipsis">
      BaseResemblanceModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BaseResemblanceModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.compute" class="md-nav__link">
    <span class="md-ellipsis">
      compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.fit_compute" class="md-nav__link">
    <span class="md-ellipsis">
      fit_compute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.get_data_splits" class="md-nav__link">
    <span class="md-ellipsis">
      get_data_splits
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance" class="md-nav__link">
    <span class="md-ellipsis">
      PermutationImportanceResemblance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PermutationImportanceResemblance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance" class="md-nav__link">
    <span class="md-ellipsis">
      SHAPImportanceResemblance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SHAPImportanceResemblance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.get_shap_values" class="md-nav__link">
    <span class="md-ellipsis">
      get_shap_values
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="sample-similarity">Sample Similarity</h1>
<p>The goal of sample similarity module is understanding how different two samples are from a multivariate perspective.</p>
<p>One of the ways to indicate this is Resemblance Model. Having two datasets -  say X1 and X2 - one can analyse how easy it is to recognize which dataset a randomly selected row comes from. The Resemblance model assigns label 0 to the dataset X1, and label 1 to X2 and trains a binary classification model to predict which sample a given row comes from.
By looking at the test AUC, one can conclude that the samples have a different distribution if the AUC is significantly higher than 0.5. Furthermore, by analysing feature importance one can understand which of the features have predictive power.</p>
<p><img src="../img/resemblance_model_schema.png"/></p>
<p>The following features are implemented:</p>
<ul>
<li><a class="autorefs autorefs-internal" href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance">SHAPImportanceResemblance (Recommended)</a>:
  The class applies SHAP library, in order to interpret the tree based resemblance model.</li>
<li><a class="autorefs autorefs-internal" href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance">PermutationImportanceResemblance</a>:
  The class applies permutation feature importance in order to understand which features the current model relies on the most. The higher the importance of the feature, the more a given feature possibly differs in X2 compared to X1. The importance indicates how much the test AUC drops if a given feature is permuted.</li>
</ul>


<div class="doc doc-object doc-module">



<a id="probatus.sample_similarity.resemblance_model"></a>
    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="probatus.sample_similarity.resemblance_model.BaseResemblanceModel" class="doc doc-heading">
            <code>BaseResemblanceModel</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="probatus.utils.BaseFitComputePlotClass">BaseFitComputePlotClass</span></code></p>


      <p>This model checks for the similarity of two samples.</p>
<p>A possible use case is analysis of whether th train sample differs
from the test sample, due to e.g. non-stationarity.</p>
<p>This is a base class and needs to be extended by a fit() method, which implements how the data is split,
how the model is trained and evaluated.
Further, inheriting classes need to implement how feature importance should be indicated.</p>

              <details class="quote">
                <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BaseResemblanceModel</span><span class="p">(</span><span class="n">BaseFitComputePlotClass</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This model checks for the similarity of two samples.</span>

<span class="sd">    A possible use case is analysis of whether th train sample differs</span>
<span class="sd">    from the test sample, due to e.g. non-stationarity.</span>

<span class="sd">    This is a base class and needs to be extended by a fit() method, which implements how the data is split,</span>
<span class="sd">    how the model is trained and evaluated.</span>
<span class="sd">    Further, inheriting classes need to implement how feature importance should be indicated.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
        <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the class.</span>

<span class="sd">        Args:</span>
<span class="sd">            model (model object):</span>
<span class="sd">                Regression or classification model or pipeline.</span>

<span class="sd">            scoring (string or probatus.utils.Scorer, optional):</span>
<span class="sd">                Metric for which the model performance is calculated. It can be either a metric name aligned with</span>
<span class="sd">                predefined</span>
<span class="sd">                [classification scorers names in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).</span>
<span class="sd">                Another option is using probatus.utils.Scorer to define a custom metric. The recommended option for this</span>
<span class="sd">                class is &#39;roc_auc&#39;.</span>

<span class="sd">            test_prc (float, optional):</span>
<span class="sd">                Percentage of data used to test the model. By default 0.25 is set.</span>

<span class="sd">            n_jobs (int, optional):</span>
<span class="sd">                Number of parallel executions. If -1 use all available cores. By default 1.</span>

<span class="sd">            verbose (int, optional):</span>
<span class="sd">                Controls verbosity of the output:</span>

<span class="sd">                - 0 - neither prints nor warnings are shown</span>
<span class="sd">                - 1 - only most important warnings</span>
<span class="sd">                - 2 - shows all prints and all warnings.</span>

<span class="sd">            random_state (int, optional):</span>
<span class="sd">                Random state set at each round of feature elimination. If it is None, the results will not be</span>
<span class="sd">                reproducible and in random search at each iteration a different hyperparameters might be tested. For</span>
<span class="sd">                reproducible results set it to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_prc</span> <span class="o">=</span> <span class="n">test_prc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">get_single_scorer</span><span class="p">(</span><span class="n">scoring</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_output_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes variables that will be filled in during fit() method, and are used as output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Base fit functionality that should be executed before each fit.</span>

<span class="sd">        Args:</span>
<span class="sd">            X1 (np.ndarray or pd.DataFrame):</span>
<span class="sd">                First sample to be compared. It needs to have the same number of columns as X2.</span>

<span class="sd">            X2 (np.ndarray or pd.DataFrame):</span>
<span class="sd">                Second sample to be compared. It needs to have the same number of columns as X1.</span>

<span class="sd">            column_names (list of str, optional):</span>
<span class="sd">                List of feature names of the provided samples. If provided it will be used to overwrite the existing</span>
<span class="sd">                feature names. If not provided the existing feature names are used or default feature names are</span>
<span class="sd">                generated.</span>

<span class="sd">            class_names (None, or list of str, optional):</span>
<span class="sd">                List of class names assigned, in this case provided samples e.g. [&#39;sample1&#39;, &#39;sample2&#39;]. If none, the</span>
<span class="sd">                default [&#39;First Sample&#39;, &#39;Second Sample&#39;] are used.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (BaseResemblanceModel):</span>
<span class="sd">                Fitted object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set class names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">class_names</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;First Sample&quot;</span><span class="p">,</span> <span class="s2">&quot;Second Sample&quot;</span><span class="p">]</span>

        <span class="c1"># Ensure inputs are correct</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="c1"># Prepare dataset for modelling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Assure the type and number of classes for the variable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">preprocess_labels</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="c1"># Reinitialize variables in case of multiple times being fit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_output_variables</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_prc</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">stratify</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Train </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_score</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Test </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_score</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Finished model training: </span><span class="se">\n</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">results_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Train </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2"> &gt; Test </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">, which might indicate &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;an overfit. </span><span class="se">\n</span><span class="s2"> Strong overfit might lead to misleading conclusions when analysing &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;feature importance. Consider retraining with more regularization applied to the model.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">get_data_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the data splits used to train the Resemblance model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series):</span>
<span class="sd">                X_train, X_test, y_train, y_test.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks if fit() method has been run and computes the output variables.</span>

<span class="sd">        Args:</span>
<span class="sd">            return_scores (bool, optional):</span>
<span class="sd">                Flag indicating whether the method should return a tuple (feature importances, train score,</span>
<span class="sd">                test score), or feature importances. By default the second option is selected.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (tuple(pd.DataFrame, float, float) or pd.DataFrame):</span>
<span class="sd">                Depending on value of return_tuple either returns a tuple (feature importances, train AUC, test AUC), or</span>
<span class="sd">                feature importances.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">return_scores</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">report</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">report</span>

    <span class="k">def</span> <span class="nf">fit_compute</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X1</span><span class="p">,</span>
        <span class="n">X2</span><span class="p">,</span>
        <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">fit_kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the resemblance model and computes the report regarding feature importance.</span>

<span class="sd">        Args:</span>
<span class="sd">            X1 (np.ndarray or pd.DataFrame):</span>
<span class="sd">                First sample to be compared. It needs to have the same number of columns as X2.</span>

<span class="sd">            X2 (np.ndarray or pd.DataFrame):</span>
<span class="sd">                Second sample to be compared. It needs to have the same number of columns as X1.</span>

<span class="sd">            column_names (list of str, optional):</span>
<span class="sd">                List of feature names of the provided samples. If provided it will be used to overwrite the existing</span>
<span class="sd">                feature names. If not provided the existing feature names are used or default feature names are</span>
<span class="sd">                generated.</span>

<span class="sd">            class_names (None, or list of str, optional):</span>
<span class="sd">                List of class names assigned, in this case provided samples e.g. [&#39;sample1&#39;, &#39;sample2&#39;]. If none, the</span>
<span class="sd">                default [&#39;First Sample&#39;, &#39;Second Sample&#39;] are used.</span>

<span class="sd">            return_scores (bool, optional):</span>
<span class="sd">                Flag indicating whether the method should return a tuple (feature importances, train score,</span>
<span class="sd">                test score), or feature importances. By default the second option is selected.</span>

<span class="sd">            **fit_kwargs:</span>
<span class="sd">                In case any other arguments are accepted by fit() method, they can be passed as keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (tuple of (pd.DataFrame, float, float) or pd.DataFrame):</span>
<span class="sd">                Depending on value of return_tuple either returns a tuple (feature importances, train AUC, test AUC), or</span>
<span class="sd">                feature importances.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">return_scores</span><span class="o">=</span><span class="n">return_scores</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Plot method has not been implemented.&quot;</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.BaseResemblanceModel.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Initializes the class.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
                  <code>model object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Regression or classification model or pipeline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scoring</code></td>
            <td>
                  <code>string or <a class="autorefs autorefs-internal" title="probatus.utils.Scorer" href="utils.html#probatus.utils.scoring.Scorer">Scorer</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Metric for which the model performance is calculated. It can be either a metric name aligned with
predefined
<a href="https://scikit-learn.org/stable/modules/model_evaluation.html">classification scorers names in sklearn</a>.
Another option is using probatus.utils.Scorer to define a custom metric. The recommended option for this
class is 'roc_auc'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;roc_auc&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>test_prc</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Percentage of data used to test the model. By default 0.25 is set.</p>
              </div>
            </td>
            <td>
                  <code>0.25</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_jobs</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of parallel executions. If -1 use all available cores. By default 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>verbose</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Controls verbosity of the output:</p>
<ul>
<li>0 - neither prints nor warnings are shown</li>
<li>1 - only most important warnings</li>
<li>2 - shows all prints and all warnings.</li>
</ul>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>random_state</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random state set at each round of feature elimination. If it is None, the results will not be
reproducible and in random search at each iteration a different hyperparameters might be tested. For
reproducible results set it to an integer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
    <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the class.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (model object):</span>
<span class="sd">            Regression or classification model or pipeline.</span>

<span class="sd">        scoring (string or probatus.utils.Scorer, optional):</span>
<span class="sd">            Metric for which the model performance is calculated. It can be either a metric name aligned with</span>
<span class="sd">            predefined</span>
<span class="sd">            [classification scorers names in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).</span>
<span class="sd">            Another option is using probatus.utils.Scorer to define a custom metric. The recommended option for this</span>
<span class="sd">            class is &#39;roc_auc&#39;.</span>

<span class="sd">        test_prc (float, optional):</span>
<span class="sd">            Percentage of data used to test the model. By default 0.25 is set.</span>

<span class="sd">        n_jobs (int, optional):</span>
<span class="sd">            Number of parallel executions. If -1 use all available cores. By default 1.</span>

<span class="sd">        verbose (int, optional):</span>
<span class="sd">            Controls verbosity of the output:</span>

<span class="sd">            - 0 - neither prints nor warnings are shown</span>
<span class="sd">            - 1 - only most important warnings</span>
<span class="sd">            - 2 - shows all prints and all warnings.</span>

<span class="sd">        random_state (int, optional):</span>
<span class="sd">            Random state set at each round of feature elimination. If it is None, the results will not be</span>
<span class="sd">            reproducible and in random search at each iteration a different hyperparameters might be tested. For</span>
<span class="sd">            reproducible results set it to an integer.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test_prc</span> <span class="o">=</span> <span class="n">test_prc</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">get_single_scorer</span><span class="p">(</span><span class="n">scoring</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.BaseResemblanceModel.compute" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Checks if fit() method has been run and computes the output variables.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>return_scores</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag indicating whether the method should return a tuple (feature importances, train score,
test score), or feature importances. By default the second option is selected.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>tuple(<span title="pandas.DataFrame">DataFrame</span>, float, float) or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Depending on value of return_tuple either returns a tuple (feature importances, train AUC, test AUC), or
feature importances.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks if fit() method has been run and computes the output variables.</span>

<span class="sd">    Args:</span>
<span class="sd">        return_scores (bool, optional):</span>
<span class="sd">            Flag indicating whether the method should return a tuple (feature importances, train score,</span>
<span class="sd">            test score), or feature importances. By default the second option is selected.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (tuple(pd.DataFrame, float, float) or pd.DataFrame):</span>
<span class="sd">            Depending on value of return_tuple either returns a tuple (feature importances, train AUC, test AUC), or</span>
<span class="sd">            feature importances.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">return_scores</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">report</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">report</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.BaseResemblanceModel.fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Base fit functionality that should be executed before each fit.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X1</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>First sample to be compared. It needs to have the same number of columns as X2.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X2</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Second sample to be compared. It needs to have the same number of columns as X1.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>column_names</code></td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of feature names of the provided samples. If provided it will be used to overwrite the existing
feature names. If not provided the existing feature names are used or default feature names are
generated.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names assigned, in this case provided samples e.g. ['sample1', 'sample2']. If none, the
default ['First Sample', 'Second Sample'] are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="probatus.sample_similarity.resemblance_model.BaseResemblanceModel" href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel">BaseResemblanceModel</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fitted object</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base fit functionality that should be executed before each fit.</span>

<span class="sd">    Args:</span>
<span class="sd">        X1 (np.ndarray or pd.DataFrame):</span>
<span class="sd">            First sample to be compared. It needs to have the same number of columns as X2.</span>

<span class="sd">        X2 (np.ndarray or pd.DataFrame):</span>
<span class="sd">            Second sample to be compared. It needs to have the same number of columns as X1.</span>

<span class="sd">        column_names (list of str, optional):</span>
<span class="sd">            List of feature names of the provided samples. If provided it will be used to overwrite the existing</span>
<span class="sd">            feature names. If not provided the existing feature names are used or default feature names are</span>
<span class="sd">            generated.</span>

<span class="sd">        class_names (None, or list of str, optional):</span>
<span class="sd">            List of class names assigned, in this case provided samples e.g. [&#39;sample1&#39;, &#39;sample2&#39;]. If none, the</span>
<span class="sd">            default [&#39;First Sample&#39;, &#39;Second Sample&#39;] are used.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (BaseResemblanceModel):</span>
<span class="sd">            Fitted object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Set class names</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">class_names</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;First Sample&quot;</span><span class="p">,</span> <span class="s2">&quot;Second Sample&quot;</span><span class="p">]</span>

    <span class="c1"># Ensure inputs are correct</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

    <span class="c1"># Prepare dataset for modelling</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="p">]</span>
        <span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Assure the type and number of classes for the variable</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">X_name</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">preprocess_labels</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

    <span class="c1"># Reinitialize variables in case of multiple times being fit</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_init_output_variables</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
        <span class="n">test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_prc</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">stratify</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Train </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_score</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Test </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_score</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Finished model training: </span><span class="se">\n</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">results_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_score</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Train </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2"> &gt; Test </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">, which might indicate &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;an overfit. </span><span class="se">\n</span><span class="s2"> Strong overfit might lead to misleading conclusions when analysing &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;feature importance. Consider retraining with more regularization applied to the model.&quot;</span>
            <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.BaseResemblanceModel.fit_compute" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fit_compute</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Fits the resemblance model and computes the report regarding feature importance.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X1</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>First sample to be compared. It needs to have the same number of columns as X2.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X2</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Second sample to be compared. It needs to have the same number of columns as X1.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>column_names</code></td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of feature names of the provided samples. If provided it will be used to overwrite the existing
feature names. If not provided the existing feature names are used or default feature names are
generated.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names assigned, in this case provided samples e.g. ['sample1', 'sample2']. If none, the
default ['First Sample', 'Second Sample'] are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>return_scores</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Flag indicating whether the method should return a tuple (feature importances, train score,
test score), or feature importances. By default the second option is selected.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**fit_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>In case any other arguments are accepted by fit() method, they can be passed as keyword arguments.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>tuple of (pd.DataFrame, float, float) or pd.DataFrame</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Depending on value of return_tuple either returns a tuple (feature importances, train AUC, test AUC), or
feature importances.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit_compute</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">X1</span><span class="p">,</span>
    <span class="n">X2</span><span class="p">,</span>
    <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">return_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">fit_kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fits the resemblance model and computes the report regarding feature importance.</span>

<span class="sd">    Args:</span>
<span class="sd">        X1 (np.ndarray or pd.DataFrame):</span>
<span class="sd">            First sample to be compared. It needs to have the same number of columns as X2.</span>

<span class="sd">        X2 (np.ndarray or pd.DataFrame):</span>
<span class="sd">            Second sample to be compared. It needs to have the same number of columns as X1.</span>

<span class="sd">        column_names (list of str, optional):</span>
<span class="sd">            List of feature names of the provided samples. If provided it will be used to overwrite the existing</span>
<span class="sd">            feature names. If not provided the existing feature names are used or default feature names are</span>
<span class="sd">            generated.</span>

<span class="sd">        class_names (None, or list of str, optional):</span>
<span class="sd">            List of class names assigned, in this case provided samples e.g. [&#39;sample1&#39;, &#39;sample2&#39;]. If none, the</span>
<span class="sd">            default [&#39;First Sample&#39;, &#39;Second Sample&#39;] are used.</span>

<span class="sd">        return_scores (bool, optional):</span>
<span class="sd">            Flag indicating whether the method should return a tuple (feature importances, train score,</span>
<span class="sd">            test score), or feature importances. By default the second option is selected.</span>

<span class="sd">        **fit_kwargs:</span>
<span class="sd">            In case any other arguments are accepted by fit() method, they can be passed as keyword arguments.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (tuple of (pd.DataFrame, float, float) or pd.DataFrame):</span>
<span class="sd">            Depending on value of return_tuple either returns a tuple (feature importances, train AUC, test AUC), or</span>
<span class="sd">            feature importances.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">return_scores</span><span class="o">=</span><span class="n">return_scores</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.BaseResemblanceModel.get_data_splits" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_data_splits</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Returns the data splits used to train the Resemblance model.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>(<span title="pandas.DataFrame">DataFrame</span>, <span title="pandas.DataFrame">DataFrame</span>, <span title="pandas.Series">Series</span>, <span title="pandas.Series">Series</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>X_train, X_test, y_train, y_test.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_data_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the data splits used to train the Resemblance model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series):</span>
<span class="sd">            X_train, X_test, y_train, y_test.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.BaseResemblanceModel.plot" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Plot.</p>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Plot method has not been implemented.&quot;</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance" class="doc doc-heading">
            <code>PermutationImportanceResemblance</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="probatus.sample_similarity.resemblance_model.BaseResemblanceModel" href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel">BaseResemblanceModel</a></code></p>


      <p>This model checks the similarity of two samples.</p>
<p>A possible use case is analysis of whether the train sample differs
from the test sample, due to e.g. non-stationarity.</p>
<p>It assigns labels to each sample, 0 to the first sample, 1 to the second. Then, it randomly selects a portion of
data to train on. The resulting model tries to distinguish which sample a given test row comes from. This
provides insights on how distinguishable these samples are and which features contribute to that. The feature
importance is calculated using permutation importance.</p>
<p>If the model achieves a test AUC significantly different than 0.5, it indicates that it is possible to distinguish
between the samples, and therefore, the samples differ.
Features with a high permutation importance contribute to that effect the most.
Thus, their distribution might differ between two samples.</p>
<p>Examples:</p>
<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from probatus.sample_similarity import PermutationImportanceResemblance
X1, _ = make_classification(n_samples=100, n_features=5)
X2, _ = make_classification(n_samples=100, n_features=5, shift=0.5)
model = RandomForestClassifier(max_depth=2)
perm = PermutationImportanceResemblance(model)
feature_importance = perm.fit_compute(X1, X2)
perm.plot()
</code></pre>
<p><img src="../img/sample_similarity_permutation_importance.png" width="500" /></p>

              <details class="quote">
                <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PermutationImportanceResemblance</span><span class="p">(</span><span class="n">BaseResemblanceModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This model checks the similarity of two samples.</span>

<span class="sd">    A possible use case is analysis of whether the train sample differs</span>
<span class="sd">    from the test sample, due to e.g. non-stationarity.</span>

<span class="sd">    It assigns labels to each sample, 0 to the first sample, 1 to the second. Then, it randomly selects a portion of</span>
<span class="sd">    data to train on. The resulting model tries to distinguish which sample a given test row comes from. This</span>
<span class="sd">    provides insights on how distinguishable these samples are and which features contribute to that. The feature</span>
<span class="sd">    importance is calculated using permutation importance.</span>

<span class="sd">    If the model achieves a test AUC significantly different than 0.5, it indicates that it is possible to distinguish</span>
<span class="sd">    between the samples, and therefore, the samples differ.</span>
<span class="sd">    Features with a high permutation importance contribute to that effect the most.</span>
<span class="sd">    Thus, their distribution might differ between two samples.</span>

<span class="sd">    Examples:</span>
<span class="sd">    ```python</span>
<span class="sd">    from sklearn.datasets import make_classification</span>
<span class="sd">    from sklearn.ensemble import RandomForestClassifier</span>
<span class="sd">    from probatus.sample_similarity import PermutationImportanceResemblance</span>
<span class="sd">    X1, _ = make_classification(n_samples=100, n_features=5)</span>
<span class="sd">    X2, _ = make_classification(n_samples=100, n_features=5, shift=0.5)</span>
<span class="sd">    model = RandomForestClassifier(max_depth=2)</span>
<span class="sd">    perm = PermutationImportanceResemblance(model)</span>
<span class="sd">    feature_importance = perm.fit_compute(X1, X2)</span>
<span class="sd">    perm.plot()</span>
<span class="sd">    ```</span>
<span class="sd">    &lt;img src=&quot;../img/sample_similarity_permutation_importance.png&quot; width=&quot;500&quot; /&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
        <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the class.</span>

<span class="sd">        Args:</span>
<span class="sd">            model (model object):</span>
<span class="sd">                Regression or classification model or pipeline.</span>

<span class="sd">            iterations (int, optional):</span>
<span class="sd">                Number of iterations performed to calculate permutation importance. By default 100 iterations per</span>
<span class="sd">                feature are done.</span>

<span class="sd">            scoring (string or probatus.utils.Scorer, optional):</span>
<span class="sd">                Metric for which the model performance is calculated. It can be either a metric name aligned with</span>
<span class="sd">                predefined</span>
<span class="sd">                [classification scorers names in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).</span>
<span class="sd">                Another option is using probatus.utils.Scorer to define a custom metric. Recommended option for this</span>
<span class="sd">                class is &#39;roc_auc&#39;.</span>

<span class="sd">            test_prc (float, optional):</span>
<span class="sd">                Percentage of data used to test the model. By default 0.25 is set.</span>

<span class="sd">            n_jobs (int, optional):</span>
<span class="sd">                Number of parallel executions. If -1 use all available cores. By default 1.</span>

<span class="sd">            verbose (int, optional):</span>
<span class="sd">                Controls verbosity of the output:</span>

<span class="sd">                - 0 - neither prints nor warnings are shown</span>
<span class="sd">                - 1 - only most important warnings</span>
<span class="sd">                - 2 - shows all prints and all warnings.</span>

<span class="sd">            random_state (int, optional):</span>
<span class="sd">                Random state set at each round of feature elimination. If it is None, the results will not be</span>
<span class="sd">                reproducible and in random search at each iteration a different hyperparameters might be tested. For</span>
<span class="sd">                reproducible results set it to integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
            <span class="n">test_prc</span><span class="o">=</span><span class="n">test_prc</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="o">=</span> <span class="n">iterations</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iterations_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature&quot;</span><span class="p">,</span> <span class="s2">&quot;importance&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations_columns</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">plot_x_label</span> <span class="o">=</span> <span class="s2">&quot;Permutation Feature Importance&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot_y_label</span> <span class="o">=</span> <span class="s2">&quot;Feature Name&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot_title</span> <span class="o">=</span> <span class="s2">&quot;Permutation Feature Importance of Resemblance Model&quot;</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function assigns labels to each sample, 0 to the first sample, 1 to the second.</span>

<span class="sd">        Then, it randomly selects a</span>
<span class="sd">            portion of data to train on. The resulting model tries to distinguish which sample a given test row</span>
<span class="sd">            comes from. This provides insights on how distinguishable these samples are and which features contribute to</span>
<span class="sd">            that. The feature importance is calculated using permutation importance.</span>

<span class="sd">        Args:</span>
<span class="sd">            X1 (np.ndarray or pd.DataFrame):</span>
<span class="sd">                First sample to be compared. It needs to have the same number of columns as X2.</span>

<span class="sd">            X2 (np.ndarray or pd.DataFrame):</span>
<span class="sd">                Second sample to be compared. It needs to have the same number of columns as X1.</span>

<span class="sd">            column_names (list of str, optional):</span>
<span class="sd">                List of feature names of the provided samples. If provided it will be used to overwrite the existing</span>
<span class="sd">                feature names. If not provided the existing feature names are used or default feature names are</span>
<span class="sd">                generated.</span>

<span class="sd">            class_names (None, or list of str, optional):</span>
<span class="sd">                List of class names assigned, in this case provided samples e.g. [&#39;sample1&#39;, &#39;sample2&#39;]. If none, the</span>
<span class="sd">                default [&#39;First Sample&#39;, &#39;Second Sample&#39;] are used.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (PermutationImportanceResemblance):</span>
<span class="sd">                Fitted object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="o">=</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="o">=</span><span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">)</span>

        <span class="n">permutation_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">,</span>
            <span class="n">scoring</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">scorer</span><span class="p">,</span>
            <span class="n">n_repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Prepare report</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mean_importance&quot;</span><span class="p">,</span> <span class="s2">&quot;std_importance&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">report_columns</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">feature_index</span><span class="p">,</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">):</span>
            <span class="c1"># Fill in the report</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">feature_name</span><span class="p">,</span> <span class="s2">&quot;mean_importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">permutation_result</span><span class="p">[</span><span class="s2">&quot;importances_mean&quot;</span><span class="p">][</span><span class="n">feature_index</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">feature_name</span><span class="p">,</span> <span class="s2">&quot;std_importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">permutation_result</span><span class="p">[</span><span class="s2">&quot;importances_std&quot;</span><span class="p">][</span><span class="n">feature_index</span><span class="p">]</span>

            <span class="c1"># Fill in the iterations</span>
            <span class="n">current_iterations</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">),</span>
                        <span class="n">permutation_result</span><span class="p">[</span><span class="s2">&quot;importances&quot;</span><span class="p">][</span><span class="n">feature_index</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">,)),</span>
                    <span class="p">],</span>
                    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations_columns</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">,</span> <span class="n">current_iterations</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

        <span class="c1"># Sort by mean test score of first metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;mean_importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the resulting AUC of the model as well as the feature importances.</span>

<span class="sd">        Args:</span>
<span class="sd">            ax (matplotlib.axes, optional):</span>
<span class="sd">                Axes to which the output should be plotted. If not provided new axes are created.</span>

<span class="sd">            top_n (int, optional):</span>
<span class="sd">                Number of the most important features to be plotted. By default features are included in the plot.</span>

<span class="sd">            show (bool, optional):</span>
<span class="sd">                If True, the plots are shown to the user, otherwise they are not shown. Not showing a plot can be useful</span>
<span class="sd">                when you want to edit the returned axis before showing it.</span>

<span class="sd">            **plot_kwargs:</span>
<span class="sd">                Keyword arguments passed to the matplotlib.plotly.subplots method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (matplotlib.axes):</span>
<span class="sd">                Axes that include the plot.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">feature_report</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

        <span class="n">sorted_features</span> <span class="o">=</span> <span class="n">feature_report</span><span class="p">[</span><span class="s2">&quot;mean_importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="n">top_n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">top_n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sorted_features</span> <span class="o">=</span> <span class="n">sorted_features</span><span class="p">[</span><span class="o">-</span><span class="n">top_n</span><span class="p">:]</span>

        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="o">**</span><span class="n">plot_kwargs</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">position</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_features</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;feature&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">feature</span><span class="p">][</span><span class="s2">&quot;importance&quot;</span><span class="p">],</span>
                <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="n">position</span><span class="p">],</span>
                <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">position</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">sorted_features</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_x_label</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_y_label</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_title</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span><span class="p">,</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">),</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
            <span class="n">xycoords</span><span class="o">=</span><span class="s2">&quot;axes fraction&quot;</span><span class="p">,</span>
            <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
            <span class="n">va</span><span class="o">=</span><span class="s2">&quot;top&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Initializes the class.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
                  <code>model object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Regression or classification model or pipeline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>iterations</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of iterations performed to calculate permutation importance. By default 100 iterations per
feature are done.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scoring</code></td>
            <td>
                  <code>string or <a class="autorefs autorefs-internal" title="probatus.utils.Scorer" href="utils.html#probatus.utils.scoring.Scorer">Scorer</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Metric for which the model performance is calculated. It can be either a metric name aligned with
predefined
<a href="https://scikit-learn.org/stable/modules/model_evaluation.html">classification scorers names in sklearn</a>.
Another option is using probatus.utils.Scorer to define a custom metric. Recommended option for this
class is 'roc_auc'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;roc_auc&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>test_prc</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Percentage of data used to test the model. By default 0.25 is set.</p>
              </div>
            </td>
            <td>
                  <code>0.25</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_jobs</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of parallel executions. If -1 use all available cores. By default 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>verbose</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Controls verbosity of the output:</p>
<ul>
<li>0 - neither prints nor warnings are shown</li>
<li>1 - only most important warnings</li>
<li>2 - shows all prints and all warnings.</li>
</ul>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>random_state</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random state set at each round of feature elimination. If it is None, the results will not be
reproducible and in random search at each iteration a different hyperparameters might be tested. For
reproducible results set it to integer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
    <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the class.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (model object):</span>
<span class="sd">            Regression or classification model or pipeline.</span>

<span class="sd">        iterations (int, optional):</span>
<span class="sd">            Number of iterations performed to calculate permutation importance. By default 100 iterations per</span>
<span class="sd">            feature are done.</span>

<span class="sd">        scoring (string or probatus.utils.Scorer, optional):</span>
<span class="sd">            Metric for which the model performance is calculated. It can be either a metric name aligned with</span>
<span class="sd">            predefined</span>
<span class="sd">            [classification scorers names in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).</span>
<span class="sd">            Another option is using probatus.utils.Scorer to define a custom metric. Recommended option for this</span>
<span class="sd">            class is &#39;roc_auc&#39;.</span>

<span class="sd">        test_prc (float, optional):</span>
<span class="sd">            Percentage of data used to test the model. By default 0.25 is set.</span>

<span class="sd">        n_jobs (int, optional):</span>
<span class="sd">            Number of parallel executions. If -1 use all available cores. By default 1.</span>

<span class="sd">        verbose (int, optional):</span>
<span class="sd">            Controls verbosity of the output:</span>

<span class="sd">            - 0 - neither prints nor warnings are shown</span>
<span class="sd">            - 1 - only most important warnings</span>
<span class="sd">            - 2 - shows all prints and all warnings.</span>

<span class="sd">        random_state (int, optional):</span>
<span class="sd">            Random state set at each round of feature elimination. If it is None, the results will not be</span>
<span class="sd">            reproducible and in random search at each iteration a different hyperparameters might be tested. For</span>
<span class="sd">            reproducible results set it to integer.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
        <span class="n">test_prc</span><span class="o">=</span><span class="n">test_prc</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="o">=</span> <span class="n">iterations</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">iterations_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feature&quot;</span><span class="p">,</span> <span class="s2">&quot;importance&quot;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations_columns</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">plot_x_label</span> <span class="o">=</span> <span class="s2">&quot;Permutation Feature Importance&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">plot_y_label</span> <span class="o">=</span> <span class="s2">&quot;Feature Name&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">plot_title</span> <span class="o">=</span> <span class="s2">&quot;Permutation Feature Importance of Resemblance Model&quot;</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>This function assigns labels to each sample, 0 to the first sample, 1 to the second.</p>
<p>Then, it randomly selects a
    portion of data to train on. The resulting model tries to distinguish which sample a given test row
    comes from. This provides insights on how distinguishable these samples are and which features contribute to
    that. The feature importance is calculated using permutation importance.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X1</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>First sample to be compared. It needs to have the same number of columns as X2.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X2</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Second sample to be compared. It needs to have the same number of columns as X1.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>column_names</code></td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of feature names of the provided samples. If provided it will be used to overwrite the existing
feature names. If not provided the existing feature names are used or default feature names are
generated.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names assigned, in this case provided samples e.g. ['sample1', 'sample2']. If none, the
default ['First Sample', 'Second Sample'] are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance" href="#probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance">PermutationImportanceResemblance</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fitted object.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function assigns labels to each sample, 0 to the first sample, 1 to the second.</span>

<span class="sd">    Then, it randomly selects a</span>
<span class="sd">        portion of data to train on. The resulting model tries to distinguish which sample a given test row</span>
<span class="sd">        comes from. This provides insights on how distinguishable these samples are and which features contribute to</span>
<span class="sd">        that. The feature importance is calculated using permutation importance.</span>

<span class="sd">    Args:</span>
<span class="sd">        X1 (np.ndarray or pd.DataFrame):</span>
<span class="sd">            First sample to be compared. It needs to have the same number of columns as X2.</span>

<span class="sd">        X2 (np.ndarray or pd.DataFrame):</span>
<span class="sd">            Second sample to be compared. It needs to have the same number of columns as X1.</span>

<span class="sd">        column_names (list of str, optional):</span>
<span class="sd">            List of feature names of the provided samples. If provided it will be used to overwrite the existing</span>
<span class="sd">            feature names. If not provided the existing feature names are used or default feature names are</span>
<span class="sd">            generated.</span>

<span class="sd">        class_names (None, or list of str, optional):</span>
<span class="sd">            List of class names assigned, in this case provided samples e.g. [&#39;sample1&#39;, &#39;sample2&#39;]. If none, the</span>
<span class="sd">            default [&#39;First Sample&#39;, &#39;Second Sample&#39;] are used.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (PermutationImportanceResemblance):</span>
<span class="sd">            Fitted object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="o">=</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="o">=</span><span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">)</span>

    <span class="n">permutation_result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">scorer</span><span class="p">,</span>
        <span class="n">n_repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Prepare report</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">report_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mean_importance&quot;</span><span class="p">,</span> <span class="s2">&quot;std_importance&quot;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">report</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">report_columns</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">feature_index</span><span class="p">,</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">):</span>
        <span class="c1"># Fill in the report</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">feature_name</span><span class="p">,</span> <span class="s2">&quot;mean_importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">permutation_result</span><span class="p">[</span><span class="s2">&quot;importances_mean&quot;</span><span class="p">][</span><span class="n">feature_index</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">feature_name</span><span class="p">,</span> <span class="s2">&quot;std_importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">permutation_result</span><span class="p">[</span><span class="s2">&quot;importances_std&quot;</span><span class="p">][</span><span class="n">feature_index</span><span class="p">]</span>

        <span class="c1"># Fill in the iterations</span>
        <span class="n">current_iterations</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">),</span>
                    <span class="n">permutation_result</span><span class="p">[</span><span class="s2">&quot;importances&quot;</span><span class="p">][</span><span class="n">feature_index</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">,)),</span>
                <span class="p">],</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations_columns</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">,</span> <span class="n">current_iterations</span><span class="p">])</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="c1"># Sort by mean test score of first metric</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;mean_importance&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.PermutationImportanceResemblance.plot" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Plots the resulting AUC of the model as well as the feature importances.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>ax</code></td>
            <td>
                  <code><span title="matplotlib.axes">axes</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axes to which the output should be plotted. If not provided new axes are created.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>top_n</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of the most important features to be plotted. By default features are included in the plot.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>show</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, the plots are shown to the user, otherwise they are not shown. Not showing a plot can be useful
when you want to edit the returned axis before showing it.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**plot_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments passed to the matplotlib.plotly.subplots method.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="matplotlib.axes">axes</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axes that include the plot.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots the resulting AUC of the model as well as the feature importances.</span>

<span class="sd">    Args:</span>
<span class="sd">        ax (matplotlib.axes, optional):</span>
<span class="sd">            Axes to which the output should be plotted. If not provided new axes are created.</span>

<span class="sd">        top_n (int, optional):</span>
<span class="sd">            Number of the most important features to be plotted. By default features are included in the plot.</span>

<span class="sd">        show (bool, optional):</span>
<span class="sd">            If True, the plots are shown to the user, otherwise they are not shown. Not showing a plot can be useful</span>
<span class="sd">            when you want to edit the returned axis before showing it.</span>

<span class="sd">        **plot_kwargs:</span>
<span class="sd">            Keyword arguments passed to the matplotlib.plotly.subplots method.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (matplotlib.axes):</span>
<span class="sd">            Axes that include the plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">feature_report</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="n">sorted_features</span> <span class="o">=</span> <span class="n">feature_report</span><span class="p">[</span><span class="s2">&quot;mean_importance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span>
    <span class="k">if</span> <span class="n">top_n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">top_n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sorted_features</span> <span class="o">=</span> <span class="n">sorted_features</span><span class="p">[</span><span class="o">-</span><span class="n">top_n</span><span class="p">:]</span>

    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="o">**</span><span class="n">plot_kwargs</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">position</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_features</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">iterations_results</span><span class="p">[</span><span class="s2">&quot;feature&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">feature</span><span class="p">][</span><span class="s2">&quot;importance&quot;</span><span class="p">],</span>
            <span class="n">positions</span><span class="o">=</span><span class="p">[</span><span class="n">position</span><span class="p">],</span>
            <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">position</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">sorted_features</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_x_label</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_y_label</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_title</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span><span class="p">,</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">),</span>
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">xycoords</span><span class="o">=</span><span class="s2">&quot;axes fraction&quot;</span><span class="p">,</span>
        <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
        <span class="n">va</span><span class="o">=</span><span class="s2">&quot;top&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance" class="doc doc-heading">
            <code>SHAPImportanceResemblance</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="probatus.sample_similarity.resemblance_model.BaseResemblanceModel" href="#probatus.sample_similarity.resemblance_model.BaseResemblanceModel">BaseResemblanceModel</a></code></p>


      <p>This model checks for similarity of two samples.</p>
<p>A possible use case is analysis of whether the train sample differs
    from the test sample, due to e.g. non-stationarity.</p>
<p>It assigns labels to each sample, 0 to the first sample, 1 to the second. Then, it randomly selects a portion of
    data to train on. The resulting model tries to distinguish which sample a given test row comes from. This
    provides insights on how distinguishable these samples are and which features contribute to that. The feature
    importance is calculated using SHAP feature importance.</p>
<p>If the model achieves test AUC significantly different than 0.5, it indicates that it is possible to distinguish
    between the samples, and therefore, the samples differ. Features with a high permutation importance contribute
    to that effect the most. Thus, their distribution might differ between two samples.</p>
<p>This class currently works only with the Tree based models.</p>
<p>Examples:</p>
<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from probatus.sample_similarity import SHAPImportanceResemblance
X1, _ = make_classification(n_samples=100, n_features=5)
X2, _ = make_classification(n_samples=100, n_features=5, shift=0.5)
model = RandomForestClassifier(max_depth=2)
rm = SHAPImportanceResemblance(model)
feature_importance = rm.fit_compute(X1, X2)
rm.plot()
</code></pre>
<p><img src="../img/sample_similarity_shap_importance.png" width="320" />
<img src="../img/sample_similarity_shap_summary.png" width="320" /></p>

              <details class="quote">
                <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SHAPImportanceResemblance</span><span class="p">(</span><span class="n">BaseResemblanceModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This model checks for similarity of two samples.</span>

<span class="sd">    A possible use case is analysis of whether the train sample differs</span>
<span class="sd">        from the test sample, due to e.g. non-stationarity.</span>

<span class="sd">    It assigns labels to each sample, 0 to the first sample, 1 to the second. Then, it randomly selects a portion of</span>
<span class="sd">        data to train on. The resulting model tries to distinguish which sample a given test row comes from. This</span>
<span class="sd">        provides insights on how distinguishable these samples are and which features contribute to that. The feature</span>
<span class="sd">        importance is calculated using SHAP feature importance.</span>

<span class="sd">    If the model achieves test AUC significantly different than 0.5, it indicates that it is possible to distinguish</span>
<span class="sd">        between the samples, and therefore, the samples differ. Features with a high permutation importance contribute</span>
<span class="sd">        to that effect the most. Thus, their distribution might differ between two samples.</span>

<span class="sd">    This class currently works only with the Tree based models.</span>

<span class="sd">    Examples:</span>
<span class="sd">    ```python</span>
<span class="sd">    from sklearn.datasets import make_classification</span>
<span class="sd">    from sklearn.ensemble import RandomForestClassifier</span>
<span class="sd">    from probatus.sample_similarity import SHAPImportanceResemblance</span>
<span class="sd">    X1, _ = make_classification(n_samples=100, n_features=5)</span>
<span class="sd">    X2, _ = make_classification(n_samples=100, n_features=5, shift=0.5)</span>
<span class="sd">    model = RandomForestClassifier(max_depth=2)</span>
<span class="sd">    rm = SHAPImportanceResemblance(model)</span>
<span class="sd">    feature_importance = rm.fit_compute(X1, X2)</span>
<span class="sd">    rm.plot()</span>
<span class="sd">    ```</span>

<span class="sd">    &lt;img src=&quot;../img/sample_similarity_shap_importance.png&quot; width=&quot;320&quot; /&gt;</span>
<span class="sd">    &lt;img src=&quot;../img/sample_similarity_shap_summary.png&quot; width=&quot;320&quot; /&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
        <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the class.</span>

<span class="sd">        Args:</span>
<span class="sd">            model (model object):</span>
<span class="sd">                Regression or classification model or pipeline.</span>

<span class="sd">            scoring (string or probatus.utils.Scorer, optional):</span>
<span class="sd">                Metric for which the model performance is calculated. It can be either a metric name aligned with</span>
<span class="sd">                predefined</span>
<span class="sd">                [classification scorers names in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).</span>
<span class="sd">                Another option is using probatus.utils.Scorer to define a custom metric. Recommended option for this</span>
<span class="sd">                class is &#39;roc_auc&#39;.</span>

<span class="sd">            test_prc (float, optional):</span>
<span class="sd">                Percentage of data used to test the model. By default 0.25 is set.</span>

<span class="sd">            n_jobs (int, optional):</span>
<span class="sd">                Number of parallel executions. If -1 use all available cores. By default 1.</span>

<span class="sd">            verbose (int, optional):</span>
<span class="sd">                Controls verbosity of the output:</span>

<span class="sd">                - 0 - neither prints nor warnings are shown</span>
<span class="sd">                - 1 - only most important warnings</span>
<span class="sd">                - 2 - shows all prints and all warnings.</span>

<span class="sd">            random_state (int, optional):</span>
<span class="sd">                Random state set at each round of feature elimination. If it is None, the results will not be</span>
<span class="sd">                reproducible and in random search at each iteration a different hyperparameters might be tested. For</span>
<span class="sd">                reproducible results set it to integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
            <span class="n">test_prc</span><span class="o">=</span><span class="n">test_prc</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">plot_title</span> <span class="o">=</span> <span class="s2">&quot;SHAP summary plot&quot;</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function assigns labels to each sample, 0 to the first sample, 1 to the second.</span>

<span class="sd">        Then, it randomly selects a</span>
<span class="sd">            portion of data to train on. The resulting model tries to distinguish which sample a given test row</span>
<span class="sd">            comes from. This provides insights on how distinguishable these samples are and which features contribute to</span>
<span class="sd">            that. The feature importance is calculated using SHAP feature importance.</span>

<span class="sd">        Args:</span>
<span class="sd">            X1 (np.ndarray or pd.DataFrame):</span>
<span class="sd">                First sample to be compared. It needs to have the same number of columns as X2.</span>

<span class="sd">            X2 (np.ndarray or pd.DataFrame):</span>
<span class="sd">                Second sample to be compared. It needs to have the same number of columns as X1.</span>

<span class="sd">            column_names (list of str, optional):</span>
<span class="sd">                List of feature names of the provided samples. If provided it will be used to overwrite the existing</span>
<span class="sd">                feature names. If not provided the existing feature names are used or default feature names are</span>
<span class="sd">                generated.</span>

<span class="sd">            class_names (None, or list of str, optional):</span>
<span class="sd">                List of class names assigned, in this case provided samples e.g. [&#39;sample1&#39;, &#39;sample2&#39;]. If none, the</span>
<span class="sd">                default [&#39;First Sample&#39;, &#39;Second Sample&#39;] are used.</span>

<span class="sd">            **shap_kwargs:</span>
<span class="sd">                keyword arguments passed to</span>
<span class="sd">                [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">                It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">                The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">                `check_additivity=False` disables the additivity check inside SHAP.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (SHAPImportanceResemblance):</span>
<span class="sd">                Fitted object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="o">=</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="o">=</span><span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span> <span class="o">=</span> <span class="n">shap_calc</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report</span> <span class="o">=</span> <span class="n">calculate_shap_importance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">summary_plot_kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the resulting AUC of the model as well as the feature importances.</span>

<span class="sd">        Args:</span>
<span class="sd">            plot_type (str, optional): Type of plot, used to compute shap.summary_plot. By default &#39;bar&#39;, available ones</span>
<span class="sd">                are  &quot;dot&quot;, &quot;bar&quot;, &quot;violin&quot;,</span>

<span class="sd">            show (bool, optional):</span>
<span class="sd">                If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,</span>
<span class="sd">                when you want to edit the returned axis, before showing it.</span>

<span class="sd">            **summary_plot_kwargs:</span>
<span class="sd">                kwargs passed to the shap.summary_plot.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (matplotlib.axes):</span>
<span class="sd">                Axes that include the plot.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># This line serves as a double check if the object has been fitted</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>

        <span class="n">summary_plot</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span>
            <span class="n">plot_type</span><span class="o">=</span><span class="n">plot_type</span><span class="p">,</span>
            <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
            <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">summary_plot_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_title</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span><span class="p">,</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">),</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
            <span class="n">xycoords</span><span class="o">=</span><span class="s2">&quot;axes fraction&quot;</span><span class="p">,</span>
            <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
            <span class="n">va</span><span class="o">=</span><span class="s2">&quot;top&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">ax</span>

    <span class="k">def</span> <span class="nf">get_shap_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the SHAP values generated on the test set.</span>

<span class="sd">        Returns:</span>
<span class="sd">             (np.array):</span>
<span class="sd">                SHAP values generated on the test set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Initializes the class.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>model</code></td>
            <td>
                  <code>model object</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Regression or classification model or pipeline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scoring</code></td>
            <td>
                  <code>string or <a class="autorefs autorefs-internal" title="probatus.utils.Scorer" href="utils.html#probatus.utils.scoring.Scorer">Scorer</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Metric for which the model performance is calculated. It can be either a metric name aligned with
predefined
<a href="https://scikit-learn.org/stable/modules/model_evaluation.html">classification scorers names in sklearn</a>.
Another option is using probatus.utils.Scorer to define a custom metric. Recommended option for this
class is 'roc_auc'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;roc_auc&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>test_prc</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Percentage of data used to test the model. By default 0.25 is set.</p>
              </div>
            </td>
            <td>
                  <code>0.25</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_jobs</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of parallel executions. If -1 use all available cores. By default 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>verbose</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Controls verbosity of the output:</p>
<ul>
<li>0 - neither prints nor warnings are shown</li>
<li>1 - only most important warnings</li>
<li>2 - shows all prints and all warnings.</li>
</ul>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>random_state</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random state set at each round of feature elimination. If it is None, the results will not be
reproducible and in random search at each iteration a different hyperparameters might be tested. For
reproducible results set it to integer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
    <span class="n">test_prc</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the class.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (model object):</span>
<span class="sd">            Regression or classification model or pipeline.</span>

<span class="sd">        scoring (string or probatus.utils.Scorer, optional):</span>
<span class="sd">            Metric for which the model performance is calculated. It can be either a metric name aligned with</span>
<span class="sd">            predefined</span>
<span class="sd">            [classification scorers names in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html).</span>
<span class="sd">            Another option is using probatus.utils.Scorer to define a custom metric. Recommended option for this</span>
<span class="sd">            class is &#39;roc_auc&#39;.</span>

<span class="sd">        test_prc (float, optional):</span>
<span class="sd">            Percentage of data used to test the model. By default 0.25 is set.</span>

<span class="sd">        n_jobs (int, optional):</span>
<span class="sd">            Number of parallel executions. If -1 use all available cores. By default 1.</span>

<span class="sd">        verbose (int, optional):</span>
<span class="sd">            Controls verbosity of the output:</span>

<span class="sd">            - 0 - neither prints nor warnings are shown</span>
<span class="sd">            - 1 - only most important warnings</span>
<span class="sd">            - 2 - shows all prints and all warnings.</span>

<span class="sd">        random_state (int, optional):</span>
<span class="sd">            Random state set at each round of feature elimination. If it is None, the results will not be</span>
<span class="sd">            reproducible and in random search at each iteration a different hyperparameters might be tested. For</span>
<span class="sd">            reproducible results set it to integer.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
        <span class="n">test_prc</span><span class="o">=</span><span class="n">test_prc</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">plot_title</span> <span class="o">=</span> <span class="s2">&quot;SHAP summary plot&quot;</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>This function assigns labels to each sample, 0 to the first sample, 1 to the second.</p>
<p>Then, it randomly selects a
    portion of data to train on. The resulting model tries to distinguish which sample a given test row
    comes from. This provides insights on how distinguishable these samples are and which features contribute to
    that. The feature importance is calculated using SHAP feature importance.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>X1</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>First sample to be compared. It needs to have the same number of columns as X2.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X2</code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> or <span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Second sample to be compared. It needs to have the same number of columns as X1.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>column_names</code></td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of feature names of the provided samples. If provided it will be used to overwrite the existing
feature names. If not provided the existing feature names are used or default feature names are
generated.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>class_names</code></td>
            <td>
                  <code>None, or list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of class names assigned, in this case provided samples e.g. ['sample1', 'sample2']. If none, the
default ['First Sample', 'Second Sample'] are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**shap_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>keyword arguments passed to
<a href="https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer">shap.Explainer</a>.
It also enables <code>approximate</code> and <code>check_additivity</code> parameters, passed while calculating SHAP values.
The <code>approximate=True</code> causes less accurate, but faster SHAP values calculation, while
<code>check_additivity=False</code> disables the additivity check inside SHAP.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance" href="#probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance">SHAPImportanceResemblance</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fitted object.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function assigns labels to each sample, 0 to the first sample, 1 to the second.</span>

<span class="sd">    Then, it randomly selects a</span>
<span class="sd">        portion of data to train on. The resulting model tries to distinguish which sample a given test row</span>
<span class="sd">        comes from. This provides insights on how distinguishable these samples are and which features contribute to</span>
<span class="sd">        that. The feature importance is calculated using SHAP feature importance.</span>

<span class="sd">    Args:</span>
<span class="sd">        X1 (np.ndarray or pd.DataFrame):</span>
<span class="sd">            First sample to be compared. It needs to have the same number of columns as X2.</span>

<span class="sd">        X2 (np.ndarray or pd.DataFrame):</span>
<span class="sd">            Second sample to be compared. It needs to have the same number of columns as X1.</span>

<span class="sd">        column_names (list of str, optional):</span>
<span class="sd">            List of feature names of the provided samples. If provided it will be used to overwrite the existing</span>
<span class="sd">            feature names. If not provided the existing feature names are used or default feature names are</span>
<span class="sd">            generated.</span>

<span class="sd">        class_names (None, or list of str, optional):</span>
<span class="sd">            List of class names assigned, in this case provided samples e.g. [&#39;sample1&#39;, &#39;sample2&#39;]. If none, the</span>
<span class="sd">            default [&#39;First Sample&#39;, &#39;Second Sample&#39;] are used.</span>

<span class="sd">        **shap_kwargs:</span>
<span class="sd">            keyword arguments passed to</span>
<span class="sd">            [shap.Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer).</span>
<span class="sd">            It also enables `approximate` and `check_additivity` parameters, passed while calculating SHAP values.</span>
<span class="sd">            The `approximate=True` causes less accurate, but faster SHAP values calculation, while</span>
<span class="sd">            `check_additivity=False` disables the additivity check inside SHAP.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (SHAPImportanceResemblance):</span>
<span class="sd">            Fitted object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="o">=</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="o">=</span><span class="n">X2</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span> <span class="o">=</span> <span class="n">shap_calc</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span> <span class="o">**</span><span class="n">shap_kwargs</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">report</span> <span class="o">=</span> <span class="n">calculate_shap_importance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.get_shap_values" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_shap_values</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Gets the SHAP values generated on the test set.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>SHAP values generated on the test set.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_shap_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gets the SHAP values generated on the test set.</span>

<span class="sd">    Returns:</span>
<span class="sd">         (np.array):</span>
<span class="sd">            SHAP values generated on the test set.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="probatus.sample_similarity.resemblance_model.SHAPImportanceResemblance.plot" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot</span><span class="p">(</span><span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">summary_plot_kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

      <p>Plots the resulting AUC of the model as well as the feature importances.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>plot_type</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Type of plot, used to compute shap.summary_plot. By default 'bar', available ones
are  "dot", "bar", "violin",</p>
              </div>
            </td>
            <td>
                  <code>&#39;bar&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>show</code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,
when you want to edit the returned axis, before showing it.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>**summary_plot_kwargs</code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>kwargs passed to the shap.summary_plot.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="matplotlib.axes">axes</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axes that include the plot.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>probatus/sample_similarity/resemblance_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">summary_plot_kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots the resulting AUC of the model as well as the feature importances.</span>

<span class="sd">    Args:</span>
<span class="sd">        plot_type (str, optional): Type of plot, used to compute shap.summary_plot. By default &#39;bar&#39;, available ones</span>
<span class="sd">            are  &quot;dot&quot;, &quot;bar&quot;, &quot;violin&quot;,</span>

<span class="sd">        show (bool, optional):</span>
<span class="sd">            If True, the plots are showed to the user, otherwise they are not shown. Not showing plot can be useful,</span>
<span class="sd">            when you want to edit the returned axis, before showing it.</span>

<span class="sd">        **summary_plot_kwargs:</span>
<span class="sd">            kwargs passed to the shap.summary_plot.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (matplotlib.axes):</span>
<span class="sd">            Axes that include the plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># This line serves as a double check if the object has been fitted</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>

    <span class="n">summary_plot</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shap_values_test</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span>
        <span class="n">plot_type</span><span class="o">=</span><span class="n">plot_type</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
        <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">summary_plot_kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">plot_title</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results_text</span><span class="p">,</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">),</span>
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">xycoords</span><span class="o">=</span><span class="s2">&quot;axes fraction&quot;</span><span class="p">,</span>
        <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
        <span class="n">va</span><span class="o">=</span><span class="s2">&quot;top&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; ING Bank N.V.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  </body>
</html>